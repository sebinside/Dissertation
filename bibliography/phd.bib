
@thesis{meier_automated_2010,
	location = {Karlsruhe, Germany},
	title = {Automated Transformation of Palladio Component Models to Queueing Petri Nets},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Master's Thesis},
	author = {Meier, Philipp},
	date = {2010},
}

@thesis{kunz_efficient_2018,
	location = {Karlsruhe, Germany},
	title = {Efficient Data Flow Constraint Analysis},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Master's Thesis},
	author = {Kunz, Jonas},
	date = {2018},
}

@article{van_deursen_domain-specific_2000,
	title = {Domain-specific languages: An annotated bibliography},
	volume = {35},
	pages = {26--36},
	number = {6},
	journaltitle = {{ACM} Sigplan Notices},
	author = {Van Deursen, Arie and Klint, Paul and Visser, Joost},
	date = {2000},
}

@unpublished{hahner_confidentiality_2019,
	title = {Confidentiality Formalisms for Design Time Security Analyses},
	author = {Hahner, Sebastian},
	date = {2019},
	note = {Seminar Thesis},
}

@book{reussner_modeling_2016,
	title = {Modeling and Simulating Software Architectures: The Palladio Approach},
	publisher = {The {MIT} Press},
	author = {Reussner, Ralf H. and Becker, Steffen and Happe, Jens and Heinrich, Robert and Koziolek, Anne and Koziolek, Heiko and Kramer, Max and Krogmann, Klaus},
	date = {2016},
}

@inproceedings{mohagheghi_evaluating_2010,
	title = {Evaluating domain-specific modelling solutions},
	pages = {212--221},
	booktitle = {International Conference on Conceptual Modeling},
	publisher = {Springer},
	author = {Mohagheghi, Parastoo and Haugen, Øystein},
	date = {2010},
}

@thesis{mueller_abbildung_2019,
	location = {Karlsruhe, Germany},
	title = {Abbildung von {UMLsec}-Vertraulichkeitsanalysen auf Data-Centric Palladio},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Master's Thesis},
	author = {Mueller, Philip},
	date = {2019},
}

@thesis{juerjens_principles_2002,
	title = {Principles for secure systems design},
	institution = {University of Oxford},
	type = {phdthesis},
	author = {Juerjens, Jan},
	date = {2002},
}

@article{cardelli_type_1996,
	title = {Type systems (Fundamentals)},
	volume = {28},
	pages = {263--264},
	number = {1},
	journaltitle = {{ACM} Computing Surveys ({CSUR})},
	author = {Cardelli, Luca},
	date = {1996},
	note = {Publisher: {ACM} New York, {NY}, {USA}},
}

@incollection{cardelli_type_1996-1,
	title = {Type Systems},
	publisher = {Digital Equipment Corporation},
	author = {Cardelli, Luca},
	date = {1996},
	note = {Section: 103},
}

@book{stachowiak_allgemeine_1973,
	title = {Allgemeine Modelltheorie},
	publisher = {Springer},
	author = {Stachowiak, Herbert},
	date = {1973},
}

@book{pierce_type_2002,
	title = {Type Systems and Programming Languages},
	publisher = {{MIT} Press},
	author = {Pierce, Benjamin C},
	date = {2002},
}

@report{kang_feature-oriented_1990,
	title = {Feature-oriented domain analysis ({FODA}) feasibility study},
	institution = {Carnegie-Mellon Univ Pittsburgh Pa Software Engineering Inst},
	author = {Kang, Kyo C and Cohen, Sholom G and Hess, James A and Novak, William E and Peterson, A Spencer},
	date = {1990},
}

@article{runeson_guidelines_2009,
	title = {Guidelines for conducting and reporting case study research in software engineering},
	volume = {14},
	pages = {131},
	number = {2},
	journaltitle = {Empirical software engineering},
	author = {Runeson, Per and Höst, Martin},
	date = {2009},
}

@article{harrison_protection_1976,
	title = {Protection in operating systems},
	volume = {19},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/360303.360333},
	doi = {10.1145/360303.360333},
	abstract = {A model of protection mechanisms in computing systems is presented and its appropriateness is argued. The "safety" problem for protection systems under this model is to determine in a given situation whether a subject can acquire a particular right to an object. In restricted cases, it can be shown that this problem is decidable, i.e. there is an algorithm to determine whether a system in a particular configuration is safe. In general, and under surprisingly weak assumptions, it cannot be decided if a situation is safe. Various implications of this fact are discussed.},
	pages = {461--471},
	number = {8},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Harrison, Michael A. and Ruzzo, Walter L. and Ullman, Jeffrey D.},
	urldate = {2020-09-28},
	date = {1976-08},
	langid = {english},
}

@report{hu_guide_2014,
	title = {Guide to Attribute Based Access Control ({ABAC}) Definition and Considerations},
	url = {https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-162.pdf},
	abstract = {This document provides Federal agencies with a definition of attribute based access control ({ABAC}). {ABAC} is a logical access control methodology where authorization to perform a set of operations is determined by evaluating attributes associated with the subject, object, requested operations, and, in some cases, environment conditions against policy, rules, or relationships that describe the allowable operations for a given set of attributes. This document also provides considerations for using {ABAC} to improve information sharing within organizations and between organizations while maintaining control of that information.},
	pages = {NIST SP 800--162},
	number = {{NIST} {SP} 800-162},
	institution = {National Institute of Standards and Technology},
	author = {Hu, Vincent C. and Ferraiolo, David and Kuhn, Rick and Schnitzer, Adam and Sandlin, Kenneth and Miller, Robert and Scarfone, Karen},
	urldate = {2020-09-28},
	date = {2014-01},
	langid = {english},
}

@article{schaad_role-based_2001,
	title = {The Role-Based Access Control System of a European Bank: A Case Study and Discussion},
	abstract = {Research in the area of role-based access control has made fast progress over the last few years. However, little has been done to identify and describe existing role-based access control systems within large organisations. This paper describes the access control system of a major European Bank. An overview of the system’s structure, its administration and existing control principles constraining the administration is given. In addition, we provide an answer to a key question – the ratio of the number of roles to the system user population – which was raised in the recent {RBAC}2000 Workshop. Having described certain weaknesses of the Bank’s system, the case study is extended to a comparison between the system and the {RBAC}96 models. In particular the issues of inheritance and grouping are addressed.},
	pages = {7},
	journaltitle = {Proceedings of the sixth {ACM} symposium on Access control models and technologies},
	author = {Schaad, Andreas and Moffett, Jonathan and Jacob, Jeremy},
	date = {2001},
	langid = {english},
}

@inproceedings{abdul-rahman_pgp_1997,
	title = {The {PGP} Trust Model},
	volume = {10},
	pages = {27--31},
	booktitle = {{EDI}-Forum: the Journal of Electronic Commerce},
	author = {Abdul-Rahman, Alfarez},
	date = {1997},
	note = {Issue: 3},
}

@book{bramer_logic_2013,
	location = {London},
	title = {Logic Programming with Prolog},
	isbn = {978-1-4471-5486-0 978-1-4471-5487-7},
	url = {http://link.springer.com/10.1007/978-1-4471-5487-7},
	publisher = {Springer London},
	author = {Bramer, Max},
	urldate = {2020-09-28},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-1-4471-5487-7},
}

@inproceedings{bariic_usability_2012,
	location = {Lisbon, {TBD}, Portugal},
	title = {Usability Evaluation of Domain-Specific Languages},
	isbn = {978-1-4673-2345-1 978-0-7695-4777-0},
	url = {http://ieeexplore.ieee.org/document/6511840/},
	doi = {10.1109/QUATIC.2012.63},
	abstract = {Domain-Specific Languages ({DSLs}) are claimed to bring important productivity improvements to developers, when compared to General-Purpose Languages ({GPLs}). The increased Usability is regarded as one of the key benefits of {DSLs} when compared to {GPLs}, and has an important impact on the achieved productivity of the {DSL} users. So, it is essential to build in good usability while developing the {DSL}. The purpose of this proposal is to contribute to the systematic activity of Software Language Engineering by focusing on the issue of the Usability evaluation of {DSLs}. Usability evaluation is often skipped, relaxed, or at least omitted from papers reporting development of {DSLs}. We argue that a systematic approach based on User Interface experimental validation techniques should be used to assess the impact of new {DSLs}. For that purpose, we propose to merge common Usability evaluation processes with the {DSL} development process. In order to provide reliable metrics and tools we should reuse and identify good practices that exist in Human-Computer Interaction community.},
	eventtitle = {2012 Eighth International Conference on the Quality of Information and Communications Technology ({QUATIC})},
	pages = {342--347},
	booktitle = {2012 Eighth International Conference on the Quality of Information and Communications Technology},
	publisher = {{IEEE}},
	author = {Bariic, Ankica and Amaral, Vasco and Goulao, Miguel},
	urldate = {2020-09-28},
	date = {2012-09},
	langid = {english},
}

@inproceedings{van_amstel_exercise_2010,
	location = {Antwerp, Belgium},
	title = {An exercise in iterative domain-specific language design?},
	isbn = {978-1-4503-0128-2},
	url = {http://portal.acm.org/citation.cfm?doid=1862372.1862386},
	doi = {10.1145/1862372.1862386},
	abstract = {We describe our experiences with the process of designing a domain-speciﬁc language ({DSL}) and corresponding model transformations. The simultaneous development of the language and the transformations has lead to an iterative evolution of the {DSL}. We identiﬁed four main inﬂuences on the evolution of our {DSL}: the problem domain, the target platforms, model quality, and model transformation quality.},
	eventtitle = {the Joint {ERCIM} Workshop on Software Evolution ({EVOL}) and International Workshop on Principles of Software Evolution ({IWPSE})},
	pages = {48--57},
	booktitle = {Proceedings of the Joint {ERCIM} Workshop on Software Evolution ({EVOL}) and International Workshop on Principles of Software Evolution ({IWPSE}) on - {IWPSE}-{EVOL} '10},
	publisher = {{ACM} Press},
	author = {van Amstel, Marcel and van den Brand, Mark and Engelen, Luc},
	urldate = {2020-09-28},
	date = {2010},
	langid = {english},
}

@article{strembeck_approach_2009,
	title = {An approach for the systematic development of domain-specific languages},
	volume = {39},
	issn = {00380644, 1097024X},
	url = {http://doi.wiley.com/10.1002/spe.936},
	doi = {10.1002/spe.936},
	abstract = {Building tailored software systems for a particular application domain is a complex task. For this reason, domain-speciﬁc languages ({DSLs}) receive a constantly growing attention in recent years. So far the main focus of {DSL} research is on case studies and experience reports for the development of individual {DSLs}, design approaches and implementation techniques for {DSLs}, and the integration of {DSLs} with other software development approaches on a technical level. In this paper, we identify and describe the different activities that we conduct when engineering a {DSL}, and describe how these activities can be combined in order to deﬁne a tailored {DSL} engineering process. Our research results are based on the experiences we gained from multiple different {DSL} development projects and prototyping experiments. Copyright © 2009 John Wiley \& Sons, Ltd.},
	pages = {1253--1292},
	number = {15},
	journaltitle = {Software: Practice and Experience},
	shortjournal = {Softw: Pract. Exper.},
	author = {Strembeck, Mark and Zdun, Uwe},
	urldate = {2020-09-28},
	date = {2009-10},
	langid = {english},
}

@article{paige_principles_2000,
	title = {Principles for modeling language design},
	volume = {42},
	issn = {09505849},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584900001099},
	doi = {10.1016/S0950-5849(00)00109-9},
	abstract = {Modeling languages, like programming languages, need to be designed if they are to be practical, usable, accepted, and of lasting value. We present principles for the design of modeling languages. To arrive at these principles, we consider the intended use of modeling languages. We conject that the principles are applicable to the development of new modeling languages, and for improving the design of existing modeling languages that have evolved, perhaps through a process of uniﬁcation. The principles are illustrated and explained by several examples, drawing on object-oriented and mathematical modeling languages. ᭧ 2000 Elsevier Science B.V. All rights reserved.},
	pages = {665--675},
	number = {10},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Paige, R.F and Ostroff, J.S and Brooke, P.J},
	urldate = {2020-09-28},
	date = {2000-07},
	langid = {english},
}

@article{mernik_when_2005,
	title = {When and how to develop domain-specific languages},
	volume = {37},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/1118890.1118892},
	doi = {10.1145/1118890.1118892},
	pages = {316--344},
	number = {4},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Mernik, Marjan and Heering, Jan and Sloane, Anthony M.},
	urldate = {2020-09-28},
	date = {2005-12},
	langid = {english},
}

@article{basili_methodology_1984,
	title = {A Methodology for Collecting Valid Software Engineering Data},
	volume = {{SE}-10},
	issn = {0098-5589},
	url = {http://ieeexplore.ieee.org/document/5010301/},
	doi = {10.1109/TSE.1984.5010301},
	abstract = {{OF} {PROJECT} {INFORMATION} The projects studied vary widely with respect to factors such as application, size, development team, methodology, hardware, and support software. Nonetheless, the same basic data collection methodology was applicable everywhere. The schema used has six basic steps, listed in the following, with considerable feedback and iteration occurring at several different places.},
	pages = {728--738},
	number = {6},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	shortjournal = {{IIEEE} Trans. Software Eng.},
	author = {Basili, Victor R. and Weiss, David M.},
	urldate = {2020-09-28},
	date = {1984-11},
	langid = {english},
}

@article{basili_goal_1994,
	title = {The Goal Question Metric Approach},
	pages = {10},
	journaltitle = {Encyclopedia of software engineering},
	author = {Basili, Victor R and Caldiera, Gianluigi and Rombach, H Dieter},
	date = {1994},
	langid = {english},
}

@article{challenger_systematic_2016,
	title = {A systematic approach to evaluating domain-specific modeling language environments for multi-agent systems},
	volume = {24},
	issn = {0963-9314, 1573-1367},
	url = {http://link.springer.com/10.1007/s11219-015-9291-5},
	doi = {10.1007/s11219-015-9291-5},
	abstract = {Multi-agent systems ({MASs}) include multiple interacting agents within an environment to provide a solution for complex systems that cannot be easily solved with individual agents or monolithic systems. However, the development of {MASs} is not trivial due to the various agent properties such as autonomy, responsiveness, and proactiveness, and the need for realization of the many different agent interactions. To support the development of {MASs} various domain-speciﬁc modeling languages ({DSMLs}) have been introduced that provide a declarative approach for modeling and supporting the generation of agent-based systems. To be effective, the proposed {DSMLs} need to meet the various stakeholder concerns and the related quality criteria for the corresponding {MASs}. Unfortunately, very often the evaluation of the {DSML} is completely missing or has been carried out in idiosyncratic approach. If the {DSMLs} are not well deﬁned, then implicitly this will have an impact on the quality of the {MASs}. In this paper, we present an evaluation framework and systematic approach for assessing existing or newly deﬁned {DSMLs} for {MASs}. The evaluation is speciﬁc for {MAS} {DSMLs} and targets both the language and the corresponding tools. To illustrate the evaluation approach, we ﬁrst present {SEA}\_ML, which is a model-driven {MAS} {DSML} for supporting the modeling and generation of agentbased systems. The evaluation of {SEA}\_ML is based on a multi-case study research approach and provides both qualitative evaluation and quantitative analysis. We report on the lessons learned considering the adoption of the evaluation approach as well as the {SEA}\_ML for supporting the generation of agent-based systems.},
	pages = {755--795},
	number = {3},
	journaltitle = {Software Quality Journal},
	shortjournal = {Software Qual J},
	author = {Challenger, Moharram and Kardas, Geylani and Tekinerdogan, Bedir},
	urldate = {2020-09-28},
	date = {2016-09},
	langid = {english},
}

@article{blanchette_soundness_2017,
	title = {Soundness and Completeness Proofs by Coinductive Methods},
	volume = {58},
	issn = {0168-7433, 1573-0670},
	url = {http://link.springer.com/10.1007/s10817-016-9391-3},
	doi = {10.1007/s10817-016-9391-3},
	abstract = {We show how codatatypes can be employed to produce compact, high-level proofs of key results in logic: the soundness and completeness of proof systems for variations of ﬁrst-order logic. For the classical completeness result, we ﬁrst establish an abstract property of possibly inﬁnite derivation trees. The abstract proof can be instantiated for a wide range of Gentzen and tableau systems for various ﬂavors of ﬁrst-order logic. Soundness becomes interesting as soon as one allows inﬁnite proofs of ﬁrst-order formulas. This forms the subject of several cyclic proof systems for ﬁrst-order logic augmented with inductive predicate deﬁnitions studied in the literature. All the discussed results are formalized using Isabelle/{HOL}’s recently introduced support for codatatypes and corecursion. The development illustrates some unique features of Isabelle/{HOL}’s new coinductive speciﬁcation language such as nesting through non-free types and mixed recursion–corecursion.},
	pages = {149--179},
	number = {1},
	journaltitle = {Journal of Automated Reasoning},
	shortjournal = {J Autom Reasoning},
	author = {Blanchette, Jasmin Christian and Popescu, Andrei and Traytel, Dmitriy},
	urldate = {2020-09-28},
	date = {2017-01},
	langid = {english},
}

@article{karsai_design_2014,
	title = {Design Guidelines for Domain Speciﬁc Languages},
	abstract = {Designing a new domain speciﬁc language is as any other complex task sometimes error-prone and usually time consuming, especially if the language shall be of high-quality and comfortably usable. Existing tool support focuses on the simpliﬁcation of technical aspects but lacks support for an enforcement of principles for a good language design. In this paper we investigate guidelines that are useful for designing domain speciﬁc languages, largely based on our experience in developing languages as well as relying on existing guidelines on general purpose ({GPLs}) and modeling languages. We deﬁned guidelines to support a {DSL} developer to achieve better quality of the language design and a better acceptance among its users.},
	pages = {7},
	author = {Karsai, Gabor and Krahn, Holger and Pinkernell, Claas and Rumpe, Bernhard and Schindler, Martin and Völkel, Steven},
	date = {2014},
	langid = {english},
}

@article{cousot_language_1989,
	title = {A language independent proof of the soundness and completeness of generalized Hoare logic},
	volume = {80},
	issn = {08905401},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0890540189900187},
	doi = {10.1016/0890-5401(89)90018-7},
	pages = {165--191},
	number = {2},
	journaltitle = {Information and Computation},
	shortjournal = {Information and Computation},
	author = {Cousot, Patrick and Cousot, Radhia},
	urldate = {2020-09-28},
	date = {1989-02},
	langid = {english},
}

@article{thatcher_more_1981,
	title = {More on Advice on structuring compilers and proving them correct},
	volume = {15},
	abstract = {Following Lockwood Morris, a method for algebraically structuring a compiler and proving it correct is described. An example language with block structure and side-effects is presented. This determines an initial many-sorted algebra\#L which is the ‘abstract syntax’ of the example language. Then the semantics of L is completely determined by describing a semantic algebra M ‘similar’ to L. In particular, initiality of L ensures that there is a unique homomorphism Lsem : L + M This is algebraically structuring the semantic definition {OIIthe} language. A category of flow-charts over a stack machine is used as a target language for the purposes of compilation. The semantics of the flow charts (Tsem : T + S) ibsalso algebraically determined given interpretations of the primitive operations on the stack and store. The homomorphism camp : C + T is the compiler which is also uniquely determined by presenting an algebra T of flowcharts similar to L. This is algebraically structuring the compiler.},
	pages = {27},
	number = {3},
	journaltitle = {Theoretical Computer Science},
	author = {Thatcher, James W and Wagner, Eric G},
	date = {1981},
	langid = {english},
}

@incollection{mehlhorn_using_1985,
	location = {Berlin/Heidelberg},
	title = {Using domain algebras to prove the correctness of a compiler},
	volume = {182},
	isbn = {978-3-540-13912-6},
	url = {http://link.springer.com/10.1007/BFb0023999},
	abstract = {Domain algebras are proposed as a tool for structuring compiler correctness proofs which are based on denotational semantics of the source and target language. The correctness of a compiler for a small imperative language is proved as an illustration.},
	pages = {98--108},
	booktitle = {{STACS} 85},
	publisher = {Springer-Verlag},
	author = {Dybjer, Peter},
	editor = {Mehlhorn, K.},
	urldate = {2020-09-28},
	date = {1985},
	langid = {english},
	doi = {10.1007/BFb0023999},
	note = {Series Title: Lecture Notes in Computer Science},
}

@article{jackson_formalizing_2009,
	title = {Formalizing the structural semantics of domain-specific modeling languages},
	volume = {8},
	issn = {1619-1366, 1619-1374},
	url = {http://link.springer.com/10.1007/s10270-008-0105-0},
	doi = {10.1007/s10270-008-0105-0},
	abstract = {Model-based approaches to system design are now widespread and successful. These approaches make extensive use of model structure to describe systems using domain-speciﬁc abstractions, to specify and implement model transformations, and to analyze structural properties of models. In spite of its general importance the structural semantics of modeling languages are not well-understood. In this paper we develop the formal foundations for the structural semantics of domain-speciﬁc modeling languages ({DSML}), including the mechanisms by which metamodels specify the structural semantics of {DSMLs}. Additionally, we show how our formalization can complement existing tools, and how it yields algorithms for the analysis of {DSMLs} and model transformations.},
	pages = {451--478},
	number = {4},
	journaltitle = {Software \& Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Jackson, Ethan and Sztipanovits, Janos},
	urldate = {2020-09-28},
	date = {2009-09},
	langid = {english},
}

@incollection{hutchison_model_2010,
	location = {Berlin, Heidelberg},
	title = {Model Transformation Languages Relying on Models as {ADTs}},
	volume = {5969},
	isbn = {978-3-642-12106-7 978-3-642-12107-4},
	url = {http://link.springer.com/10.1007/978-3-642-12107-4_10},
	abstract = {In this paper we describe a simple formal approach that can be used to support the definition and implementation of model to model transformations. The approach is based on the idea that models as well as metamodels should be regarded as abstract data types ({ADTs}), that is to say, as abstract structures equipped with a set of operations. On top of these {ADTs} we define a minimal, imperative model transformation language with strong formal semantics. This proposal can be used in two different ways, on one hand it enables simple transformations to be implemented simply by writing them in any ordinary programming language enriched with the {ADTs}. And on the other hand, it provides a practical way to formally define the semantics of more complex model transformation languages.},
	pages = {133--143},
	booktitle = {Software Language Engineering},
	publisher = {Springer Berlin Heidelberg},
	author = {Irazábal, Jerónimo and Pons, Claudia},
	editor = {van den Brand, Mark and Gašević, Dragan and Gray, Jeff},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-09-28},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-3-642-12107-4_10},
	note = {Series Title: Lecture Notes in Computer Science},
}

@inproceedings{morris_advice_1973,
	location = {Boston, Massachusetts},
	title = {Advice on structuring compilers and proving them correct},
	url = {http://portal.acm.org/citation.cfm?doid=512927.512941},
	doi = {10.1145/512927.512941},
	eventtitle = {the 1st annual {ACM} {SIGACT}-{SIGPLAN} symposium},
	pages = {144--152},
	booktitle = {Proceedings of the 1st annual {ACM} {SIGACT}-{SIGPLAN} symposium on Principles of programming languages  - {POPL} '73},
	publisher = {{ACM} Press},
	author = {Morris, F. Lockwood},
	urldate = {2020-09-28},
	date = {1973},
	langid = {english},
}

@collection{bertot_theorem_1999,
	location = {Berlin},
	title = {Theorem proving in higher order logics: 12th international conference ; proceedings},
	isbn = {978-3-540-66463-5},
	series = {Lecture notes in computer science},
	shorttitle = {Theorem proving in higher order logics},
	pagetotal = {358},
	number = {1690},
	publisher = {Springer},
	editor = {Bertot, Yves and {TPHOLs}},
	date = {1999},
	langid = {english},
	note = {Meeting Name: International Conference on Theorem Proving in Higher Order Logics ({TPHOLs})
{OCLC}: 845320206},
}

@article{narayanan_towards_2008,
	title = {Towards Verifying Model Transformations},
	volume = {211},
	issn = {15710661},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1571066108002569},
	doi = {10.1016/j.entcs.2008.04.041},
	abstract = {In model-based software development, a complete design and analysis process involves designing the system using the design language, converting it into the analysis language, and performing the veriﬁcation and analysis on the analysis model. Graph transformation is increasingly being used to automate this conversion. In such a scenario, it is very important that the conversion preserves the semantics of the design model. This paper discusses an approach to verify this semantic equivalence for each transformation. We will show how to check whether a particular transformation resulted in an output model that preserves the semantics of the input model with respect to a particular property.},
	pages = {191--200},
	journaltitle = {Electronic Notes in Theoretical Computer Science},
	shortjournal = {Electronic Notes in Theoretical Computer Science},
	author = {Narayanan, Anantha and Karsai, Gabor},
	urldate = {2020-09-28},
	date = {2008-04},
	langid = {english},
}

@article{carlsson_implementing_1984,
	title = {On implementing Prolog in functional programming},
	volume = {2},
	issn = {0288-3635, 1882-7055},
	url = {http://link.springer.com/10.1007/BF03037326},
	doi = {10.1007/BF03037326},
	abstract = {This report surveys techniques for implementing the programming language Prolog. It focuses on explaining the procedural semantics of the language in terms of functional programming constructs. The techniques success continuations and proof streams are introduced, and it is shown how Horn clause interpreters can be built upon them. Continuations are well known from denotational semantics theory, in this paper it is shown that they are viable constructs in actual programs. Other issues include implementation of logical variables, structure sharing vs. structure copying, determinacy, builtin predicates, and cut.},
	pages = {347--359},
	number = {4},
	journaltitle = {New Generation Computing},
	shortjournal = {New Gener Comput},
	author = {Carlsson, Mats},
	urldate = {2020-09-28},
	date = {1984-12},
	langid = {english},
}

@incollection{goos_efficient_1996,
	location = {Berlin, Heidelberg},
	title = {Efficient translation of lazy functional logic programs into Prolog},
	volume = {1048},
	url = {http://link.springer.com/10.1007/3-540-60939-3_19},
	abstract = {In this paper, we present a high-level implementation of lazy functional logic programs by transforming them into Prolog programs. The transformation is controlled by generalized definitional trees which specify the narrowing strategy to be implemented. Since we consider a sophisticated narrowing strategy! a direct mapping of functions into predicates is not possible. Therefore, we present new techniques to reduce the interpretational overhead of the generated Prolog code. This leads to a portable and efficient implementation of functional logic programs.},
	pages = {252--266},
	booktitle = {Logic Program Synthesis and Transformation},
	publisher = {Springer Berlin Heidelberg},
	author = {Hanus, Michael},
	editor = {Proietti, Maurizio},
	editorb = {Goos, Gerhard and Hartmanis, Juris and Leeuwen, Jan},
	editorbtype = {redactor},
	urldate = {2020-09-28},
	date = {1996},
	langid = {english},
}

@incollection{goos_compiling_2000,
	location = {Berlin, Heidelberg},
	title = {Compiling Multi-paradigm Declarative Programs into Prolog},
	volume = {1794},
	url = {http://link.springer.com/10.1007/10720084_12},
	abstract = {This paper describes a high-level implementation of the concurrent constraint functional logic language Curry. The implementation, directed by the lazy pattern matching strategy of Curry, is obtained by transforming Curry programs into Prolog programs. Contrary to previous transformations of functional logic programs into Prolog, our implementation includes new mechanisms for both eﬃciently performing concurrent evaluation steps and sharing common subterms. The practical results show that our implementation is superior to previously proposed similar implementations of functional logic languages in Prolog and is competitive w.r.t. lower-level implementations of Curry in other target languages.},
	pages = {171--185},
	booktitle = {Frontiers of Combining Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Antoy, Sergio and Hanus, Michael},
	editor = {Kirchner, Hélène and Ringeissen, Christophe},
	editorb = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan},
	editorbtype = {redactor},
	urldate = {2020-09-28},
	date = {2000},
	langid = {english},
}

@article{cabot_verification_2014,
	title = {On the verification of {UML}/{OCL} class diagrams using constraint programming},
	volume = {93},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121214000739},
	doi = {10.1016/j.jss.2014.03.023},
	abstract = {Assessment of the correctness of software models is a key issue to ensure the quality of the ﬁnal application. To this end, this paper presents an automatic method for the veriﬁcation of {UML} class diagrams extended with {OCL} constraints. Our method checks compliance of the diagram with respect to several correctness properties including weak and strong satisﬁability or absence of constraint redundancies among others. The method works by translating the {UML}/{OCL} model into a Constraint Satisfaction Problem ({CSP}) that is evaluated using state-of-the-art constraint solvers to determine the correctness of the initial model. Our approach is particularly relevant to current {MDA} and {MDD} methods where software models are the primary artifacts of the development process and the basis for the (semi-)automatic code-generation of the ﬁnal application.},
	pages = {1--23},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Cabot, J. and Clarisó, R. and Riera, D.},
	urldate = {2020-09-28},
	date = {2014-07},
	langid = {english},
}

@article{sprinkle_domain-specific_2004,
	title = {A domain-specific visual language for domain model evolution},
	volume = {15},
	issn = {1045926X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1045926X0400014X},
	doi = {10.1016/j.jvlc.2004.01.006},
	abstract = {Domain-speciﬁc visual languages ({DSVLs}) are concise and useful tools that allow the rapid development of the behavior and/or structure of applications in well-deﬁned domains. These languages are typically developed speciﬁcally for a domain, and have a strong cohesion to the domain concepts, which often appear as primitives in the language. The strong cohesion between {DSVL} language primitives and the domain is a beneﬁt for development by domain experts, but can be a drawback when the domain evolves—even when that evolution appears to be insigniﬁcant. This paper presents a domain-speciﬁc visual language developed expressly for the evolution of domain-speciﬁc visual languages, and uses concepts from graph rewriting to specify and carry out the transformation of the models built using the original {DSVL}.},
	pages = {291--307},
	number = {3},
	journaltitle = {Journal of Visual Languages \& Computing},
	shortjournal = {Journal of Visual Languages \& Computing},
	author = {Sprinkle, Jonathan and Karsai, Gabor},
	urldate = {2020-09-28},
	date = {2004-06},
	langid = {english},
}

@article{kosar_domain-specific_2016,
	title = {Domain-Specific Languages: A Systematic Mapping Study},
	volume = {71},
	issn = {09505849},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950584915001858},
	doi = {10.1016/j.infsof.2015.11.001},
	shorttitle = {Domain-Specific Languages},
	abstract = {Objective: The main objective of the described work was to perform an {SMS} on {DSLs} to better understand the {DSL} research ﬁeld, identify research trends, and any possible open issues. The set of research questions was inspired by a {DSL} survey paper published in 2005.
Method: We conducted a {SMS} over 5 stages: deﬁning research questions, conducting the search, screening, classifying, and data extraction. Our {SMS} included 1153 candidate primary studies from the {ISI} Web of Science and {ACM} Digital Library, 390 primary studies were classiﬁed after screening.
Results: This {SMS} discusses two main research questions: research space and trends/demographics of the literature within the ﬁeld of {DSLs}. Both research questions are further subdivided into several research subquestions. The results from the ﬁrst research question clearly show that the {DSL} community focuses more on the development of new techniques/methods rather than investigating the integrations of {DSLs} with other software engineering processes or measuring the effectiveness of {DSL} approaches. Furthermore, there is a clear lack of evaluation research. Amongst different {DSL} development phases more attention is needed in regard to domain analysis, validation, and maintenance. The second research question revealed that the number of publications remains stable, and has not increased over the years. Top cited papers and venues are mentioned, as well as identifying the more active institutions carrying {DSL} research.
Conclusion: The statistical ﬁndings regarding research questions paint an interesting picture about the mainstreams of the {DSL} community, as well as open issues where researchers can improve their research in their future work.},
	pages = {77--91},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Kosar, Tomaž and Bohra, Sudev and Mernik, Marjan},
	urldate = {2020-09-28},
	date = {2016-03},
	langid = {english},
}

@inproceedings{mohagheghi_existing_2009,
	location = {Vancouver, {BC}},
	title = {Existing model metrics and relations to model quality},
	isbn = {978-1-4244-3723-8},
	url = {http://ieeexplore.ieee.org/document/5071555/},
	doi = {10.1109/WOSQ.2009.5071555},
	abstract = {This paper presents quality goals for models and provides a state-of-the-art analysis regarding model metrics. While model-based software development often requires assessing the quality of models at different abstraction and precision levels and developed for multiple purposes, existing work on model metrics do not reflect this need. Model size metrics are descriptive and may be used for comparing models but their relation to model quality is not welldefined. Code metrics are proposed to be applied on models for evaluating design quality while metrics related to other quality goals are few. Models often consist of a significant amount of elements, which allows a large amount of metrics to be defined on them. However, identifying useful model metrics, linking them to model quality goals, providing some baseline for interpretation of data, and combining metrics with other evaluation models such as inspections requires more theoretical and empirical work.},
	eventtitle = {2009 {ICSE} Workshop on Software Quality ({WoSQ} 2009)},
	pages = {39--45},
	booktitle = {2009 {ICSE} Workshop on Software Quality},
	publisher = {{IEEE}},
	author = {Mohagheghi, P. and Dehlen, V.},
	urldate = {2020-09-28},
	date = {2009-05},
	langid = {english},
}

@article{grassi_filling_2007,
	title = {Filling the gap between design and performance/reliability models of component-based systems: A model-driven approach},
	volume = {80},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121206002044},
	doi = {10.1016/j.jss.2006.07.023},
	shorttitle = {Filling the gap between design and performance/reliability models of component-based systems},
	abstract = {To facilitate the use of non-functional analysis results in the selection and assembly of components for component-based systems, automatic prediction tools should be devised, to predict some overall quality attribute of the application without requiring extensive knowledge of analysis methodologies to the application designer. To achieve this goal, a key idea is to deﬁne a model transformation that takes as input some ‘‘design-oriented’’ model of the component assembly and produces as a result an ‘‘analysis-oriented’’ model that lends itself to the application of some analysis methodology. However, to actually devise such a transformation, we must face both the heterogeneous design level notations for component-based systems, and the variety of non-functional attributes and related analysis methodologies we could be interested in. To tackle these problems, we deﬁne a model-driven transformation framework, centered around a kernel language whose aim is to capture the relevant information for the analysis of non-functional attributes of component-based systems, with a focus on performance and reliability. Using this kernel language as a bridge between design-oriented and analysisoriented notations we reduce the burden of deﬁning a variety of direct transformations from the former to the latter to the less complex problem of deﬁning transformations to/from the kernel language. The proposed kernel language is deﬁned within the {MOF} (Meta-Object Facility) framework, to allow the exploitation of {MOF}-based model transformation facilities.},
	pages = {528--558},
	number = {4},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Grassi, Vincenzo and Mirandola, Raffaela and Sabetta, Antonino},
	urldate = {2020-09-28},
	date = {2007-04},
	langid = {english},
}

@article{gotz_quality-based_2018,
	title = {Quality-based Software-Selection and Hardware-Mapping as Model Transformation Problem},
	abstract = {In this {TTC} case, we describe the computation of an optimal mapping from software implementations to hardware components for a given set of user requests as a model transformation problem. Further, contracts specify dependencies between components in terms of non-functional properties. Diﬀerent approaches of this case can be compared in terms of their validity, performance, scalability and, quality w.r.t. the real optimal deployment.},
	pages = {9},
	journaltitle = {{TTC}@ {STAF}},
	author = {Gotz, Sebastian and Mey, Johannes and Schone, Rene and Aßmann, Uwe},
	date = {2018},
	langid = {english},
}

@inproceedings{matinlassi_quality-driven_2005,
	location = {Pittsburgh, {PA}, {USA}},
	title = {Quality-Driven Software Architecture Model Transformation},
	isbn = {978-0-7695-2548-8},
	url = {http://ieeexplore.ieee.org/document/1620109/},
	doi = {10.1109/WICSA.2005.56},
	eventtitle = {5th Working {IEEE}/{IFIP} Conference on Software Architecture ({WICSA}'05)},
	pages = {199--200},
	booktitle = {5th Working {IEEE}/{IFIP} Conference on Software Architecture ({WICSA}'05)},
	publisher = {{IEEE}},
	author = {Matinlassi, M.},
	urldate = {2020-09-28},
	date = {2005},
	langid = {english},
}

@inproceedings{seifermann_architectural_2016,
	location = {Venice, Italy},
	title = {Architectural Data Flow Analysis},
	isbn = {978-1-5090-2131-4},
	url = {http://ieeexplore.ieee.org/document/7516842/},
	doi = {10.1109/WICSA.2016.49},
	abstract = {Quality properties including performance, security and compliance are crucial for a system’s success but are hard to prove, especially for complex systems. Data ﬂow analyses support this but often only consider source code and thereby introduce high costs of repair. Data ﬂow analyses on the architectural design level use call-and-return semantics or eventbased communication between components but do not deﬁne data ﬂows as ﬁrst class entities or consider important runtime or deployment conﬁgurations. We propose introducing data ﬂows as ﬁrst class entities on the architectural level. Analyses ensure that systems meet the quality requirements even after changes in e.g. runtime or deployment conﬁgurations. Having data ﬂows modeled as ﬁrst class entities allows analyzing compliance with privacy laws, requirements for external service providers, and throughput requirements in big data scenarios on architectural level. The results allow early, cost-efﬁcient ﬁxing of issues.},
	eventtitle = {2016 13th Working {IEEE}/{IFIP} Conference on Software Architecture ({WICSA})},
	pages = {270--271},
	booktitle = {2016 13th Working {IEEE}/{IFIP} Conference on Software Architecture ({WICSA})},
	publisher = {{IEEE}},
	author = {Seifermann, Stephan},
	urldate = {2020-09-28},
	date = {2016-04},
	langid = {english},
}

@inproceedings{seifermann_data-driven_2019,
	location = {Hamburg, Germany},
	title = {Data-Driven Software Architecture for Analyzing Confidentiality},
	isbn = {978-1-72810-528-4},
	url = {https://ieeexplore.ieee.org/document/8703910/},
	doi = {10.1109/ICSA.2019.00009},
	abstract = {Preservation of conﬁdentiality has become a crucial quality property of software systems that software vendors have to consider in each development phase. Especially, neglecting conﬁdentiality constraints in the software architecture leads to severe issues in later phases that often are hard to correct. In contrast to the implementation phase, there is no support for systematically considering conﬁdentiality in architectural design phases by means of data processing descriptions. To ﬁll this gap, we introduce data ﬂows in an architectural description language to enable simple deﬁnition of conﬁdentiality constraints. Afterwards, we transform the software architecture speciﬁcation to a logic program to ﬁnd violated conﬁdentiality constraints. In a case study-based evaluation, we apply the analysis to sixteen scenarios to show the accuracy of the approach.},
	pages = {1--10},
	booktitle = {2019 {IEEE} International Conference on Software Architecture ({ICSA})},
	publisher = {{IEEE}},
	author = {Seifermann, Stephan and Heinrich, Robert and Reussner, Ralf},
	urldate = {2020-09-28},
	date = {2019-03},
	langid = {english},
}

@thesis{weimann_automated_2017,
	location = {Karlsruhe, Germany},
	title = {Automated Cloud-to-Cloud Migration of Distributed So ware Systems for Privacy Compliance},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Master's Thesis},
	author = {Weimann, B Philipp},
	date = {2017},
	langid = {english},
}

@inproceedings{meier_automated_2011,
	location = {Singapore, Singapore},
	title = {Automated Transformation of Component-Based Software Architecture Models to Queueing Petri Nets},
	isbn = {978-1-4577-0468-0},
	url = {http://ieeexplore.ieee.org/document/6005378/},
	doi = {10.1109/MASCOTS.2011.23},
	abstract = {Performance predictions early in the software development process can help to detect problems before resources have been spent on implementation. The Palladio Component Model ({PCM}) is an example of a mature domain-speciﬁc modeling language for component-based systems enabling performance predictions at design time. {PCM} provides several alternative model solution methods based on analytical and simulation techniques. However, existing solution methods suffer from scalability issues and provide limited ﬂexibility in trading-off between results accuracy and analysis overhead. Queueing Petri Nets ({QPNs}) are a general-purpose modeling formalism, at a lower level of abstraction, for which efﬁcient and mature simulation-based solution techniques are available. This paper contributes a formal mapping from {PCM} to {QPN} models, implemented by means of an automated model-to-model transformation as part of a new {PCM} solution method based on simulation of {QPNs}. The limitations of the mapping and the accuracy and overhead of the new solution method compared to existing methods are evaluated in detail in the context of ﬁve case studies of different size and complexity. The new solution method proved to provide good accuracy with solution overhead up to 20 times lower compared to {PCM}’s reference solver.},
	eventtitle = {Simulation of Computer and Telecommunication Systems ({MASCOTS})},
	pages = {339--348},
	booktitle = {2011 {IEEE} 19th Annual International Symposium on Modelling, Analysis, and Simulation of Computer and Telecommunication Systems},
	publisher = {{IEEE}},
	author = {Meier, Philipp and Kounev, Samuel and Koziolek, Heiko},
	urldate = {2020-09-28},
	date = {2011-07},
	langid = {english},
}

@incollection{kounev_model_2008,
	location = {Berlin, Heidelberg},
	title = {A Model Transformation from the Palladio Component Model to Layered Queueing Networks},
	volume = {5119},
	isbn = {978-3-540-69813-5 978-3-540-69814-2},
	url = {http://link.springer.com/10.1007/978-3-540-69814-2_6},
	abstract = {For component-based performance engineering, software component developers individually create performance speciﬁcations of their components. Software architects compose these speciﬁcations to architectural models. This enables assessing the possible fulﬁlment of performance requirements without the need to purchase and deploy the component implementations. Many existing performance models do not support component-based performance engineering but o↵er e cient solvers. On the other hand, component-based performance engineering approaches often lack tool support. We present a model transformation combining the advanced component concepts of the Palladio Component Model ({PCM}) with the e cient performance solvers of Layered Queueing Networks ({LQN}). Joining the tool-set for {PCM} speciﬁcations with the toolset for {LQN} solution is an important step to carry component-based performance engineering into industrial practice. We validate the correctness of the transformation by mapping the {PCM} model of a component-based architecture to an {LQN} and conduct performance predictions.},
	pages = {58--78},
	booktitle = {Performance Evaluation: Metrics, Models and Benchmarks},
	publisher = {Springer Berlin Heidelberg},
	author = {Koziolek, Heiko and Reussner, Ralf},
	editor = {Kounev, Samuel and Gorton, Ian and Sachs, Kai},
	urldate = {2020-09-28},
	date = {2008},
	langid = {english},
	doi = {10.1007/978-3-540-69814-2_6},
	note = {{ISSN}: 0302-9743, 1611-3349
Series Title: Lecture Notes in Computer Science},
}

@inproceedings{liu_fabric_2009,
	location = {Big Sky, Montana, {USA}},
	title = {Fabric: a platform for secure distributed computation and storage},
	isbn = {978-1-60558-752-3},
	url = {http://portal.acm.org/citation.cfm?doid=1629575.1629606},
	doi = {10.1145/1629575.1629606},
	shorttitle = {Fabric},
	abstract = {Fabric is a new system and language for building secure distributed information systems. It is a decentralized system that allows heterogeneous network nodes to securely share both information and computation resources despite mutual distrust. Its high-level programming language makes distribution and persistence largely transparent to programmers. Fabric supports data-shipping and functionshipping styles of computation: both computation and information can move between nodes to meet security requirements or to improve performance. Fabric provides a rich, Java-like object model, but data resources are labeled with conﬁdentiality and integrity policies that are enforced through a combination of compile-time and run-time mechanisms. Optimistic, nested transactions ensure consistency across all objects and nodes. A peer-to-peer dissemination layer helps to increase availability and to balance load. Results from applications built using Fabric suggest that Fabric has a clean, concise programming model, offers good performance, and enforces security.},
	eventtitle = {the {ACM} {SIGOPS} 22nd symposium},
	pages = {321},
	booktitle = {Proceedings of the {ACM} {SIGOPS} 22nd symposium on Operating systems principles - {SOSP} '09},
	publisher = {{ACM} Press},
	author = {Liu, Jed and George, Michael D. and Vikram, K. and Qi, Xin and Waye, Lucas and Myers, Andrew C.},
	urldate = {2020-09-28},
	date = {2009},
	langid = {english},
}

@thesis{katkalov_modellgetriebener_2017,
	title = {Ein modellgetriebener Ansatz zur Entwicklung informationsflusssicherer Systeme},
	institution = {University of Augsburg},
	type = {phdthesis},
	author = {Katkalov, Kuzman},
	date = {2017},
	langid = {german},
}

@inproceedings{katkalov_model-driven_2013,
	location = {Alexandria, {VA}, {USA}},
	title = {Model-Driven Development of Information Flow-Secure Systems with {IFlow}},
	isbn = {978-0-7695-5137-1},
	url = {http://ieeexplore.ieee.org/document/6693311/},
	doi = {10.1109/SocialCom.2013.14},
	abstract = {In our increasingly interconnected world, privacy can seem like an unattainable goal. We are surrounded by countless devices and web services that acquire and collect our personal data as we interact with them. In many cases, the conﬁdentiality of such data is not guaranteed and is frequently (if not always intentionally) violated. Smartphone apps and Internet web services in particular are known to often leak their users’ conﬁdential data to other users or (afﬁliated) third parties. We present a novel model-driven approach called {IFlow} that allows the development of distributed applications consisting of mobile apps and web services with secure information ﬂow. In {IFlow}, a {UML} model of an information ﬂow-sensitive application is used to automatically generate deployable app and web service code as well as a formal model. By employing automatic, language-based information ﬂow control as well as interactive veriﬁcation, {IFlow} enables the developer to give veriﬁable guarantees to the user about how his private data is being treated by the application.},
	pages = {51--56},
	booktitle = {2013 International Conference on Social Computing},
	publisher = {{IEEE}},
	author = {Katkalov, Kuzman and Stenzel, Kurt and Borek, Marian and Reif, Wolfgang},
	urldate = {2020-09-28},
	date = {2013},
	langid = {english},
}

@inproceedings{tuma_flaws_2019,
	location = {Hamburg, Germany},
	title = {Flaws in Flows: Unveiling Design Flaws via Information Flow Analysis},
	isbn = {978-1-72810-528-4},
	url = {https://ieeexplore.ieee.org/document/8703905/},
	doi = {10.1109/ICSA.2019.00028},
	shorttitle = {Flaws in Flows},
	eventtitle = {2019 {IEEE} International Conference on Software Architecture ({ICSA})},
	pages = {191--200},
	booktitle = {2019 {IEEE} International Conference on Software Architecture ({ICSA})},
	publisher = {{IEEE}},
	author = {Tuma, Katja and Scandariato, Riccardo and Balliu, Musard},
	urldate = {2020-09-28},
	date = {2019-03},
	langid = {english},
}

@inproceedings{peldszus_secure_2019,
	location = {Munich, Germany},
	title = {Secure Data-Flow Compliance Checks between Models and Code Based on Automated Mappings},
	isbn = {978-1-72812-536-7},
	url = {https://ieeexplore.ieee.org/document/8906984/},
	doi = {10.1109/MODELS.2019.00-18},
	abstract = {During the development of security-critical software, the system implementation must capture the security properties postulated by the architectural design. This paper presents an approach to support secure data-ﬂow compliance checks between design models and code. To iteratively guide the developer in discovering such compliance violations we introduce automated mappings. These mappings are created by searching for correspondences between a design-level model (Security Data Flow Diagram) and an implementation-level model (Program Model). We limit the search space by considering name similarities between model elements and code elements as well as by the use of heuristic rules for matching data-ﬂow structures. The main contributions of this paper are three-fold. First, the automated mappings support the designer in an early discovery of implementation absence, convergence, and divergence with respect to the planned software design. Second, the mappings also support the discovery of secure data-ﬂow compliance violations in terms of illegal asset ﬂows in the software implementation. Third, we present our implementation of the approach as a publicly available Eclipse plugin and its evaluation on ﬁve open source Java projects (including Eclipse secure storage).},
	eventtitle = {2019 {ACM}/{IEEE} 22nd International Conference on Model Driven Engineering Languages and Systems ({MODELS})},
	pages = {23--33},
	publisher = {{IEEE}},
	author = {Peldszus, Sven and Tuma, Katja and Struber, Daniel and Jurjens, Jan and Scandariato, Riccardo},
	urldate = {2020-09-28},
	date = {2019-09},
	langid = {english},
}

@inproceedings{best_model-based_2007,
	location = {Minneapolis, {MN}},
	title = {Model-Based Security Engineering of Distributed Information Systems Using {UMLsec}},
	isbn = {978-0-7695-2828-1},
	url = {https://ieeexplore.ieee.org/document/4222619/},
	doi = {10.1109/ICSE.2007.55},
	abstract = {Given the explosive growth of digitally stored information in modern enterprises, distributed information systems together with search engines are increasingly used in companies. By enabling the user to search all relevant information sources with one single query, however, crucial risks concerning information security arise. In order to make these applications secure, it is not sufﬁcient to penetrateand-patch past system development, but security analysis has to be an integral part of the system design process for such distributed information systems. This work presents the experiences and results of the security analysis of a search engine in the intranet of a German car manufacturer, by making use of an approach to Model-based Security Engineering that is based on the {UML} extension {UMLsec}. The focus lies on the application’s single-sign-on-mechanism, which was analyzed using the {UMLsec} method and tools. Main results of the paper include a ﬁeld report on the employment of the {UMLsec} method in an industrial context as well as indications on its beneﬁts and limitations.},
	eventtitle = {29th International Conference on Software Engineering ({ICSE}'07)},
	pages = {581--590},
	booktitle = {29th International Conference on Software Engineering ({ICSE}'07)},
	publisher = {{IEEE}},
	author = {Best, Bastian and Jurjens, Jan and Nuseibeh, Bashar},
	urldate = {2020-09-28},
	date = {2007-05},
	langid = {english},
}

@incollection{goos_towards_2001,
	location = {Berlin, Heidelberg},
	title = {Towards Development of Secure Systems Using {UMLsec}},
	url = {http://link.springer.com/10.1007/3-540-45314-8_14},
	abstract = {We show how {UML} (the industry standard in object-oriented modelling) can be used to express security requirements during system development. Using the extension mechanisms provided by {UML}, we incorporate standard concepts from formal methods regarding multi-level secure systems and security protocols. These deﬁnitions evaluate diagrams of various kinds and indicate possible vulnerabilities.},
	pages = {187--200},
	booktitle = {Fundamental Approaches to Software Engineering},
	publisher = {Springer Berlin Heidelberg},
	author = {Jürjens, Jan},
	editor = {Hussmann, Heinrich},
	editorb = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan},
	editorbtype = {redactor},
	urldate = {2020-09-28},
	date = {2001},
	langid = {english},
}

@article{brucker_case_2003,
	title = {A Case Study of a Formalized Security Architecture},
	volume = {80},
	issn = {15710661},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1571066104808077},
	doi = {10.1016/S1571-0661(04)80807-7},
	abstract = {{CVS} is a widely known version management system, which can be used for the distributed development of software as well as its distribution from a central database. In this paper, we provide an outline of a formal security analysis of a {CVS}-Server architecture performed in [1]. The analysis is based on an abstract architecture (enforcing a role-based access control on the repository), which is reﬁned to an implementation architecture (based on the usual discretionary access control provided by the {POSIX} environment). Both architectures serve as framework to formulate access control and conﬁdentiality properties.},
	pages = {24--40},
	journaltitle = {Electronic Notes in Theoretical Computer Science},
	shortjournal = {Electronic Notes in Theoretical Computer Science},
	author = {Brucker, Achim D. and Wolff, Burkhart},
	urldate = {2020-09-28},
	date = {2003-08},
	langid = {english},
}

@incollection{hutchison_automated_2004,
	location = {Berlin, Heidelberg},
	title = {Automated Verification of {UMLsec} Models for Security Requirements},
	volume = {3273},
	isbn = {978-3-540-23307-7 978-3-540-30187-5},
	url = {http://link.springer.com/10.1007/978-3-540-30187-5_26},
	abstract = {For model-based development to be a success in practice, it needs to have a convincing added-value associated with its use. Our goal is to provide such added-value by developing tool-support for the analysis of {UML} models against diﬃcult system requirements. Towards this goal, we describe a {UML} veriﬁcation framework supporting the construction of automated requirements analysis tools for {UML} diagrams. The framework is connected to industrial {CASE} tools using {XMI} and allows convenient access to this data and to the human user.},
	pages = {365--379},
	booktitle = {{\textless} {\textless}{UML}{\textgreater} {\textgreater} 2004 - The Unified Modeling Language. Modelling Languages and Applications},
	publisher = {Springer Berlin Heidelberg},
	author = {Jürjens, Jan and Shabalin, Pasha},
	editor = {Baar, Thomas and Strohmeier, Alfred and Moreira, Ana and Mellor, Stephen J.},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-09-28},
	date = {2004},
	langid = {english},
	doi = {10.1007/978-3-540-30187-5_26},
	note = {Series Title: Lecture Notes in Computer Science},
}

@article{simonet_flow_2003,
	title = {Flow Caml in a Nutshell},
	abstract = {Flow Caml is an extension of the Objective Caml language with a type system tracing information ﬂow. It automatically checks information ﬂow within Flow Caml programs, then translates them to regular Objective Caml code that can be compiled by the ordinary compiler to produce secure programs. In this paper, we give a short overview of this system, from a practical viewpoint.},
	pages = {14},
	journaltitle = {Proceedings of the first {APPSEM}-{II} workshop},
	author = {Simonet, Vincent},
	date = {2003},
	langid = {english},
}

@article{landwehr_formal_1981,
	title = {Formal Models for Computer Security},
	volume = {13},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/356850.356852},
	doi = {10.1145/356850.356852},
	pages = {247--278},
	number = {3},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Landwehr, Carl E.},
	urldate = {2020-09-28},
	date = {1981-09},
	langid = {english},
}

@article{pimentel_formal_2008,
	title = {Formal Support to Security Protocol Development: A Survey},
	volume = {12},
	abstract = {Security protocols aim to allow two or more principals to establish a secure communication over a hostile network, such as the Internet. The design of security protocols is particularly error-prone, because it is difficult to anticipate what an intruder may achieve interacting through a number of protocol runs, claiming to be an honest participant. Thus, the verification of security protocols has attracted a lot of interest in the formal methods community and as a result lots of verification techniques/tools, as well as good practices for protocol design, have appeared in the two last decades. In this paper, we describe the state of the art in automated tools that support security protocol development. This mainly involves tools for protocol verification and, to a lesser extent, for protocol synthesis and protocol diagnosis and repair. Also, we give an overview of the most significant principles for the design of security protocols and of the major problems that still need to be addressed in order to ease the development of security protocols.},
	pages = {20},
	number = {1},
	author = {Pimentel, Juan Carlos López and Monroy, Raúl},
	date = {2008},
	langid = {english},
}

@incollection{hutchison_formal_2010,
	location = {Berlin, Heidelberg},
	title = {Formal Verification of Application-Specific Security Properties in a Model-Driven Approach},
	volume = {5965},
	isbn = {978-3-642-11746-6 978-3-642-11747-3},
	url = {http://link.springer.com/10.1007/978-3-642-11747-3_13},
	abstract = {We present a veriﬁcation method that allows to prove security for security-critical systems based on cryptographic protocols. Designing cryptographic protocols is very diﬃcult and error-prone and most tool-based veriﬁcation approaches only consider standard security properties such as secrecy or authenticity. In our opinion, application-speciﬁc security properties give better guarantees. In this paper we illustrate how to verify properties that are relevant for e-commerce applications, e.g. ’The provider of a copying service does not lose money’. This yields a more complex security property that is proven using interactive veriﬁcation. The veriﬁcation of this kind of application-speciﬁc property is part of the {SecureMDD} approach which provides a method to model a security-critical application with {UML} and automatically generates executable code as well as a formal speciﬁcation for interactive veriﬁcation from the {UML} models.},
	pages = {166--181},
	booktitle = {Engineering Secure Software and Systems},
	publisher = {Springer Berlin Heidelberg},
	author = {Moebius, Nina and Stenzel, Kurt and Reif, Wolfgang},
	editor = {Massacci, Fabio and Wallach, Dan and Zannone, Nicola},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2020-09-28},
	date = {2010},
	langid = {english},
	doi = {10.1007/978-3-642-11747-3_13},
	note = {Series Title: Lecture Notes in Computer Science},
}

@inproceedings{moebius_generating_2009,
	location = {Vancouver, {BC}, Canada},
	title = {Generating formal specifications for security-critical applications - A model-driven approach},
	isbn = {978-1-4244-3725-2},
	url = {http://ieeexplore.ieee.org/document/5068461/},
	doi = {10.1109/IWSESS.2009.5068461},
	abstract = {The {SecureMDD} approach aims to generate both, a formal speciﬁcation for veriﬁcation and executable code, from {UML} diagrams. The {UML} models deﬁne the static as well as dynamic components of the system under development. This model-driven approach is focused on security-critical applications that are based on cryptographic protocols, esp. Java Card applications. In this paper we describe the generation of the formal speciﬁcation from the {UML} model which is then used as input for our interactive veriﬁcation system {KIV}. The formal speciﬁcation is based on abstract state machines and algebraic speciﬁcations. It allows to formulate and to prove application-speciﬁc security properties.},
	eventtitle = {2009 {ICSE} Workshop on Software Engineering for Secure Systems ({SESS})},
	pages = {68--74},
	booktitle = {2009 {ICSE} Workshop on Software Engineering for Secure Systems},
	publisher = {{IEEE}},
	author = {Moebius, Nina and Stenzel, Kurt and Reif, Wolfgang},
	urldate = {2020-09-28},
	date = {2009-05},
	langid = {english},
}

@article{sabelfeld_language-based_2003,
	title = {Language-based information-flow security},
	volume = {21},
	issn = {0733-8716},
	url = {http://ieeexplore.ieee.org/document/1159651/},
	doi = {10.1109/JSAC.2002.806121},
	abstract = {Current standard security practices do not provide substantial assurance that the end-to-end behavior of a computing system satisfies important security policies such as confidentiality. An end-to-end confidentiality policy might assert that secret input data cannot be inferred by an attacker through the attacker’s observations of system output; this policy regulates information flow. Conventional security mechanisms such as access control and encryption do not directly address the enforcement of information-flow policies. Recently, a promising new approach has been developed: the use of programming-language techniques for specifying and enforcing information-flow policies. In this paper, we survey the past three decades of research on information-flow security, particularly focusing on work that uses static program analysis to enforce information-flow policies. We give a structured view of recent work in the area and identify some important open challenges.},
	pages = {5--19},
	number = {1},
	journaltitle = {{IEEE} Journal on Selected Areas in Communications},
	shortjournal = {{IEEE} J. Select. Areas Commun.},
	author = {Sabelfeld, A. and Myers, A.C.},
	urldate = {2020-09-28},
	date = {2003-01},
	langid = {english},
}

@article{nicol_model-based_2004,
	title = {Model-based evaluation: from dependability to security},
	volume = {1},
	issn = {1545-5971},
	url = {http://ieeexplore.ieee.org/document/1335467/},
	doi = {10.1109/TDSC.2004.11},
	shorttitle = {Model-based evaluation},
	abstract = {The development of techniques for quantitative, model-based evaluation of computer system dependability has a long and rich history. A wide array of model-based evaluation techniques is now available, ranging from combinatorial methods, which are useful for quick, rough-cut analyses, to state-based methods, such as Markov reward models, and detailed, discrete-event simulation. The use of quantitative techniques for security evaluation is much less common, and has typically taken the form of formal analysis of small parts of an overall design, or experimental red team-based approaches. Alone, neither of these approaches is fully satisfactory, and we argue that there is much to be gained through the development of a sound model-based methodology for quantifying the security one can expect from a particular design. In this work, we survey existing model-based techniques for evaluating system dependability, and summarize how they are now being extended to evaluate system security. We find that many techniques from dependability evaluation can be applied in the security domain, but that significant challenges remain, largely due to fundamental differences between the accidental nature of the faults commonly assumed in dependability evaluation, and the intentional, human nature of cyber attacks.},
	pages = {48--65},
	number = {1},
	journaltitle = {{IEEE} Transactions on Dependable and Secure Computing},
	shortjournal = {{IEEE} Trans.Dependable and Secure Comput.},
	author = {Nicol, D.M. and Sanders, W.H. and Trivedi, K.S.},
	urldate = {2020-09-28},
	date = {2004-01},
	langid = {english},
}

@article{yu_formal_2003,
	title = {Formal Software Architecture Design of Secure Distributed Systems},
	abstract = {This paper proposes a formal software architecture design method for distributed systems. The underlying formalism is the Software Architecture Model ({SAM}), a general software architecture model combining Petri nets and temporal logic. We present a two-tier structure for architectural modeling. The upper level models the workﬂow of a distributed system. Each place at the upper level is a super-place that corresponds to a lower level Petri net. An initial distributed architecture can be directly derived from the upper level model. Security of the architecture is checked using the dependence relation of the model. Security policies are enforced by systematically reconstructing the initial architecture. A Travel Planner is used as the example to demonstrate our approach to secure software architecture design of distributed systems.},
	pages = {9},
	journaltitle = {{SEKE}},
	author = {Yu, Huiqun and He, Xudong and Gao, Shu and Deng, Yi},
	date = {2003},
	langid = {english},
}

@article{he_formally_2004,
	title = {Formally analyzing software architectural specifications using {SAM}},
	volume = {71},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121202000870},
	doi = {10.1016/S0164-1212(02)00087-0},
	abstract = {In the past decade, software architecture has emerged as a major research area in software engineering. Many architecture description languages have been proposed and some analysis techniques have also been explored. In this paper, we present a graphical formal software architecture description model called software architecture model ({SAM}). {SAM} is a general software architecture development framework based on two complementary formalisms––Petri nets and temporal logic. Petri nets are used to visualize the structure and model the behavior of software architectures while temporal logic is used to specify the required properties of software architectures. These two formal methods are nicely integrated through the {SAM} software architecture framework. Furthermore, {SAM} provides the ﬂexibility to choose diﬀerent compatible Petri net and temporal logic models according to the nature of system under study. Most importantly, {SAM} supports formal analysis of software architecture properties in a variety of well-established techniques––simulation, reachability analysis, model checking, and interactive proving. In this paper, we show how to formally analyze {SAM} software architecture speciﬁcations using two well-known techniques––symbolic model checking with tool Symbolic Model Veriﬁer, and theorem proving with tool {STeP}.},
	pages = {11--29},
	number = {1},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {He, Xudong and Yu, Huiqun and Shi, Tianjun and Ding, Junhua and Deng, Yi},
	urldate = {2020-09-28},
	date = {2004-04},
	langid = {english},
}

@incollection{goos_umlsec_2002,
	location = {Berlin, Heidelberg},
	title = {{UMLsec}: Extending {UML} for Secure Systems Development},
	volume = {2460},
	url = {http://link.springer.com/10.1007/3-540-45800-X_32},
	shorttitle = {{UMLsec}},
	abstract = {Developing secure-critical systems is diﬃcult and there are many well-known examples of security weaknesses exploited in practice. Thus a sound methodology supporting secure systems development is urgently needed.},
	pages = {412--425},
	booktitle = {{UML} 2002 — The Unified Modeling Language},
	publisher = {Springer Berlin Heidelberg},
	author = {Jürjens, Jan},
	editor = {Jézéquel, Jean-Marc and Hussmann, Heinrich and Cook, Stephen},
	editorb = {Goos, Gerhard and Hartmanis, Juris and van Leeuwen, Jan},
	editorbtype = {redactor},
	urldate = {2020-09-28},
	date = {2002},
	langid = {english},
}

@article{dai_survey_2007,
	title = {A Survey of Modelling and Analysis Approaches for Architecting Secure Software Systems},
	pages = {12},
	author = {Dai, Lirong and Cooper, Kendra},
	date = {2007},
	langid = {english},
}

@inproceedings{kasal_model-driven_2011,
	location = {Kauai, {HI}},
	title = {Model-Driven Development Meets Security: An Evaluation of Current Approaches},
	isbn = {978-1-4244-9618-1},
	url = {http://ieeexplore.ieee.org/document/5719002/},
	doi = {10.1109/HICSS.2011.310},
	shorttitle = {Model-Driven Development Meets Security},
	abstract = {Although our society is critically dependent on software systems, these systems are mainly secured by protection mechanisms during operation instead of considering security issues during software design. Deﬁciencies in software design are the main reasons for security incidents, resulting in severe economic consequences for (i) the organizations using the software and (ii) the development companies. Lately, model-driven development has been proposed in order to increase the quality and thereby the security of software systems. This paper evaluates current efforts that position security as a fundamental element in model-driven development, highlights their deﬁciencies and identiﬁes current research challenges. The evaluation shows that applying special-purpose methods to particular aspects of the problem is more suitable than applying generic ones, since (i) the problem can be represented on the proper abstraction level, (ii) the user can build on the knowledge of experts, and (iii) the available tools are more efﬁcient and powerful.},
	eventtitle = {2011 44th Hawaii International Conference on System Sciences ({HICSS} 2011)},
	pages = {1--9},
	booktitle = {2011 44th Hawaii International Conference on System Sciences},
	publisher = {{IEEE}},
	author = {Kasal, K and Heurix, J and Neubauer, T},
	urldate = {2020-09-28},
	date = {2011-01},
	langid = {english},
}

@article{heitmeyer_formal_1999,
	title = {Formal Methods for Developing Software Speci cations: Paths to Wider Usage},
	abstract = {Although many formal methods have been proposed for improving the quality of software speci cations, a number of barriers to widespread use of these methods remain. This paper describes four of these barriers{\textbar}failure to scale, unnatural interfaces, limited analysis capabilities, and insu cient tool integration{\textbar}and suggests some promising approaches for overcoming them. These approaches include automated abstraction, user interfaces designed for ease of use, and the application of powerful decision procedures. To illustrate the barriers and approaches to overcoming them, several examples are presented based on the {SCR} (Software Cost Reduction) requirements method.},
	pages = {8},
	journaltitle = {{PDPTA}},
	author = {Heitmeyer, Constance},
	date = {1999},
	langid = {english},
}

@inproceedings{goguen_security_1982,
	title = {Security Policies and Security Models},
	doi = {10.1109/SP.1982.10014},
	abstract = {We assune that the reader is familiar with the ubiquity of information in the modern world and is sympathetic with the need for restricting rights to read, add, modify, or delete information in specific contexts. This need is particularly acute for systems having computers as significant components.},
	eventtitle = {1982 {IEEE} Symposium on Security and Privacy},
	pages = {11--11},
	booktitle = {1982 {IEEE} Symposium on Security and Privacy},
	author = {Goguen, J. A. and Meseguer, J.},
	date = {1982-04},
	note = {{ISSN}: 1540-7993},
	keywords = {Automata, Computational modeling, Computers, Data models, Finite element methods, Mathematical model, Message systems},
}

@inproceedings{garlan_software_2010,
	location = {Santa Fe, New Mexico, {USA}},
	title = {Software engineering in an uncertain world},
	isbn = {978-1-4503-0427-6},
	url = {http://portal.acm.org/citation.cfm?doid=1882362.1882389},
	doi = {10.1145/1882362.1882389},
	abstract = {In this paper, we argue that the reality of today’s software systems requires us to consider uncertainty as a first-class concern in the design, implementation, and deployment of those systems. We further argue that this induces a paradigm shift, and a number of research challenges that must be addressed.},
	eventtitle = {the {FSE}/{SDP} workshop},
	pages = {125},
	booktitle = {Proceedings of the {FSE}/{SDP} workshop on Future of software engineering research - {FoSER} '10},
	publisher = {{ACM} Press},
	author = {Garlan, David},
	urldate = {2020-09-28},
	date = {2010},
	langid = {english},
}

@article{refsgaard_framework_2006,
	title = {A framework for dealing with uncertainty due to model structure error},
	volume = {29},
	issn = {0309-1708},
	url = {http://www.sciencedirect.com/science/article/pii/S0309170805002903},
	doi = {10.1016/j.advwatres.2005.11.013},
	abstract = {Although uncertainty about structures of environmental models (conceptual uncertainty) is often acknowledged to be the main source of uncertainty in model predictions, it is rarely considered in environmental modelling. Rather, formal uncertainty analyses have traditionally focused on model parameters and input data as the principal source of uncertainty in model predictions. The traditional approach to model uncertainty analysis, which considers only a single conceptual model, may fail to adequately sample the relevant space of plausible conceptual models. As such, it is prone to modelling bias and underestimation of predictive uncertainty. In this paper we review a range of strategies for assessing structural uncertainties in models. The existing strategies fall into two categories depending on whether field data are available for the predicted variable of interest. To date, most research has focussed on situations where inferences on the accuracy of a model structure can be made directly on the basis of field data. This corresponds to a situation of ‘interpolation’. However, in many cases environmental models are used for ‘extrapolation’; that is, beyond the situation and the field data available for calibration. In the present paper, a framework is presented for assessing the predictive uncertainties of environmental models used for extrapolation. It involves the use of multiple conceptual models, assessment of their pedigree and reflection on the extent to which the sampled models adequately represent the space of plausible models.},
	pages = {1586--1597},
	number = {11},
	journaltitle = {Advances in Water Resources},
	shortjournal = {Advances in Water Resources},
	author = {Refsgaard, Jens Christian and van der Sluijs, Jeroen P. and Brown, James and van der Keur, Peter},
	urldate = {2020-09-28},
	date = {2006-11},
	langid = {english},
	keywords = {Conceptual uncertainty, Environmental modelling, Model error, Model structure, Pedigree, Scenario analysis},
}

@inproceedings{perez-palacin_uncertainties_2014,
	location = {New York, {NY}, {USA}},
	title = {Uncertainties in the modeling of self-adaptive systems: a taxonomy and an example of availability evaluation},
	isbn = {978-1-4503-2733-6},
	url = {https://doi.org/10.1145/2568088.2568095},
	doi = {10.1145/2568088.2568095},
	series = {{ICPE} '14},
	shorttitle = {Uncertainties in the modeling of self-adaptive systems},
	abstract = {The complexity of modern software systems has grown enormously in the past years with users always demanding for new features and better quality of service. Besides, software is often embedded in dynamic contexts, where requirements, environment assumptions, and usage profiles continuously change. As an answer to this need, it has been proposed the usage of self-adaptive systems. Self-adaptation endows a system with the capability to accommodate its execution to different contexts in order to achieve continuous satisfaction of requirements. Often, self-adaptation process also makes use of runtime model evaluations to decide the changes in the system. However, even at runtime, context information that can be managed by the system is not complete or accurate; i.e, it is still subject to some uncertainties. This work motivates the need for the consideration of the concept of uncertainty in the model-based evaluation as a primary actor, classifies the avowed uncertainties of self-adaptive systems, and illustrates examples of how different types of uncertainties are present in the modeling of system characteristics for availability requirement satisfaction.},
	pages = {3--14},
	booktitle = {Proceedings of the 5th {ACM}/{SPEC} international conference on Performance engineering},
	publisher = {Association for Computing Machinery},
	author = {Perez-Palacin, Diego and Mirandola, Raffaela},
	urldate = {2020-09-28},
	date = {2014},
	keywords = {models, sef-adaptive software, uncertainty},
}

@article{zadeh_fuzzy_1965,
	title = {Fuzzy sets},
	volume = {8},
	issn = {0019-9958},
	url = {http://www.sciencedirect.com/science/article/pii/S001999586590241X},
	doi = {10.1016/S0019-9958(65)90241-X},
	abstract = {A fuzzy set is a class of objects with a continuum of grades of membership. Such a set is characterized by a membership (characteristic) function which assigns to each object a grade of membership ranging between zero and one. The notions of inclusion, union, intersection, complement, relation, convexity, etc., are extended to such sets, and various properties of these notions in the context of fuzzy sets are established. In particular, a separation theorem for convex fuzzy sets is proved without requiring that the fuzzy sets be disjoint.},
	pages = {338--353},
	number = {3},
	journaltitle = {Information and Control},
	shortjournal = {Information and Control},
	author = {Zadeh, L. A.},
	urldate = {2020-09-28},
	date = {1965-06-01},
	langid = {english},
}

@article{kiureghian_aleatory_2009,
	title = {Aleatory or epistemic? Does it matter?},
	volume = {31},
	issn = {0167-4730},
	url = {http://www.sciencedirect.com/science/article/pii/S0167473008000556},
	doi = {10.1016/j.strusafe.2008.06.020},
	series = {Risk Acceptance and Risk Communication},
	shorttitle = {Aleatory or epistemic?},
	abstract = {The sources and characters of uncertainties in engineering modeling for risk and reliability analyses are discussed. While many sources of uncertainty may exist, they are generally categorized as either aleatory or epistemic. Uncertainties are characterized as epistemic, if the modeler sees a possibility to reduce them by gathering more data or by refining models. Uncertainties are categorized as aleatory if the modeler does not foresee the possibility of reducing them. From a pragmatic standpoint, it is useful to thus categorize the uncertainties within a model, since it then becomes clear as to which uncertainties have the potential of being reduced. More importantly, epistemic uncertainties may introduce dependence among random events, which may not be properly noted if the character of uncertainties is not correctly modeled. Influences of the two types of uncertainties in reliability assessment, codified design, performance-based engineering and risk-based decision-making are discussed. Two simple examples demonstrate the influence of statistical dependence arising from epistemic uncertainties on systems and time-variant reliability problems.},
	pages = {105--112},
	number = {2},
	journaltitle = {Structural Safety},
	shortjournal = {Structural Safety},
	author = {Kiureghian, Armen Der and Ditlevsen, Ove},
	urldate = {2020-09-28},
	date = {2009-03-01},
	langid = {english},
	keywords = {Aleatory, Epistemic, Ergodicity, Parameter uncertainty, Predictive models, Probability distribution choice, Statistical dependence, Systems, Time-variant reliability, Uncertainty},
}

@article{refsgaard_uncertainty_2007,
	title = {Uncertainty in the environmental modelling process – A framework and guidance},
	volume = {22},
	issn = {1364-8152},
	url = {http://www.sciencedirect.com/science/article/pii/S1364815207000266},
	doi = {10.1016/j.envsoft.2007.02.004},
	abstract = {A terminology and typology of uncertainty is presented together with a framework for the modelling process, its interaction with the broader water management process and the role of uncertainty at different stages in the modelling processes. Brief reviews have been made of 14 different (partly complementary) methods commonly used in uncertainty assessment and characterisation: data uncertainty engine ({DUE}), error propagation equations, expert elicitation, extended peer review, inverse modelling (parameter estimation), inverse modelling (predictive uncertainty), Monte Carlo analysis, multiple model simulation, {NUSAP}, quality assurance, scenario analysis, sensitivity analysis, stakeholder involvement and uncertainty matrix. The applicability of these methods has been mapped according to purpose of application, stage of the modelling process and source and type of uncertainty addressed. It is concluded that uncertainty assessment is not just something to be added after the completion of the modelling work. Instead uncertainty should be seen as a red thread throughout the modelling study starting from the very beginning, where the identification and characterisation of all uncertainty sources should be performed jointly by the modeller, the water manager and the stakeholders.},
	pages = {1543--1556},
	number = {11},
	journaltitle = {Environmental Modelling \& Software},
	shortjournal = {Environmental Modelling \& Software},
	author = {Refsgaard, Jens Christian and van der Sluijs, Jeroen P. and Højberg, Anker Lajer and Vanrolleghem, Peter A.},
	urldate = {2020-09-28},
	date = {2007-11},
	langid = {english},
	keywords = {Uncertainty, Catchment modelling, Integrated water resources management, Water framework directive},
}

@article{berzal_managing_2007,
	title = {Managing fuzziness on conventional object-oriented platforms},
	volume = {22},
	rights = {Copyright © 2007 Wiley Periodicals, Inc., A Wiley Company},
	issn = {1098-111X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.20228},
	doi = {10.1002/int.20228},
	abstract = {During the last few years, many database researchers have aimed their efforts at extending the object-oriented model for dealing with different kinds of imperfect information. Some of these scholars have used the Fuzzy Set Theory to deal with imperfection because it has proved to be useful in problems where imprecision and uncertainty play important roles. This article describes an architecture that can be used to develop a fuzzy object-oriented system on top of an existing classical one. This article also introduces a general framework as the basis for managing fuzziness in conventional object-oriented systems. Foodbi, a fuzzy object-oriented database interface, is presented as a prototype that allows the creation of fuzzy object-oriented schemata that can be translated into sets of standard Java classes. © 2007 Wiley Periodicals, Inc. Int J Int Syst 22: 781–803, 2007.},
	pages = {781--803},
	number = {7},
	journaltitle = {International Journal of Intelligent Systems},
	author = {Berzal, F. and Marín, N. and Pons, O. and Vila, M. A.},
	urldate = {2020-09-28},
	date = {2007},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.20228},
}

@inproceedings{fernandez_security_2007,
	location = {Berlin, Heidelberg},
	title = {Security Patterns for Physical Access Control Systems},
	isbn = {978-3-540-73538-0},
	doi = {10.1007/978-3-540-73538-0_19},
	series = {Lecture Notes in Computer Science},
	abstract = {Physical security has received increased attention after 9/11. However, access control to physical units has not been explored much. On the other hand, there is a rich literature on access control to information. These two areas appear converging as seen by recent products and studies. However, use of different notations and implementation details make this convergence harder. We need to try to take this convergence at a more abstract level first. Although introduced about 10 years ago, security patterns have recently become accepted by industry and two books on this topic have appeared recently. Security patterns for information access control have appeared but now we extend this concept to access for physical units. The unification of information and physical access control is just beginning but the strong requirements of infrastructure protection will make this convergence to happen rapidly. Examining existing systems, industry standards and government regulations, we describe, in the form of patterns, the core set of features a physical access control system should have. The paper illustrates the structure and use of these patterns.},
	pages = {259--274},
	booktitle = {Data and Applications Security {XXI}},
	publisher = {Springer},
	author = {Fernandez, Eduardo B. and Ballesteros, Jose and Desouza-Doucet, Ana C. and Larrondo-Petrie, Maria M.},
	editor = {Barker, Steve and Ahn, Gail-Joon},
	date = {2007},
	langid = {english},
	keywords = {access control, intelligent buildings, physical access control, security, software patterns},
}

@incollection{majumder_taxonomy_2014,
	location = {London},
	title = {Taxonomy and Classification of Access Control Models for Cloud Environments},
	isbn = {978-1-4471-6452-4},
	url = {https://doi.org/10.1007/978-1-4471-6452-4_2},
	series = {Computer Communications and Networks},
	abstract = {Cloud computing is an emerging and highly attractive technology due to its inherent efficiency, cost-effectiveness, flexibility, scalability and pay-per-use characteristics. But alongside these advantages, many new problems have also surfaced and some of these issues have become a cause of grave concern. One of the existing problems that have become critical in the cloud environment is the issue of access control and security. Access control refers to a policy that authenticates a user and permits the authorized user to access data and other resources of cloud-based systems. In access control, there are several restrictions and rules that need to be followed by the users before they can access any kind of data or resource from the cloud-based servers. In this context, there are many access control models suggested by researchers that currently exist. In this chapter, a brief discussion of the various access control models has been presented. Moreover, the taxonomy of access control schemes has also been introduced. Finally, based on the analysis of the mechanisms adapted therein, the access control models are classified into different classes of the proposed taxonomy.},
	pages = {23--53},
	booktitle = {Continued Rise of the Cloud: Advances and Trends in Cloud Computing},
	publisher = {Springer},
	author = {Majumder, Abhishek and Namasudra, Suyel and Nath, Samir},
	editor = {Mahmood, Zaigham},
	urldate = {2020-09-30},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-1-4471-6452-4_2},
	keywords = {Access control models, Centralized, Classification, Cloud environment, Collaborative, Identity-based, Non identity-based, Taxonomy},
}

@inproceedings{ahmad_access_2011,
	title = {Access control taxonomy for social networks},
	doi = {10.1109/ISIAS.2011.6122829},
	abstract = {Social networks are online platforms where users form relationships with others by sharing resources. Access control for these social networks is different from other systems as it fulfills the social requirements of community as well as the technical requirements of the system. This paper presents a classification of access control models for social networks based on lattice taxonomy where axes represent the properties of the models. The proposed taxonomy has eight axes representing: requestor identity, mapping authority, resource control, relationship management, credential distribution, access control decisions, rights delegation and transparency. Analysis of existing models using this taxonomy highlights the tradeoffs between user control, state distribution and social needs. The taxonomy reveals that various interesting features of social networks have not been implemented yet and there is a gap between the social requirements and access control features of social networks.},
	eventtitle = {2011 7th International Conference on Information Assurance and Security ({IAS})},
	pages = {256--261},
	booktitle = {2011 7th International Conference on Information Assurance and Security ({IAS})},
	author = {Ahmad, Adnan and Whitworth, Brian},
	date = {2011-12},
	keywords = {Taxonomy, Access control, Access Control, access control model classification, authorisation, Communities, Control systems, credential distribution, lattice taxonomy, Lattices, mapping authority, online platforms, relationship management, resource control, resource sharing, rights delegation, Servers, Social network services, social networking (online), social networks, Social networks, state distribution, user control},
}

@inproceedings{cheng_fuzzy_2007,
	title = {Fuzzy Multi-Level Security: An Experiment on Quantified Risk-Adaptive Access Control},
	doi = {10.1109/SP.2007.21},
	shorttitle = {Fuzzy Multi-Level Security},
	pages = {222--230},
	booktitle = {2007 {IEEE} Symposium on Security and Privacy ({SP} '07)},
	author = {Cheng, Pau-Chen and Rohatgi, Pankaj and Keser, Claudia and Karger, Paul A. and Wagner, Grant M. and Reninger, Angela Schuett},
	date = {2007-05},
	keywords = {Uncertainty, Access control, authorisation, adaptive control, Adaptive control, Bell-Lapadula model, Control system synthesis, fuzzy control, Fuzzy control, Fuzzy logic, fuzzy logic control system, fuzzy multilevel security, Fuzzy systems, Multilevel systems, Programmable control, quantified risk-adaptive access control, risk analysis, Security},
}

@inproceedings{ni_risk-based_2010,
	location = {New York, {NY}, {USA}},
	title = {Risk-based access control systems built on fuzzy inferences},
	isbn = {978-1-60558-936-7},
	url = {https://doi.org/10.1145/1755688.1755719},
	doi = {10.1145/1755688.1755719},
	series = {{ASIACCS} '10},
	abstract = {Fuzzy inference is a promising approach to implement risk-based access control systems. However, its application to access control raises some novel problems that have not been yet investigated. First, because there are many different fuzzy operations, one must choose the fuzzy operations that best address security requirements. Second, risk-based access control, though it improves information flow and better addresses requirements from critical organizations, may result in damages by malicious users before mitigating steps are taken. Third, the scalability of a fuzzy inference-based access control system is questionable. The time required by a fuzzy inference engine to estimate risks may be quite high especially when there are tens of parameters and hundreds of fuzzy rules. However, an access control system may need to serve hundreds or thousands of users. In this paper, we investigate these issues and present our solutions or answers to them.},
	pages = {250--260},
	booktitle = {Proceedings of the 5th {ACM} Symposium on Information, Computer and Communications Security},
	publisher = {Association for Computing Machinery},
	author = {Ni, Qun and Bertino, Elisa and Lobo, Jorge},
	urldate = {2020-09-30},
	date = {2010-04},
	keywords = {access control, fuzzy inference, risk},
}

@inproceedings{mahalle_fuzzy_2013,
	title = {A fuzzy approach to trust based access control in internet of things},
	doi = {10.1109/VITAE.2013.6617083},
	abstract = {In the Internet of thing ({IoT}), the activities of daily life are supported by a multitude of heterogeneous, loosely coupled ubiquitous devices. Traditional access control model are not suitable to the nomadic, decentralized and dynamic scenarios in the {IoT} where identities are not known in advance. This makes the trust management in {IoT} more promising to address the access control issues .This paper present a Fuzzy approach to the Trust Based Access Control ({FBAC}) with the notion of trust levels for identity management. The presented fuzzy approach for trust calculations deals with the linguistic information of devices to address access control in the {IoT}. The simulation result shows that the fuzzy approach for trust based access control guarantees scalability ad it is energy efficient. This paper also proposes {FTBAC} framework or trust based dynamic access control in distributed {IoT}. {FTBAC} framework i a flexible and scalable a increasing number o devices do not affect the functioning and performance.},
	eventtitle = {Wireless {VITAE} 2013},
	pages = {1--5},
	booktitle = {Wireless {VITAE} 2013},
	author = {Mahalle, Parikshit N. and Thakre, Pravin A. and Prasad, Neeli Rashmi and Prasad, Ramjee},
	date = {2013-06},
	keywords = {Access Control, authorisation, fuzzy control, energy efficient, {FTBAC} framework, fuzzy approach, Fuzzy Rule Base, identity management, Identity Management, Internet of Things, Trust, trust based access control, trust management, trusted computing, ubiquitous devices},
}

@article{martinez-garcia_fuzzy_2011,
	title = {Fuzzy Role-Based Access Control},
	volume = {111},
	issn = {0020-0190},
	url = {http://www.sciencedirect.com/science/article/pii/S0020019011000500},
	doi = {10.1016/j.ipl.2011.02.010},
	abstract = {{RBAC} (Role-Based Access Control) is a widely used access control model, which reduces the maintenance cost of classical identity-based access control. However, despite the benefits of {RBAC}, there are environments in which {RBAC} can hardly be applied. We present {FRBAC} (Fuzzy Role-Based Access Control), a generalization of {RBAC} through fuzzy relations that extends the applicability of {RBAC} to environments where authorization-related information is vague. Moreover, {FRBAC} deals with environments where the actions that can be executed over the resources have a fractional meaning, as data lying in databases and risk-based access control.},
	pages = {483--487},
	number = {10},
	journaltitle = {Information Processing Letters},
	shortjournal = {Information Processing Letters},
	author = {Martínez-García, Carles and Navarro-Arribas, Guillermo and Borrell, Joan},
	urldate = {2020-09-30},
	date = {2011-04},
	langid = {english},
	keywords = {Uncertainty, Databases, Role-Based Access Control, Safety/security in digital systems},
}

@article{hosmer_using_1992,
	title = {Using fuzzy logic to represent security policies in the multipolicy paradigm},
	volume = {10},
	issn = {0277-920X},
	url = {https://dl.acm.org/doi/10.1145/152399.152403},
	doi = {10.1145/152399.152403},
	abstract = {Fuzzy logic is a promising way to represent non-traditional policies, like privacy, integrity and availability. Its vagueness and use of continuous data fit better with many non-military enterprise policy requirements. The theoretical foundation needed for development and assurance of computer systems has been worked out in an extensive literature, but more attention needs to be paid to its use in trusted systems. It is appropriate to use fuzzy logic for implementing aspects of the Multipolicy Paradigm.},
	pages = {12--21},
	number = {4},
	journaltitle = {{ACM} {SIGSAC} Review},
	shortjournal = {{SIGSAC} Rev.},
	author = {Hosmer, Hilary H.},
	urldate = {2020-09-30},
	date = {1992},
	langid = {english},
}

@article{firesmith_engineering_2003,
	title = {Engineering Security Requirements},
	volume = {2},
	abstract = {Most requirements engineers are poorly trained to elicit, analyze, and specify security requirements, often confusing them with the architectural security mechanisms that are traditionally used to fulfill them. They thus end up specifying architecture and design constraints rather than true security requirements. This article defines the different types of security requirements and provides associated examples and guildlines with the intent of enabling requirements engineers to adequately specify security requirements without unnecessarily constraining the security and architecture teams from using the most appropriate security mechanisms for the job. 1 {SECURITY} {REQUIREMENTS} The engineering of the requirements for a business, system or software application, component, or (contact, data, or reuse) center involves far more than merely engineering its functional requirements. One must also engineer its quality, data, and interface requirements as well as its architectural, design, implementation, and testing constraints. Whereas some requirements engineers might remember to elicit, analyze, specify, and},
	pages = {53--68},
	journaltitle = {Journal of Object Technology},
	author = {Firesmith, Donald G. and Consulting, Firesmith},
	date = {2003},
}

@inproceedings{almorsy_automated_2013,
	title = {Automated software architecture security risk analysis using formalized signatures},
	doi = {10.1109/ICSE.2013.6606612},
	abstract = {Reviewing software system architecture to pinpoint potential security flaws before proceeding with system development is a critical milestone in secure software development lifecycles. This includes identifying possible attacks or threat scenarios that target the system and may result in breaching of system security. Additionally we may also assess the strength of the system and its security architecture using well-known security metrics such as system attack surface, Compartmentalization, least-privilege, etc. However, existing efforts are limited to specific, predefined security properties or scenarios that are checked either manually or using limited toolsets. We introduce a new approach to support architecture security analysis using security scenarios and metrics. Our approach is based on formalizing attack scenarios and security metrics signature specification using the Object Constraint Language ({OCL}). Using formal signatures we analyse a target system to locate signature matches (for attack scenarios), or to take measurements (for security metrics). New scenarios and metrics can be incorporated and calculated provided that a formal signature can be specified. Our approach supports defining security metrics and scenarios at architecture, design, and code levels. We have developed a prototype software system architecture security analysis tool. To the best of our knowledge this is the first extensible architecture security risk analysis tool that supports both metric-based and scenario-based architecture security analysis. We have validated our approach by using it to capture and evaluate signatures from the {NIST} security principals and attack scenarios defined in the {CAPEC} database.},
	eventtitle = {2013 35th International Conference on Software Engineering ({ICSE})},
	pages = {662--671},
	booktitle = {2013 35th International Conference on Software Engineering ({ICSE})},
	author = {Almorsy, Mohamed and Grundy, John and Ibrahim, Amani S.},
	date = {2013-05},
	note = {{ISSN}: 1558-1225},
	keywords = {Security, Architecture Security Risk analysis, automated software architecture security risk analysis, {CAPEC} database, Common attack patterns enumeration and classification ({CAPEC}), Computer architecture, digital signatures, Formal attack patterns specification, formal signatures, formalized signatures, Measurement, metric-based architecture security analysis, {NIST} security principals, object constraint language, object-oriented languages, {OCL}, Risk analysis, scenario-based architecture security analysis, secure software development lifecycles, security architecture, security flaws, security metrics signature specification, signature matches, Software, software architecture, Software architecture, software metrics, Software security, system development, system security, Unified modeling language},
}

@inproceedings{samarati_access_2001,
	location = {Berlin, Heidelberg},
	title = {Access Control: Policies, Models, and Mechanisms},
	isbn = {978-3-540-45608-7},
	doi = {10.1007/3-540-45608-2_3},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Access Control},
	abstract = {Access control is the process of mediating every request to resources and data maintained by a system and determining whether the request should be granted or denied. The access control decision is enforced by a mechanism implementing regulations established by a security policy. Different access control policies can be applied, corresponding to different criteria for defining what should, and what should not, be allowed, and, in some sense, to different definitions of what ensuring security means. In this chapter we investigate the basic concepts behind access control design and enforcement, and point out different security requirements that may need to be taken into consideration. We discuss several access control policies, and models formalizing them, that have been proposed in the literature or that are currently under investigation.},
	pages = {137--196},
	booktitle = {Foundations of Security Analysis and Design},
	publisher = {Springer},
	author = {Samarati, Pierangela and de Vimercati, Sabrina Capitani},
	editor = {Focardi, Riccardo and Gorrieri, Roberto},
	date = {2001},
	langid = {english},
	keywords = {Access Control, Access Control Model, Access Control Policy, Covert Channel, Trojan Horse},
}

@article{sandhu_access_1994,
	title = {Access control: principle and practice},
	volume = {32},
	issn = {1558-1896},
	doi = {10.1109/35.312842},
	shorttitle = {Access control},
	abstract = {Access control constrains what a user can do directly, as well as what programs executing on behalf of the users are allowed to do. In this way access control seeks to prevent activity that could lead to a breach of security. This article explains access control and its relationship to other security services such as authentication, auditing, and administration. It then reviews the access matrix model and describes different approaches to implementing the access matrix in practical systems, and follows with a discussion of access control policies commonly found in current systems, and a brief consideration of access control administration.{\textless}{\textgreater}},
	pages = {40--48},
	number = {9},
	journaltitle = {{IEEE} Communications Magazine},
	author = {Sandhu, R.S. and Samarati, P.},
	date = {1994-09},
	keywords = {access control, Access control, Control systems, Databases, access control administration, access matrix model, administration, auditing, authentication, Authentication, Authorization, computer networks, Computer security, Computerized monitoring, Data security, Information security, message authentication, security services, Software performance},
}

@inproceedings{ntentos_supporting_2019,
	location = {Cham},
	title = {Supporting Architectural Decision Making on Data Management in Microservice Architectures},
	isbn = {978-3-030-29983-5},
	doi = {10.1007/978-3-030-29983-5_2},
	series = {Lecture Notes in Computer Science},
	abstract = {Today many service-based systems follow the microservice architecture style. As microservices are used to build distributed systems and promote architecture properties such as independent service development, polyglot technology stacks including polyglot persistence, and loosely coupled dependencies, architecting data management is crucial in most microservice architectures. Many patterns and practices for microservice data management architectures have been proposed, but are today mainly informally discussed in the so-called “grey literature”: practitioner blogs, experience reports, and system documentations. As a result, the architectural knowledge is scattered across many knowledge sources that are usually based on personal experiences, inconsistent, and, when studied on their own, incomplete. In this paper we report on a qualitative, in-depth study of 35 practitioner descriptions of best practices and patterns on microservice data management architectures. Following a model-based qualitative research method, we derived a formal architecture decision model containing 325 elements and relations. Comparing the completeness of our model with an existing pattern catalog, we conclude that our architectural decision model substantially reduces the effort needed to sufficiently understand microservice data management decisions, as well as the uncertainty in the design process.},
	pages = {20--36},
	booktitle = {Software Architecture},
	publisher = {Springer International Publishing},
	author = {Ntentos, Evangelos and Zdun, Uwe and Plakidas, Konstantinos and Schall, Daniel and Li, Fei and Meixner, Sebastian},
	editor = {Bures, Tomas and Duchien, Laurence and Inverardi, Paola},
	date = {2019},
	langid = {english},
}

@inproceedings{jansen_software_2005,
	title = {Software Architecture as a Set of Architectural Design Decisions},
	doi = {10.1109/WICSA.2005.61},
	abstract = {Software architectures have high costs for change, are complex, and erode during evolution. We believe these problems are partially due to knowledge vaporization. Currently, almost all the knowledge and information about the design decisions the architecture is based on are implicitly embedded in the architecture, but lack a first-class representation. Consequently, knowledge about these design decisions disappears into the architecture, which leads to the aforementioned problems. In this paper, a new perspective on software architecture is presented, which views software architecture as a composition of a set of explicit design decisions. This perspective makes architectural design decisions an explicit part of a software architecture. Consequently, knowledge vaporization is reduced, thereby alleviating some of the fundamental problems of software architecture.},
	eventtitle = {5th Working {IEEE}/{IFIP} Conference on Software Architecture ({WICSA}'05)},
	pages = {109--120},
	booktitle = {5th Working {IEEE}/{IFIP} Conference on Software Architecture ({WICSA}'05)},
	author = {Jansen, A. and Bosch, J.},
	date = {2005-11},
	keywords = {Control systems, Computer architecture, Software architecture, Application software, Computer industry, Connectors, Costs, Electrical equipment industry, Software systems, Stress control},
}

@article{sulochana_preserving_2015,
	title = {Preserving Data Confidentiality Using Multi-cloud Architecture},
	volume = {50},
	issn = {1877-0509},
	url = {http://www.sciencedirect.com/science/article/pii/S1877050915005360},
	doi = {10.1016/j.procs.2015.04.035},
	series = {Big Data, Cloud and Computing Challenges},
	abstract = {Cloud Computing offers resources as services that are dynamically provisioned over the internet. The security of cloud computing has always been an important aspect of the quality of service from cloud service providers. The main problem that the cloud computing paradigm implicitly contains is that of secure outsourcing of sensitive as well as business-critical data and processes. One central concern in cloud computing is privacy and integrity of data processes in cloud. By using two or more distinct clouds, risks such as manipulation of data, and other threats associated with process tampering can be reduced. By integrating distinct clouds, the trust assumption can be lowered. Therefore, to provide integrity and confidentiality, the application logic and the data logic is split into two distinct clouds so that no cloud provider will gain the complete knowledge of the user data. The administrator resides in a private cloud, allows only the authenticated users to access the cloud storage. The administrator performs encryption and segmentation of the data to provide data confidentiality.},
	pages = {357--362},
	journaltitle = {Procedia Computer Science},
	shortjournal = {Procedia Computer Science},
	author = {Sulochana, M. and Dubey, Ojaswani},
	urldate = {2020-10-06},
	date = {2015-01-01},
	langid = {english},
	keywords = {De-segmentation., Decryption, Encryption, Multi cloud, Segmentation},
}

@article{yurchenko_architecture-driven_2017,
	title = {Architecture-Driven Reduction of Speciﬁcation Overhead for Verifying Conﬁdentiality in Component-Based Software Systems},
	abstract = {Code veriﬁcation techniques can be used to guarantee that some of the information processed in software systems remains conﬁdential. For this, allowed information ﬂows have to be speciﬁed for the system under analysis. Reducing the speciﬁcation overhead could render code veriﬁcation feasible where veriﬁcation was considered too complex or costly so far. In this paper, we introduce a model-driven approach to reduce the overhead for creating and maintaining such speciﬁcations. Independent of the veriﬁcation input format, developers can specify conﬁdentiality for componentbased architecture models, which are kept consistent with object-oriented code. They are supported in adapting the speciﬁcations to evolving systems in order to detect information leaks with less eﬀort and in earlier development stages.},
	pages = {321--323},
	journaltitle = {{MODELS} (Satellite Events)},
	author = {Yurchenko, Kateryna and Behr, Moritz and Klare, Heiko and Kramer, Max and Reussner, Ralf},
	date = {2017},
	langid = {english},
}

@inproceedings{chen_software-hardware_2012,
	location = {New York, {NY}, {USA}},
	title = {A software-hardware architecture for self-protecting data},
	isbn = {978-1-4503-1651-4},
	url = {https://doi.org/10.1145/2382196.2382201},
	doi = {10.1145/2382196.2382201},
	series = {{CCS} '12},
	abstract = {We propose a software-hardware architecture, {DataSafe}, that realizes the concept of self-protecting data: data that is protected by a given policy whenever it is accessed by any application -- including unvetted third-party applications. Our architecture provides dynamic instantiations of secure data compartments ({SDCs}), with hardware monitoring of the information flows from the compartment using hardware policy tags associated with the data at runtime. Unbypassable hardware output control prevents confidential information from being leaked out. Unlike previous hardware information flow tracking systems, {DataSafe} software architecture bridges the semantic gap by supporting flexible, high-level software policies for the data, seamlessly translating these policies to efficient hardware tags at runtime. Applications need not be modified to interface to these software-hardware mechanisms. {DataSafe} architecture is designed to prevent illegitimate secondary dissemination of protected plaintext data by authorized recipients, to track and protect data derived from sensitive data, and to provide lifetime enforcement of the confidentiality policies associated with the sensitive data.},
	pages = {14--27},
	booktitle = {Proceedings of the 2012 {ACM} conference on Computer and communications security},
	publisher = {Association for Computing Machinery},
	author = {Chen, Yu-Yuan and Jamkhedkar, Pramod A. and Lee, Ruby B.},
	urldate = {2020-10-06},
	date = {2012-10-16},
	keywords = {security, trusted computing, architecture, information flow tracking, policy languages, self-protecting data},
}

@inproceedings{di_vimercati_data_2007,
	location = {New York, {NY}, {USA}},
	title = {A data outsourcing architecture combining cryptography and access control},
	isbn = {978-1-59593-890-9},
	url = {https://doi.org/10.1145/1314466.1314477},
	doi = {10.1145/1314466.1314477},
	series = {{CSAW} '07},
	abstract = {Data outsourcing is becoming today a successful solution that allows users and organizations to exploit external servers for the distribution of resources. Some of the most challenging issues in such a scenario are the enforcement of authorization policies and the support of policy updates. Since a common approach for protecting the outsourced data consists in encrypting the data themselves, a promising approach for solving these issues is based on the combination of access control with cryptography. This idea is in itself not new, but the problem of applying it in an outsourced architecture introduces several challenges. In this paper, we first illustrate the basic principles on which an architecture for combining access control and cryptography can be built. We then illustrate an approach for enforcing authorization policies and supporting dynamic authorizations, allowing policy changes and data updates at a limited cost in terms of bandwidth and computational power.},
	pages = {63--69},
	booktitle = {Proceedings of the 2007 {ACM} workshop on Computer security architecture},
	publisher = {Association for Computing Machinery},
	author = {di Vimercati, Sabrina De Capitani and Foresti, Sara and Jajodia, Sushil and Paraboschi, Stefano and Samarati, Pierangela},
	urldate = {2020-10-08},
	date = {2007-11-02},
	keywords = {access control, cryptography, outsourced architecture},
}

@article{mazzoleni_xacml_2008,
	title = {{XACML} Policy Integration Algorithms},
	volume = {11},
	issn = {1094-9224},
	url = {https://doi.org/10.1145/1330295.1330299},
	doi = {10.1145/1330295.1330299},
	abstract = {{XACML} is the {OASIS} standard language specifically aimed at the specification of authorization policies. While {XACML} fits well with the security requirements of a single enterprise (even if large and composed by multiple departments), it does not address the requirements of virtual enterprises in which several autonomous subjects collaborate by sharing their resources to provide better services to customers. In this article we highlight such limitation, and we propose an {XACML} extension, the policy integration algorithms, to address them. In the article we also present the implementation of a system that makes use of the policy integration algorithms to securely replicate information in a P2P-like environment. In our solution, the data replication process considers the policies specified by both the owners of the data shared and the peers sharing data storage.},
	pages = {4:1--4:29},
	number = {1},
	journaltitle = {{ACM} Transactions on Information and System Security},
	shortjournal = {{ACM} Trans. Inf. Syst. Secur.},
	author = {Mazzoleni, Pietro and Crispo, Bruno and Sivasubramanian, Swaminathan and Bertino, Elisa},
	urldate = {2020-10-08},
	date = {2008-02-05},
	keywords = {Content Distributed Networks, Distributed Systems, Security policies integration, {SOA}, Web Services, {XACML}},
}

@thesis{emig_zugriffskontrolle_2008,
	title = {Zugriffskontrolle in dienstorientierten Architekturen},
	type = {phdthesis},
	author = {Emig, Christian},
	date = {2008},
	langid = {german},
}

@article{land_brief_2002,
	title = {A Brief Survey of Software Architecture},
	abstract = {Software of today is becoming larger and more complex. More powerful ways of structuring complexity are consequently required, whether it is about development methodologies, structural programming, naming conventions, configuration management, or, as is discussed in this report, software architecture.},
	pages = {15},
	author = {Land, Rikard},
	date = {2002},
	langid = {english},
}

@thesis{hahner_domain-specific_2020,
	title = {Domain-specific Language for Data-driven Design Time Analyses and Result Mappings for Logic Programs},
	url = {https://publikationen.bibliothek.kit.edu/1000123271},
	pagetotal = {138},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Master's Thesis},
	author = {Hahner, Sebastian},
	date = {2020},
	doi = {10.5445/IR/1000123271},
}

@article{boehm_software_2001,
	title = {Software defect reduction top 10 list},
	volume = {34},
	issn = {1558-0814},
	doi = {10.1109/2.962984},
	abstract = {Software's complexity and accelerated development schedules make avoiding defects difficult. We have found, however, that researchers have established objective and quantitative data, relationships, and predictive models that help software developers avoid predictable pitfalls and improve their ability to predict and control efficient software projects. The article presents 10 techniques that can help reduce the flaws in your code.},
	pages = {135--137},
	number = {1},
	journaltitle = {Computer},
	author = {Boehm, B. and Basili, V.R.},
	date = {2001-01},
	note = {Conference Name: Computer},
	keywords = {Computer industry, Costs, Software systems, Analytical models, accelerated development schedules, Books, defects, flaw reduction, predictable pitfalls, predictive models, project management, Project management, Prototypes, quantitative data, software complexity, software developers, software development, software development management, software fault tolerance, software projects, Software prototyping, software quality, System testing, Virtual prototyping},
}

@article{isaak_user_2018,
	title = {User Data Privacy: Facebook, Cambridge Analytica, and Privacy Protection},
	volume = {51},
	issn = {1558-0814},
	url = {https://doi.org/10.1109/MC.2018.3191268},
	doi = {10.1109/MC.2018.3191268},
	shorttitle = {User Data Privacy},
	abstract = {With the revelation that Facebook handed over personally identifiable information of more than 87 million users to Cambridge Analytica, it is now imperative that comprehensive privacy policy laws be developed. Technologists, researchers, and innovators should meaningfully contribute to the development of these policies.},
	pages = {56--59},
	number = {8},
	journaltitle = {Computer},
	author = {Isaak, Jim and Hanna, Mina J.},
	date = {2018-08},
	keywords = {security, social networking (online), Cambridge Analytica, comprehensive privacy policy laws, cybercrime, data privacy, data security, Facebook, innovators, Internet/Web technologies, online security, personally identifiable information, {PII}, privacy, privacy protection, researchers, social media, technologists, The Policy Corner, user data privacy},
}

@article{zdancewic_challenges_2004,
	title = {Challenges for Information-ﬂow Security},
	pages = {5},
	journaltitle = {Proceedings of the 1st International Workshop on the Programming Language Interference and Dependence ({PLID}’04)},
	author = {Zdancewic, Steve},
	date = {2004},
	langid = {english},
}

@article{kruchten_ontology_2004,
	title = {An Ontology of Architectural Design Decisions in Software-Intensive Systems},
	abstract = {Architectural design decisions deserve to be first class entities in the process of developing complex software-intensive systems. Preserving the graphs of decisions and all their interdependencies will support the evolution and maintenance of such systems. In this paper we present a possible ontology of architectural design decisions, their attributes and relationships, for complex, software-intensive systems.},
	journaltitle = {Proceedings of the 2nd Groningen Workshop on Software Variability Management},
	author = {Kruchten, Philippe},
	date = {2004},
}

@article{beyerer_framework_2016,
	title = {A Framework for a Uniform Quantitative Description of Risk with Respect to Safety and Security},
	volume = {1},
	issn = {2365-1695},
	url = {https://doi.org/10.1007/s41125-016-0008-y},
	doi = {10.1007/s41125-016-0008-y},
	abstract = {A mathematical framework is presented that describes risk in the context of safety and security problems quantitatively and in an integrative way. Great importance is laid on a clear notation with a sound semantics. Essentially, this seminal contribution is a substantially expanded version of our short paper “A quantitative risk model for a uniform description of safety and security”, which we presented to the 10th Future Security 2015 in Berlin (A quantitative risk model for a uniform description of safety and security. In: Proceedings of the 10th Future security—security research conference, pp 317–324, 2015). The key concept of this paper is a quantitative formulation of risk. Uncertainties are modelled based on probability distributions. Risk due to purely stochastic sources of danger is based on objective notions of probabilities and costs whereas risks of individuals (intelligent agents) are described from their own points of view, i.e. in a fully subjective manner, since individuals draw their decisions based on their subjective assessments of potential costs and of frequencies of event occurrence. Therefore, probability is interpreted in a Bayesian context as a degree of belief ({DoB}). Based on a role model for the involved agents with the three roles »source of danger«, »subject of protection« and »protector«, risk is modelled quantitatively using statistical decision theory and game theory. The set D of sources of danger is endowed with a {DoB}-distribution describing the probability of occurrence. D is partitioned into subsets that describe dangers which are due to random causes, carelessness and intention. A set of flanks of vulnerability F is assigned to each subject of protection. These flanks characterize different aspects of vulnerability concerning mechanical, physiological, informational, economical, reputational, psychological, … vulnerability. The flanks of vulnerability are endowed with conditional {DoBs} that describe to which degree an incidence or an attack will be harmful. Additionally, each flank of vulnerability is endowed with a cost function that quantifies the costs which are charged to the subject of protection, if it is affected by a harmful incidence or attack. With these ingredients the risk for the subject of protection can be quantified based on an ensemble functional with respect to all sources of danger and to all flanks of vulnerability. Depending of the respective subset of dangers such a functional is an expectation (case of random causes and carelessness) or a selection operation (case of intention), where in the latter case the attack will presumably take place at the weakest flank of vulnerability. The calculated risk can be opposed to the cost of protection measures that are offered by the protector in order to foster an effective and economical invest decision. From an attacker’s point of view a utility function is formulated which a rational attacker presumably would use to evaluate his cost-benefit ratio in order to decide whether he attacks and which of his options he exercises. The challenges of the approach are the determination of the cost functions and especially the estimation of the probabilities ({DoBs}) of the model. Two approaches for determining {DoBs}, the Maximum Entropy Principle ({MEP}) and the Conditioning On Rare Events ({CORE}), are presented and discussed. The model can be used to simulate and evaluate the endangerment of subjects of protection quantitatively, e.g. using a software agent implementation, where the agents are endowed with the cost functions and the {DoBs} of the presented framework.},
	pages = {135--150},
	number = {2},
	journaltitle = {European Journal for Security Research},
	shortjournal = {Eur J Secur Res},
	author = {Beyerer, Jürgen and Geisler, Jürgen},
	urldate = {2020-10-21},
	date = {2016-10-01},
	langid = {english},
}

@inproceedings{platenius_matching_2015,
	location = {Cham},
	title = {Matching of Incomplete Service Specifications Exemplified by Privacy Policy Matching},
	isbn = {978-3-319-14886-1},
	doi = {10.1007/978-3-319-14886-1_2},
	series = {Communications in Computer and Information Science},
	abstract = {Service matching approaches determine to what extent a provided service matches a requester’s requirements. This process is based on service specifications describing functional (e.g., signatures) as well as non-functional properties (e.g., privacy policies). However, we cannot expect service specifications to be complete as providers do not want to share all details of their services’ implementation. Moreover, creating complete specifications requires much effort. In this paper, we propose a novel service matching approach taking into account a service’s signatures and privacy policies. In particular, our approach applies fuzzy matching techniques that are able to deal with incomplete service specifications. As a benefit, decision-making based on matching results is improved and service matching becomes better applicable in practice.},
	pages = {6--17},
	booktitle = {Advances in Service-Oriented and Cloud Computing},
	publisher = {Springer International Publishing},
	author = {Platenius, Marie Christin and Arifulina, Svetlana and Petrlic, Ronald and Schäfer, Wilhelm},
	editor = {Ortiz, Guadalupe and Tran, Cuong},
	date = {2015},
	langid = {english},
	keywords = {Uncertainty, Fuzziness, Fuzzy matching, Privacy policy matching, Service discovery, Service matching},
}

@thesis{platenius_fuzzy_2016,
	title = {Fuzzy Matching of Comprehensive Service Specifications},
	institution = {Fakultät für Elektrotechnik, Informatik und Mathematik, Universität Paderborn},
	type = {Dissertation},
	author = {Platenius, Marie Christin},
	date = {2016-07},
}

@inproceedings{costante_privacy-aware_2013,
	title = {Privacy-Aware Web Service Composition and Ranking},
	doi = {10.1109/ICWS.2013.27},
	abstract = {Service selection is a key issue in the Future Internet, where applications are built by composing services and content offered by different service providers. Most existing service selection schemas only focus on {QoS} properties of services such as throughput, latency and response time, or on their trust and reputation level. By contrast, the risk of privacy breaches arising from the selection of component services whose privacy policy is not compliant with customers' privacy preferences is largely ignored. In this paper, we propose a novel privacy-preserving Web service composition and selection approach which (i) makes it possible to verify the compliance between users' privacy requirements and providers' privacy policies and (ii) ranks the composite Web services with respect to the privacy level they offer. We demonstrate our approach using a travel agency Web service as an example of service composition.},
	eventtitle = {2013 {IEEE} 20th International Conference on Web Services},
	pages = {131--138},
	booktitle = {2013 {IEEE} 20th International Conference on Web Services},
	author = {Costante, E. and Paci, F. and Zannone, N.},
	date = {2013-06},
	keywords = {data privacy, component service selection, customer privacy preferences, Data privacy, future Internet, Joining processes, Privacy, privacy breaches, privacy level, privacy policy, privacy-aware Web service composition, privacy-preserving Web service composition, {QoS} properties, quality of service, Quality of service, ranking, reputation level, response time, Sensitivity, service providers, throughput, travel agency Web service, trust level, user privacy requirements, We service ranking, Web service composition, Web services},
}

@article{mahdavi-hezavehi_classification_2017,
	title = {A Classification Framework of Uncertainty in Architecture-Based Self- Adaptive Systems with Multiple Quality Requirements},
	abstract = {Objective: In this paper we aim at a) reviewing the state-of-the-art of architecture-based approaches tackling uncertainty in self-adaptive systems with multiple quality requirements, b) proposing a classification framework for this domain, and c) classifying the current approaches according to this framework.
Method: We conducted a systematic literature review by performing an automatic search on twenty seven selected venues and books in the domain of self-adaptive systems.
Results: We propose a classification framework for uncertainty and its sources in the domain of architecture-based self-adaptive systems with multiple quality requirements. We map 51 identified primary studies into the framework and present the classified results.
Conclusions: Our results help researchers to understand the current state of research regarding uncertainty in architecture-based self-adaptive systems with multiple concerns, and identity areas for improvement in the future.},
	pages = {33},
	journaltitle = {Managing Trade-Offs in Adaptable Software Architectures},
	author = {Mahdavi-Hezavehi, Sara and Avgeriou, Paris and Weyns, Danny},
	date = {2017},
	langid = {english},
}

@incollection{esfahani_uncertainty_2013,
	location = {Berlin, Heidelberg},
	title = {Uncertainty in Self-Adaptive Software Systems},
	isbn = {978-3-642-35813-5},
	url = {https://doi.org/10.1007/978-3-642-35813-5_9},
	series = {Lecture Notes in Computer Science},
	abstract = {The ever-growing complexity of software systems coupled with their stringent availability requirements are challenging the manual management of software after its deployment. This has motivated the development of self-adaptive software systems. Self-adaptation endows a software system with the ability to satisfy certain objectives by automatically modifying its behavior at runtime. While many promising approaches for the construction of self-adaptive software systems have been developed, the majority of them ignore the uncertainty underlying the adaptation. This has been one of the key inhibitors to widespread adoption of self-adaption techniques in risk-averse real-world applications. Uncertainty in this setting is a vaguely understood term. In this paper, we characterize the sources of uncertainty in self-adaptive software system, and demonstrate its impact on the system’s ability to satisfy its objectives. We then provide an alternative notion of optimality that explicitly incorporates the uncertainty underlying the knowledge (models) used for decision making. We discuss the state-of-the-art for dealing with uncertainty in this setting, and conclude with a set of challenges, which provide a road map for future research.},
	pages = {214--238},
	booktitle = {Software Engineering for Self-Adaptive Systems {II}: International Seminar, Dagstuhl Castle, Germany, October 24-29, 2010 Revised Selected and Invited Papers},
	publisher = {Springer},
	author = {Esfahani, Naeem and Malek, Sam},
	editor = {de Lemos, Rogério and Giese, Holger and Müller, Hausi A. and Shaw, Mary},
	urldate = {2020-10-30},
	date = {2013},
	langid = {english},
	keywords = {Uncertainty, Self-Adaptive Software Systems},
}

@thesis{aughenbaugh_managing_2006,
	title = {Managing Uncertainty in Engineering Design Using Imprecise Probabilities and Principles of Information Economics},
	url = {https://smartech.gatech.edu/handle/1853/11521},
	abstract = {The engineering design community recognizes that an essential part of the design process is decision making.  Because decisions are generally made under uncertainty, engineers need appropriate methods for modeling and managing uncertainty.  Two important characteristics of uncertainty in the context of engineering design are imprecision and irreducible uncertainty.  In order to model both of these characteristics, it is valuable to use probabilities that are most generally imprecise and subjective.  These imprecise probabilities generalize traditional, precise probabilities; when the available information is extensive, imprecise probabilities reduce to precise probabilities.  An approach for comparing the practical value of different uncertainty models is developed.  The approach examines the value of a model using the principles of information economics: value equals benefits minus costs.  The benefits of a model are measured in terms of the quality of the product that results from the design process.  Costs are measured not only in terms of direct design costs, but also the costs of creating and using the model.  Using this approach, the practical value of using an uncertainty model that explicitly recognizes both imprecision and irreducible uncertainty is demonstrated in the context of a high-risk engineering design example in which the decision-maker has few statistical samples to support the decision.  It is also shown that a particular imprecise probability model called probability bounds analysis generalizes sensitivity analysis, a process of identifying whether a particular decision is robust given the decision makers lack of complete information.  An approach for bounding the value of future statistical data samples while collecting information to support design decisions is developed, and specific policies for making decisions in the presence of imprecise information are examined in the context of engineering.},
	type = {phdthesis},
	author = {Aughenbaugh, Jason Matthew},
	urldate = {2020-10-30},
	date = {2006-06-22},
	langid = {american},
	note = {Accepted: 2006-09-01T19:29:41Z
Publisher: Georgia Institute of Technology},
}

@article{sandhu_role-based_1996,
	title = {Role-based access control models},
	volume = {29},
	issn = {1558-0814},
	doi = {10.1109/2.485845},
	abstract = {Security administration of large systems is complex, but it can be simplified by a role-based access control approach. This article explains why {RBAC} is receiving renewed attention as a method of security administration and review, describes a framework of four reference models developed to better understand {RBAC} and categorizes different implementations, and discusses the use of {RBAC} to manage itself.},
	pages = {38--47},
	number = {2},
	journaltitle = {Computer},
	author = {Sandhu, R. S. and Coyne, E. J. and Feinstein, H. L. and Youman, C. E.},
	date = {1996-02},
	keywords = {Access control, authorisation, Authorization, Data security, Software systems, data security, Privacy, Government, large systems, {NIST}, Permission, {RBAC}, reference models, Resource management, role-based access control, security administration, security of data, Telephony},
}

@inproceedings{bartolini_gdpr-based_2019,
	location = {Cham},
	title = {{GDPR}-Based User Stories in the Access Control Perspective},
	isbn = {978-3-030-29238-6},
	doi = {10.1007/978-3-030-29238-6_1},
	series = {Communications in Computer and Information Science},
	abstract = {Because of {GDPR}’s principle of “data protection by design and by default”, organizations who wish to stay lawful have to re-think their data practices. Access Control ({AC}) can be a technical solution for them to protect access to “personal data by design”, and thus to gain legal compliance, but this requires to have Access Control Policies ({ACPs}) expressing requirements aligned with {GDPR}’s provisions. Provisions are however pieces of law and are not written to be immediately interpreted as technical requirements; the task is thus not straightforward. The Agile software development methodology can help untangle the problem. It has dedicated tools to describe requirements and one of such them, User Stories, seems up to task. Stories are concise yet informal descriptions telling who, what and why something is required by users; they are prioritized in lists, called backlogs. Inspired by these Agile tools this paper advances the notion of Data Protection backlogs, which are lists of User Stories about {GDPR} provisions told as technical requirements. For each User Story we build a corresponding {ACP}, so enabling the implementation of {GDPR} compliant {AC} systems.},
	pages = {3--17},
	booktitle = {Quality of Information and Communications Technology},
	publisher = {Springer International Publishing},
	author = {Bartolini, Cesare and Daoudagh, Said and Lenzini, Gabriele and Marchetti, Eda},
	editor = {Piattini, Mario and Rupino da Cunha, Paulo and García Rodríguez de Guzmán, Ignacio and Pérez-Castillo, Ricardo},
	date = {2019},
	langid = {english},
	keywords = {Access Control Policy ({ACP}), General Data Protection Regulation ({GDPR}), User Story},
}

@inproceedings{may_privacy_2006,
	title = {Privacy {APIs}: access control techniques to analyze and verify legal privacy policies},
	doi = {10.1109/CSFW.2006.24},
	shorttitle = {Privacy {APIs}},
	abstract = {There is a growing interest in establishing rules to regulate the privacy of citizens in the treatment of sensitive personal data such as medical and financial records. Such rules must be respected by software used in these sectors. The regulatory statements are somewhat informal and must be interpreted carefully in the software interface to private data. This paper describes techniques to formalize regulatory privacy rules and how to exploit this formalization to analyze the rules automatically. Our formalism, which we call privacy {APIs}, is an extension of access control matrix operations to include (1) operations for notification and logging and (2) constructs that ease the mapping between legal and formal language. We validate the expressive power of privacy {APIs} by encoding the 2000 and 2003 {HIPAA} consent rules in our system. This formalization is then encoded into Promela and we validate the usefulness of the formalism by using the {SPIN} model checker to verify properties that distinguish the two versions of {HIPAA}},
	eventtitle = {19th {IEEE} Computer Security Foundations Workshop ({CSFW}'06)},
	pages = {13 pp.--97},
	booktitle = {19th {IEEE} Computer Security Foundations Workshop ({CSFW}'06)},
	author = {May, M. J. and Gunter, C. A. and Lee, I.},
	date = {2006-07},
	note = {{ISSN}: 2377-5459},
	keywords = {Access control, authorisation, data privacy, Data privacy, Government, access control matrix operations, application program interfaces, citizen privacy, Encoding, formal language, Formal languages, formal verification, {HIPAA} consent rules, Insurance, Law, Legal factors, legal privacy policy analysis, legal privacy policy verification, Medical treatment, Power system modeling, privacy {API}, Promela, regulatory privacy rules, sensitive personal data privacy, {SPIN} model checker},
}

@inproceedings{otto_addressing_2007,
	title = {Addressing Legal Requirements in Requirements Engineering},
	doi = {10.1109/RE.2007.65},
	abstract = {Legal texts, such as regulations and legislation, are playing an increasingly important role in requirements engineering and system development. Monitoring systems for requirements and policy compliance has been recognized in the requirements engineering community as a key area for research. Similarly, regulatory compliance is critical in systems that are governed by regulations and law, especially given that non-compliance can result in both financial and criminal penalties. Working with legal texts can be very challenging, however, because they contain numerous ambiguities, cross-references, domain-specific definitions, and acronyms, and are frequently amended via new regulations and case law. Requirements engineers and compliance auditors must be able to identify relevant regulations, extract requirements and other key concepts, and monitor compliance throughout the software lifecycle. This paper surveys research efforts over the past 50 years in handling legal texts for systems development. These efforts include the use of symbolic logic, logic programming, first-order temporal logic, deontic logic, defeasible logic, goal modeling, and semi-structured representations. This survey can aid requirements engineers and auditors to better specify, monitor, and test software systems for compliance.},
	eventtitle = {15th {IEEE} International Requirements Engineering Conference ({RE} 2007)},
	pages = {5--14},
	booktitle = {15th {IEEE} International Requirements Engineering Conference ({RE} 2007)},
	author = {Otto, P. N. and Anton, A. I.},
	date = {2007-10},
	note = {{ISSN}: 2332-6441},
	keywords = {system development, Information security, Software systems, Government, Law, Legal factors, Computer science, cross-references, deontic logic, domain-specific definitions, first-order temporal logic, goal modeling, legal texts, Legislation, logic programming, Logic programming, Monitoring, monitoring systems, program testing, requirements engineering, semistructured representations, software lifecycle, symbolic logic, Systems engineering and theory, temporal logic, test software systems, text analysis},
}

@report{international_organization_for_standardization_isoiec_2018,
	location = {Geneva, {CH}},
	title = {{ISO}/{IEC} 27000:2018(E) Information technology – Security techniques – Information security management systems – Overview and vocabulary},
	type = {Standard},
	author = {{International Organization for Standardization}},
	date = {2018},
}

@article{meneely_itrust_2012,
	title = {{iTrust} Electronic Health Care System: A Case Study},
	shorttitle = {{iTrust} Electronic Health Care System},
	pages = {16},
	journaltitle = {oftware and Systems Traceability},
	author = {Meneely, Andrew and Smith, Ben and Williams, Laurie},
	date = {2012},
	langid = {english},
}

@article{pottier_information_2002,
	title = {Information flow inference for {ML}},
	volume = {25},
	pages = {319--330},
	number = {1},
	journaltitle = {Proceedings of the 29th {ACM} {SIGPLAN}-{SIGACT} symposium on Principles of programming languages},
	author = {Pottier, François and Simonet, Vincent},
	date = {2002},
	langid = {english},
}

@inproceedings{alfageeh_assurance_2019,
	title = {Assurance for {CyberSecurity} with Assume-Guarantee Reasoning},
	doi = {10.1109/UEMCON47517.2019.8992971},
	abstract = {Design of cybersecurity solutions for a network is a challenging problem as it involves the integration of several complex components such as routers, servers, computers, smart devices, that include not only essential networking algorithms but also security algorithms. This is further complicated by the need to have robust security policies implemented to prevent violation of confidentiality as the networked devices interact. The design of such complex networked systems demand a more rigorous approach to the modeling and analysis at a higher level of abstraction, which can be inherited from the field of formal methods in software engineering for safety critical systems. Presently, network or security engineers do not use a formal method based software engineering approach to design and build cybersecurity systems. Thus, we propose a software engineering based formal approach to model and analyze cybersecurity, that along with identification of concrete requirements enables automated analysis to guarantee cybersecurity properties are satisfied within the network. In this research paper, we discuss an ontology guided assume-guarantee based formal approach to model and analyze a designed network. To enable this approach, a domain specific language is designed that allows association of assumptions with components in the network that allows verifying the satisfaction of contracts that are guarantees. The formal language designed includes reserved words are guided by the {CyberSecurity} domain and the semantic reasoning is based on formal architectural representation.},
	eventtitle = {2019 {IEEE} 10th Annual Ubiquitous Computing, Electronics Mobile Communication Conference ({UEMCON})},
	pages = {0653--0659},
	booktitle = {2019 {IEEE} 10th Annual Ubiquitous Computing, Electronics Mobile Communication Conference ({UEMCON})},
	author = {Alfageeh, A. and Bhattacharyya, S. and Perl, S. and Patel, M.},
	date = {2019-10},
	keywords = {security of data, formal language, formal verification, assume-guarantee reasoning, Assurance, complex components, complex networked systems, Confidentiality, Cybersecurity, {CyberSecurity} domain, cybersecurity properties, cybersecurity solutions, cybersecurity systems, Design analysis, designed network, formal architectural representation, formal languages, formal method based software engineering approach, Formal Methods, formal specification, modeling analysis, networked devices interact, ontologies (artificial intelligence), Ontology, robust security policies, safety critical systems, security algorithms, security engineers, semantic reasoning, smart devices, software engineering, specification languages},
}

@inproceedings{ferraiolo_role-based_1995,
	title = {Role-Based Access Control ({RBAC}): Features and Motivations},
	url = {https://csrc.nist.gov/publications/detail/conference-paper/1995/12/15/role-based-access-control-rbac-features-and-motivations},
	shorttitle = {Role-Based Access Control ({RBAC})},
	abstract = {The central notion of Role-Based Access Control ({RBAC}) is that users do not have discretionary access to enterprise objects. Instead, access permissions are administratively associated with roles, and users are administratively made members of appropriate roles. This idea greatly simplifies management of authorization while providing an opportunity for great flexibility in specifying and enforcing enterprise- specific protection policies. Users can be made members of roles as determined by their responsibilities and qualifications and can be easily reassigned from one role to another without modifying the underlying access structure. Roles can be granted new permissions as new applications and actions are incorporated, and permissions can be revoked from roles as needed.},
	eventtitle = {11th Annual Computer Security Applications Conference; December 11-15, 1995; New Orleans, Louisiana, United States},
	pages = {241--248},
	booktitle = {Proceedings of the 11th Annual Computer Security Applications Conference},
	publisher = {{IEEE}},
	author = {Ferraiolo, David and Cugini, Janet and Kuhn, Richard},
	urldate = {2020-11-23},
	date = {1995-12-15},
	langid = {english},
}

@inproceedings{boltz_context-based_2020,
	title = {Context-Based Confidentiality Analysis for Industrial {IoT}},
	doi = {10.1109/SEAA51224.2020.00096},
	abstract = {In this research paper, we present an approach for an analysis process, which can find confidentiality issues in data-exchange, on the architectural level of Industrial Internet of Things software systems. Existing approaches provide an insufficient definition of dataflow or lack support of finely granulated information for providing confidentiality. Based on an existing modeling and analysis process for Data-Driven Software Architecture, we extend the role-based approach for access control, with a model to model transformation utilizing a context-based approach. Using a case study based evaluation we show that our approach works accurately and scales in a way that is feasible for big organizations.},
	eventtitle = {2020 46th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	pages = {589--596},
	booktitle = {2020 46th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	author = {Boltz, N. and Walter, M. and Heinrich, R.},
	date = {2020-08},
	keywords = {software architecture, confidentiality, dataflow, industrial {IoT}},
}

@article{seifermann_challenges_2016,
	title = {Challenges in Secure Software Evolution - The Role of Software Architecture},
	abstract = {Achieving quality properties for software systems and maintaining them during evolution is challenging. Especially, security properties often degrade during software evolution. This is often not noticed and can lead to monetary loss and serious damage to the company’s image. Approaches for maintaining security properties exist but fail to exploit the knowledge of the architectural design phase. This results in high effort and slow reactions on evolutionary changes. In this paper, we describe five key challenges in maintaining security properties during software evolution and show how architecture supports mastering them.},
	journaltitle = {Softwaretechnik-Trends},
	author = {Seifermann, Stephan and Taspolatoglu, Emre and Reussner, Ralf H. and Heinrich, R.},
	date = {2016},
}

@inproceedings{schmieders_runtime_2015,
	location = {Berlin, Heidelberg},
	title = {Runtime Model-Based Privacy Checks of Big Data Cloud Services},
	isbn = {978-3-662-48616-0},
	doi = {10.1007/978-3-662-48616-0_5},
	series = {Lecture Notes in Computer Science},
	abstract = {Cloud services have to comply with privacy policies when storing or processing data. As cloud services become increasingly data-intensive, e.g., in the case of big data analytics, data privacy concerns become more critical and challenging to address. In particular, data may only be processed at certain geo-locations. However, the actual geo-locations of the many storage and compute nodes involved in big data processing is dynamically selected during runtime. In addition, the execution of concrete data processing tasks may change data classifications from, e.g., personal to anonymized data. Thus, privacy policy checks for big data cloud services have to consider information about the actual nodes and data processing tasks at runtime. The proposed approach R-{PRIS} monitors cloud services to derive and maintain typed runtime models providing the aforementioned information. R-{PRIS} checks the typed runtime models against privacy policies by employing a data-classification-aware search. The evaluation of R-{PRIS}, performed on Amazon Web Services (including Hadoop), indicates that the approach may efficiently and timely detect privacy violations in big data cloud services.},
	pages = {71--86},
	booktitle = {Service-Oriented Computing},
	publisher = {Springer},
	author = {Schmieders, Eric and Metzger, Andreas and Pohl, Klaus},
	editor = {Barros, Alistair and Grigori, Daniela and Narendra, Nanjangud C. and Dam, Hoa Khanh},
	date = {2015},
	langid = {english},
	keywords = {Privacy, Big data, Cloud services, Runtime checking},
}

@article{coyne_abac_2013,
	title = {{ABAC} and {RBAC}: Scalable, Flexible, and Auditable Access Management},
	volume = {15},
	issn = {1941-045X},
	doi = {10.1109/MITP.2013.37},
	shorttitle = {{ABAC} and {RBAC}},
	abstract = {Is it possible to obtain the flexibility and advantages of attribute-based access control while maintaining role-based access control's advantages for analysis and risk control?},
	pages = {14--16},
	number = {3},
	journaltitle = {{IT} Professional},
	author = {Coyne, E. and Weil, T. R.},
	date = {2013-05},
	note = {Conference Name: {IT} Professional},
	keywords = {security, authorisation, {RBAC}, role-based access control, {ABAC}, Access controls, attribute-based access control, attribute-centric access control, auditable access management, information technology, Information technology, Network architecture, Network security, role-centric access control},
}

@inproceedings{bures_capturing_2020,
	location = {Cham},
	title = {Capturing Dynamicity and Uncertainty in Security and Trust via Situational Patterns},
	isbn = {978-3-030-61470-6},
	doi = {10.1007/978-3-030-61470-6_18},
	series = {Lecture Notes in Computer Science},
	abstract = {Modern smart systems are highly dynamic and allow for dynamic and ad-hoc collaboration not only among devices, but also among humans and organizations. Such a collaboration can introduce uncertainty to a system, as behavior of humans cannot be directly controlled and the system has to deal with unforeseen changes. Security and trust play a crucial role in these systems, especially in domains like Industry 4.0 and similar. In this paper we aim at providing situational patterns for tackling uncertainty in trust – in particular in access control. To do so, we provide a classification of uncertainty of access control in Industry 4.0 systems and illustrate this on a series of representative examples. Based on this classification and examples, we derive situational patterns per type of uncertainty. These situational patterns will serve as adaptation strategies in cases when, due to uncertainty, an unanticipated situation is encountered in the system. We base the approach on our previous work of autonomic component ensembles and security ensembles.},
	pages = {295--310},
	booktitle = {Leveraging Applications of Formal Methods, Verification and Validation: Engineering Principles},
	publisher = {Springer International Publishing},
	author = {Bures, Tomas and Hnetynka, Petr and Heinrich, Robert and Seifermann, Stephan and Walter, Maximilian},
	editor = {Margaria, Tiziana and Steffen, Bernhard},
	date = {2020},
	langid = {english},
	keywords = {Uncertainty, Access control, Security, Dynamic systems},
}

@inproceedings{al-ali_dynamic_2019,
	location = {New York, {NY}, {USA}},
	title = {Dynamic security rules for legacy systems},
	isbn = {978-1-4503-7142-1},
	url = {https://doi.org/10.1145/3344948.3344974},
	doi = {10.1145/3344948.3344974},
	series = {{ECSA} '19},
	abstract = {Industry 4.0 tries to digitalize the production process further. The digitalization is achieved by connecting different entities (machines, worker) to data-exchange, which needs to be dynamic and to adapt to different changing situations and members in the process. However, just exchanging data might lead to confidentiality issues. The data-exchange needs to be protected to secure the confidentiality and trust in the system. Therefore, security rules need to adapt to these dynamic situations. One part of a possible solution might be dynamic access control rules. However in many cases, existing "legacy" systems are reused, which can in not handle dynamic access control rules. Due to this gap between the required and provided functionality, we propose an approach, which integrates dynamic access control based on the system-context into legacy systems. Our approach uses a security adaption controller, which dynamically adapts the access control rules to a new situation and integrates them into an existing legacy system. We discussed our approach with industrial practitioners and related our approach to their existing legacy system. In addition, we performed a scalability analysis to demonstrate the applicability of our approach in a realistic environment.},
	pages = {277--284},
	booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
	publisher = {Association for Computing Machinery},
	author = {Al-Ali, Rima and Hnetynka, Petr and Havlik, Jiri and Krivka, Vlastimil and Heinrich, Robert and Seifermann, Stephan and Walter, Maximilian and Juan-Verdejo, Adrian},
	urldate = {2020-11-27},
	date = {2019-09-09},
	keywords = {access control, autonomic systems, Industry 4.0, legacy systems, security rules, self-adaptive architecture},
}

@article{salnitri_modelling_2020,
	title = {Modelling the interplay of security, privacy and trust in sociotechnical systems: a computer-aided design approach},
	volume = {19},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-019-00744-x},
	doi = {10.1007/s10270-019-00744-x},
	shorttitle = {Modelling the interplay of security, privacy and trust in sociotechnical systems},
	abstract = {Personal data have become a central asset for multiple enterprise applications and online services offered by private companies, public organisations or a combination of both. The sensitivity of such data and the continuously growing legislation that accompanies their management dictate the development of methods that allow the development of more secure, trustworthy software systems with focus on privacy protection. The contribution of this paper is the definition of a novel requirements engineering method that supports both early and late requirements specification, giving emphasis on security, privacy and trust. The novelty of our work is that it provides the means for software designers and security experts to analyse the system-to-be from multiple aspects, starting from identifying high-level goals to the definition of business process composition, and elicitation of mechanisms to fortify the system from external threats. The method is supported by two {CASE} tools. To demonstrate the applicability and usefulness of our work, the paper shows its applications to a real-world case study.},
	pages = {467--491},
	number = {2},
	journaltitle = {Software and Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Salnitri, Mattia and Angelopoulos, Konstantinos and Pavlidis, Michalis and Diamantopoulou, Vasiliki and Mouratidis, Haralambos and Giorgini, Paolo},
	urldate = {2020-11-30},
	date = {2020-03-01},
	langid = {english},
}

@article{allen_robust_2006,
	title = {Robust Design for Multiscale and Multidisciplinary Applications},
	volume = {128},
	issn = {1050-0472},
	url = {https://doi.org/10.1115/1.2202880},
	doi = {10.1115/1.2202880},
	abstract = {The intent in robust design is to improve the quality of products and processes by reducing their sensitivity to variations, thereby reducing the effects of variability without removing its sources. Robust design is especially useful for integrating information from designers working at multiple length and time scales. Inevitably this involves the integration of uncertain information. This uncertainty is derived from many sources and robust design may be classified based on these sources—uncertainty in noise or environmental and other noise factors (type I); uncertainty in design variables or control factors (type {II}); and uncertainty introduce by modeling methods (type {III}). Each of these types of uncertainty can be mitigated by robust design. Of particular interest are the challenges associated with the design of multidisciplinary and multiscale systems; these challenges and opportunities are examined in the context of materials design.},
	pages = {832--843},
	number = {4},
	journaltitle = {Journal of Mechanical Design},
	shortjournal = {Journal of Mechanical Design},
	author = {Allen, Janet K. and Seepersad, Carolyn and Choi, {HaeJin} and Mistree, Farrokh},
	urldate = {2020-12-08},
	date = {2006-01-30},
}

@article{armour_five_2000,
	title = {The Five Orders of Ignorance},
	volume = {43},
	pages = {4},
	number = {10},
	journaltitle = {Communications of the {ACM}},
	author = {Armour, Phillip G},
	date = {2000},
	langid = {english},
}

@article{schaar_privacy_2010,
	title = {Privacy by design},
	volume = {3},
	pages = {267--274},
	number = {2},
	journaltitle = {Identity in the Information Society},
	author = {Schaar, Peter},
	date = {2010},
	note = {Publisher: Springer},
}

@article{brooks_no_1987,
	title = {No Silver Bullet Essence and Accidents of Software Engineering},
	volume = {20},
	issn = {1558-0814},
	doi = {10.1109/MC.1987.1663532},
	pages = {10--19},
	number = {4},
	journaltitle = {Computer},
	author = {{Brooks}},
	date = {1987-04},
	keywords = {Computer industry, Costs, Project management, Diseases, Hardware, Industrial accidents, Roads, Silver, Software engineering, Technological innovation},
}

@article{powers_evaluation_2011,
	title = {Evaluation: from precision, recall and F-measure to {ROC}, informedness, markedness and correlation},
	volume = {abs/2010.16061},
	url = {https://arxiv.org/abs/2010.16061},
	journaltitle = {{CoRR}},
	author = {Powers, David M. W.},
	date = {2011},
}

@article{walker_defining_2003,
	title = {Defining uncertainty: a conceptual basis for uncertainty management in model-based decision support},
	volume = {4},
	shorttitle = {Defining uncertainty},
	abstract = {The aim of this paper is to provide a conceptual basis for the systematic treatment of uncertainty in model-based decision support activities such as policy analysis, integrated assessment and risk assessment. It focuses on the uncertainty perceived from the point of view of those providing information to support policy decisions (i.e., the modellers ’ view on uncertainty)  – uncertainty regarding the analytical outcomes and conclusions of the decision support exercise. Within the regulatory and management sciences, there is neither commonly shared terminology nor full agreement on a typology of uncertainties. Our aim is to synthesise a wide variety of contributions on uncertainty in model-based decision support in order to provide an interdisciplinary theoretical framework for systematic uncertainty analysis. To that end we adopt a general definition of uncertainty as being any deviation from the unachievable ideal of completely deterministic knowledge of the relevant system. We further propose to discriminate among three dimensions of uncertainty: location, level and nature of uncertainty, and we harmonise existing typologies to further detail the concepts behind these three dimensions of uncertainty. We propose an uncertainty matrix as a heuristic tool to classify and report the various dimensions of uncertainty, thereby providing a conceptual framework for better communication among analysts as well as between them and policymakers and stakeholders. Understanding the various dimensions of uncertainty helps in identifying,},
	pages = {5--17},
	number = {1},
	journaltitle = {Integrated assessment},
	author = {Walker, Warren E and Harremoës, Poul and Rotmans, Jan and Van Der Sluijs, Jeroen P and Van Asselt, Marjolein {BA} and Janssen, Peter and Krayer von Krauss, Martin P},
	date = {2003},
	note = {Publisher: Taylor \& Francis},
}

@article{schneider_nudging_2020,
	title = {Nudging users into digital service solutions},
	volume = {30},
	issn = {1422-8890},
	url = {https://doi.org/10.1007/s12525-019-00373-8},
	doi = {10.1007/s12525-019-00373-8},
	abstract = {With the ubiquity and prevalence of advanced technologies in society, transactions have become increasingly digital, requiring new user identity verification mechanisms. Electronic identification ({eID}) enables user identity authorization in online environments. Although {eID} plays a central role in government initiatives worldwide to digitalize citizen transactions, {eID} adoption remains surprisingly low. Drawing on digital nudging theory and e-government literature, we examine how {eID} adoption can be increased by changing the decision environment in which users choose {eID}. In a controlled experiment with 161 participants, we investigate the effect of default options ({eID} vs. offline {ID} as default) and popularity signals (presence vs. absence of social proof) on users’ {eID} adoption behavior. Both nudges increase {eID} adoption, but default options are a double-edged sword as they simultaneously fuel privacy concerns towards the government, attenuating the effect of default option on {eID} adoption. These concerns can be mitigated by adding social proof cues.},
	pages = {863--881},
	number = {4},
	journaltitle = {Electronic Markets},
	shortjournal = {Electron Markets},
	author = {Schneider, David and Klumpe, Johannes and Adam, Martin and Benlian, Alexander},
	urldate = {2020-12-17},
	date = {2020-12-01},
	langid = {english},
}

@article{adam_early_2019,
	title = {Of early birds and phantoms: how sold-out discounts impact entrepreneurial success in reward-based crowdfunding},
	volume = {13},
	issn = {1863-6691},
	url = {https://doi.org/10.1007/s11846-018-0311-2},
	doi = {10.1007/s11846-018-0311-2},
	shorttitle = {Of early birds and phantoms},
	abstract = {Reward-based crowdfunding platforms are a promising medium for entrepreneurs to raise funds from a large number of contributors. As a means to encourage contributions early in the life cycle of a crowdfunding campaign, entrepreneurs often choose to offer discounted rewards in limited numbers. Though previous research suggests that scarcity of rewards can increase the chances of success, it remains unclear whether these early bird offers continue to have an effect on the decision making of backers even when sold out, as they remain visible on the campaign’s webpage. Drawing on the theory of the phantom effect, this paper explores (1) how sold-out rewards influence backers’ selection of available options and (2) how the phantom effect may interact with different discount amounts. We conducted an online experiment with 229 subjects simulating the pledging process for a crowdfunding campaign that attempts to raise funds for the publication of a book. Our findings suggest that potential backers choose the undiscounted version of a reward more often, if a discounted, sold-out reward (phantom option) is displayed. This effect is significant when the phantom option has a high discount, but not significant when the phantom option has a low discount. Consequently, in contrast to the traditional perspective that sold-out options negatively impact sales, we suggest that, in reward-based crowdfunding, sold-out rewards may increase the chances of success, if considered and applied strategically. This study therefore offers counterintuitive implications for research as well as for entrepreneurs seeking funds through reward-based crowdfunding.},
	pages = {545--560},
	number = {3},
	journaltitle = {Review of Managerial Science},
	shortjournal = {Rev Manag Sci},
	author = {Adam, Martin and Wessel, Michael and Benlian, Alexander},
	urldate = {2020-12-17},
	date = {2019-06-01},
	langid = {english},
}

@inproceedings{salim_approach_2011,
	title = {An Approach to Access Control under Uncertainty},
	doi = {10.1109/ARES.2011.11},
	abstract = {In dynamic and uncertain environments such as healthcare, where the needs of security and information availability are difficult to balance, an access control approach based on a static policy will be suboptimal regardless of how comprehensive it is. The uncertainty stems from the unpredictability of users' operational needs as well as their private incentives to misuse permissions. In Role Based Access Control ({RBAC}), a user's legitimate access request may be denied because its need has not been anticipated by the security administrator. Alternatively, even when the policy is correctly specified an authorised user may accidentally or intentionally misuse the granted permission. This paper introduces a novel approach to access control under uncertainty and presents it in the context of {RBAC}. By taking insights from the field of economics, in particular the insurance literature, we propose a formal model where the value of resources are explicitly defined and an {RBAC} policy (entailing those predictable access needs) is only used as a reference point to determine the price each user has to pay for access, as opposed to representing hard and fast rules that are always rigidly applied.},
	eventtitle = {2011 Sixth International Conference on Availability, Reliability and Security},
	pages = {1--8},
	booktitle = {2011 Sixth International Conference on Availability, Reliability and Security},
	author = {Salim, F. and Reid, J. and Dawson, E. and Dulleck, U.},
	date = {2011-08},
	keywords = {Uncertainty, Access control, Access Control, authorisation, Permission, Resource management, formal verification, formal specification, Authorisation, Budget, Dynamic Environments, Economics, formal model, Hospitals, Incentives, Insider Problem, Proposals, {RBAC} policy, role based access control, user operational need, user private incentives},
}

@inproceedings{molloy_risk-based_2012,
	title = {Risk-based access control decisions under uncertainty},
	abstract = {Report for early dissemination of its contents. In view of the transfer of copyright to the outside publisher, its distribution outside of {IBM} prior to publication should be limited to peer communications and specific requests. After outside publication, requests should be filled only by reprints or legally obtained copies of the article (e.g. , payment of royalties). Copies may be requested from {IBM} T. J.},
	eventtitle = {Computer Science},
	author = {Molloy, Ian and Dickens, Luke and Morisset, Charles and Cheng, Pau--chen and Lobo, Jorge and Russo, Alessandra},
	date = {2012-01-01},
}

@thesis{salim_approaches_2012,
	title = {Approaches to access control under uncertainty},
	url = {https://eprints.qut.edu.au/58408/},
	abstract = {The ultimate goal of an access control system is to allocate each user the precise level of access they need to complete their job - no more and no less. This proves to be challenging in an organisational setting. On one hand employees need enough access to the organisation’s resources in order to perform their jobs and on the other hand more access will bring about an increasing risk of misuse - either intentionally, where an employee uses the access for personal benefit, or unintentionally, through carelessness or being socially engineered to give access to an adversary.

This thesis investigates issues of existing approaches to access control in allocating optimal level of access to users and proposes solutions in the form of new access control models. These issues are most evident when uncertainty surrounding users’ access needs, incentive to misuse and accountability are considered, hence the title of the thesis.

We first analyse access control in environments where the administrator is unable to identify the users who may need access to resources. To resolve this uncertainty an administrative model with delegation support is proposed. Further, a detailed technical enforcement mechanism is introduced to ensure delegated resources cannot be misused.

Then we explicitly consider that users are self-interested and capable of misusing resources if they choose to. We propose a novel game theoretic access control model to reason about and influence the factors that may affect users’ incentive to misuse.

Next we study access control in environments where neither users’ access needs can be predicted nor they can be held accountable for misuse. It is shown that by allocating budget to users, a virtual currency through which they can pay for the resources they deem necessary, the need for a precise pre-allocation of permissions can be relaxed. The budget also imposes an upper-bound on users’ ability to misuse. A generalised budget allocation function is proposed and it is shown that given the context information the optimal level of budget for users can always be numerically determined.

Finally, Role Based Access Control ({RBAC}) model is analysed under the explicit assumption of administrators’ uncertainty about self-interested users’ access needs and their incentives to misuse. A novel Budget-oriented Role Based Access Control (B-{RBAC}) model is proposed. The new model introduces the notion of users’ behaviour into {RBAC} and provides means to influence users’ incentives. It is shown how {RBAC} policy can be used to individualise the cost of access to resources and also to determine users’ budget. The implementation overheads of B-{RBAC} is examined and several low-cost sub-models are proposed.},
	institution = {Queensland University of Technology},
	type = {phdthesis},
	author = {Salim, Farzad},
	urldate = {2020-12-18},
	date = {2012},
	langid = {english},
}

@inproceedings{alissa_pais_2018,
	title = {{PAIS} Access Control Model Characteristics Analysis},
	doi = {10.1109/CAIS.2018.8442020},
	abstract = {Role-based access control ({RBAC}) is widely accepted and used as an access control model. However, an access control model for a business process environment requires particular capabilities that {RBAC} does not satisfy, such as active access control and separation of duty that can be dynamically enforced at the level of a business process execution instance. This creates the need for an access control model that is specifically designed to work in a business process environment. This paper identifies the required characteristics for a business process access control model. The researchers used real life case studies as well as the literature to identify these characteristics. The paper shows that for an access control mode to work in a business process centric environment it should support the identified characteristics.},
	eventtitle = {2018 1st International Conference on Computer Applications Information Security ({ICCAIS})},
	pages = {1--5},
	booktitle = {2018 1st International Conference on Computer Applications Information Security ({ICCAIS})},
	author = {Alissa, K. and Salim, F. and Reid, J. and Dawson, E.},
	date = {2018-04},
	keywords = {Access control, Access Control, authorisation, role-based access control, active access control, {BPM} Authorisation model, Buildings, business data processing, business process access control model, business process execution instance, Business process management, Information systems, {PAIS} access control model, Process control, Security-aware {BPM}, Task analysis, workflow access control},
}

@article{skandhakumar_graph_2016,
	title = {Graph theory based representation of building information models for access control applications},
	volume = {68},
	issn = {0926-5805},
	url = {http://www.sciencedirect.com/science/article/pii/S0926580516300644},
	doi = {10.1016/j.autcon.2016.04.001},
	abstract = {Building information models are increasingly being utilised for facility management of large facilities such as critical infrastructures. In such environments, it is valuable to utilise the vast amount of data contained within the building information models to improve access control administration. The use of building information models in access control scenarios can provide 3D visualisation of buildings as well as many other advantages such as automation of essential tasks including path finding, consistency detection, and accessibility verification. However, there is no mathematical model for building information models that can be used to describe and compute these functions. In this paper, we show how graph theory can be utilised as a representation language of building information models and the proposed security related functions. This graph-theoretic representation allows for mathematically representing building information models and performing computations using these functions.},
	pages = {44--51},
	journaltitle = {Automation in Construction},
	shortjournal = {Automation in Construction},
	author = {Skandhakumar, Nimalaprakasan and Salim, Farzad and Reid, Jason and Drogemuller, Robin and Dawson, Ed},
	urldate = {2020-12-18},
	date = {2016-08-01},
	langid = {english},
	keywords = {Access control, Security, Authorisation, {BIM}, Building information modelling, Facility management, Graph theory, {IFC}, Industry foundation classes},
}

@article{skandhakumar_authorization_2012,
	title = {An Authorization Framework using Building Information Models},
	volume = {55},
	issn = {1460-2067},
	doi = {10.1093/comjnl/bxs098},
	abstract = {A building information model ({BIM}) is an electronic repository of structured, three-dimensional data that captures both the physical and dynamic functional characteristics of a facility. In addition to its more traditional function as a tool to aid design and construction, a {BIM} can be used throughout the life cycle of a facility, functioning as a living database that places resources contained within the building in their spatial and temporal context. Through its comprehension of spatial relationships, a {BIM} can meaningfully represent and integrate previously isolated control and management systems and processes, and thereby provide a more intuitive interface to users. By placing processes in a spatial context, decision-making can be improved, with positive flow-on effects for security and efficiency. In this article, we systematically analyse the authorization requirements involved in the use of {BIMs}. We introduce the concept of using a {BIM} as a graphical tool to support spatial access control configuration and management (including physical access control). We also consider authorization requirements for regulating access to the structured data that exists within a {BIM} as well as to external systems and data repositories that can be accessed via the {BIM} interface. With a view to addressing these requirements we present a survey of relevant spatiotemporal access control models, focusing on features applicable to {BIMs} and highlighting capability gaps. Finally, we present a conceptual authorization framework that utilizes {BIMs}.},
	pages = {1244--1264},
	number = {10},
	journaltitle = {The Computer Journal},
	author = {Skandhakumar, N. and Reid, J. and Dawson, E. and Drogemuller, R. and Salim, F.},
	date = {2012-10},
	note = {Conference Name: The Computer Journal},
	keywords = {access control, authorization models, building information model},
}

@article{arunkumar_location_2017,
	title = {Location attestation and access control for mobile devices using {GeoXACML}},
	volume = {80},
	issn = {1084-8045},
	url = {http://www.sciencedirect.com/science/article/pii/S1084804516302958},
	doi = {10.1016/j.jnca.2016.11.028},
	abstract = {Access control has been applied in various scenarios in the past for negotiating the best policy. Solutions with {XACML} for access control has been very well explored by research and have resulted in significant contributions to various sectors including healthcare. In controlling access to the sensitive data such as medical records, it is important to guarantee that the data is accessed by the right person for the right reason. Location of access requestor can be a good indication for his/her eligibility and reasons for accessing the data. To reason with geospatial information for access control, Geospatial {XACML} ({eXtensible} Access Control Markup Language) is proposed as a standard. However, there is no available implementation and architecture for reasoning with Geospatial {XACML} policies. This paper proposes to extend {XACML} with geohashing to implement geospatial policies. It also proposes an architecture for checking reliability of the geospatial information provided by clients. With a case study, we demonstrate how our framework can be used to control the privacy and data access of health service data in handheld devices.},
	pages = {181--188},
	journaltitle = {Journal of Network and Computer Applications},
	shortjournal = {Journal of Network and Computer Applications},
	author = {Arunkumar, Saritha and Soyluoglu, Berker and Sensoy, Murat and Srivatsa, Mudhakar and Rajarajan, Muttukrishnan},
	urldate = {2020-12-18},
	date = {2017-02-15},
	langid = {english},
	keywords = {Access control, Geospatial, {GeoXACML}},
}

@inproceedings{skandhakumar_physical_2012,
	location = {Berlin, Heidelberg},
	title = {Physical Access Control Administration Using Building Information Models},
	isbn = {978-3-642-35362-8},
	doi = {10.1007/978-3-642-35362-8_19},
	series = {Lecture Notes in Computer Science},
	abstract = {Physical access control systems play a central role in the protection of critical infrastructures, where both the provision of timely access and preserving the security of sensitive areas are paramount. In this paper we discuss the shortcomings of existing approaches to the administration of physical access control in complex environments. At the heart of the problem is the current dependency on human administrators to reason about the implications of the provision or the revocation of staff access to an area within these facilities. We demonstrate how utilising Building Information Models ({BIMs}) and the capabilities they provide, including 3D representation of a facility and path-finding, may reduce the incidents of errors made by security administrators.},
	pages = {236--250},
	booktitle = {Cyberspace Safety and Security},
	publisher = {Springer},
	author = {Skandhakumar, Nimalaprakasan and Salim, Farzad and Reid, Jason and Dawson, Ed},
	editor = {Xiang, Yang and Lopez, Javier and Kuo, C.-C. Jay and Zhou, Wanlei},
	date = {2012},
	langid = {english},
}

@article{skandhakumar_policy_2018,
	title = {A policy model for access control using building information models},
	volume = {23},
	issn = {1874-5482},
	url = {http://www.sciencedirect.com/science/article/pii/S1874548218300271},
	doi = {10.1016/j.ijcip.2018.08.005},
	abstract = {Building information models have created a paradigm shift in how buildings are built and managed by providing a dynamic repository for building data that is useful in many new operational scenarios. This change has also created an opportunity to use building information models as an integral part of security operations and especially as a tool to facilitate fine-grained access control to building spaces in smart buildings and critical infrastructure environments. In this paper, we identify the requirements for a security policy model for such an access control system and discuss why the existing policy models are not suitable for this application. We propose a new policy language extension to {XACML}, with {BIM} specific data types and functions based on the {IFC} specification, which we call {BIM}-{XACML}.},
	pages = {1--10},
	journaltitle = {International Journal of Critical Infrastructure Protection},
	shortjournal = {International Journal of Critical Infrastructure Protection},
	author = {Skandhakumar, Nimalaprakasan and Reid, Jason and Salim, Farzad and Dawson, Ed},
	urldate = {2020-12-18},
	date = {2018-12-01},
	langid = {english},
	keywords = {Access Control, Authorization, {XACML}, {BIM}, Building information modelling, {IFC}, Industry Foundation Classes, Policy language, {XML}},
}

@patent{mcdonnell_location-based_2002,
	title = {Location-based data access control},
	url = {https://patents.google.com/patent/US20020177449A1/en},
	holder = {{HP} Inc},
	type = {patentus},
	number = {20020177449A1},
	author = {{McDonnell}, James and Thomas, Andrew and Waters, John and Crouch, Simon and Vickers, Paul},
	urldate = {2020-12-18},
	date = {2002-11-28},
	keywords = {authorized, data, equipment, location, service},
}

@patent{mathias_uncertainty_2009,
	title = {Uncertainty management in a decision-making system},
	url = {https://patents.google.com/patent/US7606784B2/en},
	holder = {Northrop Grumman Corp},
	type = {patentus},
	number = {7606784B2},
	author = {Mathias, Keith Eugene and Nixon, Mark Robert and Talbot, Patrick James},
	urldate = {2020-12-18},
	date = {2009-10-20},
	langid = {english},
	keywords = {uncertainty, decision, evidence, interest, story},
}

@inproceedings{ray_lrbac_2006,
	location = {Berlin, Heidelberg},
	title = {{LRBAC}: A Location-Aware Role-Based Access Control Model},
	isbn = {978-3-540-68963-8},
	doi = {10.1007/11961635_10},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{LRBAC}},
	abstract = {With the growing use of wireless networks and mobile devices, we are moving towards an era where location information will be necessary for access control. The use of location information can be used for enhancing the security of an application, and it can also be exploited to launch attacks. For critical applications, a formal model for location-based access control is needed that increases the security of the application and ensures that the location information cannot be exploited to cause harm. In this paper, we show how the Role-Based Access Control ({RBAC}) model can be extended to incorporate the notion of location. We show how the different components in the {RBAC} model are related with location and how this location information can be used to determine whether a subject has access to a given object. This model is suitable for applications consisting of static and dynamic objects, where location of the subject and object must be considered before granting access.},
	pages = {147--161},
	booktitle = {Information Systems Security},
	publisher = {Springer},
	author = {Ray, Indrakshi and Kumar, Mahendra and Yu, Lijun},
	editor = {Bagchi, Aditya and Atluri, Vijayalakshmi},
	date = {2006},
	langid = {english},
}

@inproceedings{ardagna_supporting_2006,
	location = {New York, {NY}, {USA}},
	title = {Supporting location-based conditions in access control policies},
	isbn = {978-1-59593-272-3},
	url = {https://doi.org/10.1145/1128817.1128850},
	doi = {10.1145/1128817.1128850},
	series = {{ASIACCS} '06},
	abstract = {Location-based Access Control ({LBAC}) techniques allow taking users' physical location into account when determining their access privileges. In this paper, we present an approach to {LBAC} aimed at integrating location-based conditions along with a generic access control model, so that a requestor can be granted or denied access by checking her location as well as her credentials. Our {LBAC} model includes a novel way of taking into account the limitations of the technology used to ascertain the location of the requester. Namely, we describe how location verification can be encapsulated as a service, representing location technologies underlying it in terms of two semantically uniform service level agreement ({SLA}) parameters called confidence and timeout. Based on these parameters, we present the formal definition of a number of location-based predicates, their management, evaluation, and enforcement. The challenges that such an extension to traditional access control policies inevitably carries are discussed also with reference to detailed examples of {LBAC} policies.},
	pages = {212--222},
	booktitle = {Proceedings of the 2006 {ACM} Symposium on Information, computer and communications security},
	publisher = {Association for Computing Machinery},
	author = {Ardagna, Claudio A. and Cremonini, Marco and Damiani, Ernesto and di Vimercati, Sabrina De Capitani and Samarati, Pierangela},
	urldate = {2020-12-18},
	date = {2006-03-21},
	keywords = {access control, location-based services, mobile system},
}

@inproceedings{santos_dynamic_2014,
	title = {A dynamic risk-based access control architecture for cloud computing},
	doi = {10.1109/NOMS.2014.6838319},
	abstract = {Cloud computing is a distributed computing model that still faces problems. New ideas emerge to take advantage of its features and among the research challenges found in the cloud, we can highlight Identity and Access Management. The main problems of the application of access control in the cloud are the necessary flexibility and scalability to support a large number of users and resources in a dynamic and heterogeneous environment, with collaboration and information sharing needs. This paper proposes the use of risk-based dynamic access control for cloud computing. The proposal is presented as an access control model based on an extension of the {XACML} standard with three new components: the Risk Engine, the Risk Quantification Web Services and the Risk Policies. The risk policies present a method to describe risk metrics and their quantification, using local or remote functions. The risk policies allow users and cloud service providers to define how to handle risk-based access control for their resources, using different quantification and aggregation methods. The model reaches the access decision based on a combination of {XACML} decisions and risk analysis. A prototype of the model is implemented, showing it has enough expressivity to describe the models of related work. In the experimental results, the prototype takes between 2 and 6 milliseconds to reach access decisions using a risk policy. A discussion on the security aspects of the model is also presented.},
	eventtitle = {2014 {IEEE} Network Operations and Management Symposium ({NOMS})},
	pages = {1--9},
	booktitle = {2014 {IEEE} Network Operations and Management Symposium ({NOMS})},
	author = {Santos, D. R. d and Westphall, C. M. and Westphall, C. B.},
	date = {2014-05},
	keywords = {Computational modeling, Access control, authorisation, risk analysis, Measurement, software architecture, Web services, Proposals, cloud computing, Cloud computing, collaboration, distributed computing, dynamic environment, dynamic risk-based access control architecture, Engines, groupware, heterogeneous environment, identity and access management, information sharing needs, risk engine, risk policies, risk quantification, {XACML} standard},
}

@inproceedings{belsis_managing_2007,
	location = {Berlin, Heidelberg},
	title = {Managing Uncertainty in Access Control Decisions in Distributed Autonomous Collaborative Environments},
	isbn = {978-3-540-76929-3},
	doi = {10.1007/978-3-540-76929-3_25},
	series = {Lecture Notes in Computer Science},
	abstract = {Coalitions of autonomous domains gain constantly interest during the last years due to the various fields of their potential application. A lot of challenges of both academic as well as of practical nature are related with their deployment. Among else, the distributed nature of a coalition demands special focus in respect to security management. In this paper we argue about the necessity for adjustable security mechanisms towards the security management of multi-domain environments; we describe an approach that allows determination of preferences when defining access control permissions over the shared objects. We handle such preferences by encoding access control constraints using fuzzy relations and we describe a prototype security architecture that implements the basic principles of our approach.},
	pages = {261--267},
	booktitle = {Advances in Computer Science – {ASIAN} 2007. Computer and Network Security},
	publisher = {Springer},
	author = {Belsis, Petros and Gritzalis, Stefanos and Skourlas, Christos and Tsoukalas, Vassilis},
	editor = {Cervesato, Iliano},
	date = {2007},
	langid = {english},
	keywords = {Access Control, Access Control Policy, Access Request, Fuzzy Relation, Security Management},
}

@inproceedings{lytra_supporting_2013,
	location = {New York, {NY}, {USA}},
	title = {Supporting architectural decision making for systems-of-systems design under uncertainty},
	isbn = {978-1-4503-2048-1},
	url = {https://doi.org/10.1145/2489850.2489859},
	doi = {10.1145/2489850.2489859},
	series = {{SESoS} '13},
	abstract = {For the design and integration of complex systems-of-systems, various architectural decisions for recurring design problems need to be made. This requires that the software architects consider various design issues and alternatives, make trade-offs for competing requirements, and adapt the decisions to specific technologies and systems. Documentations of reusable architectural design decisions ({ADDs}), e.g., pattern-based decisions, provide rather informal guidelines for making recurring {ADDs}. These and other factors introduce many sources of uncertainty in the architectural decision making process. Existing approaches do not consider this inherent uncertainty of architectural decision making, which has been until now largely ad hoc and informal, without explicit, automated support. Apart from that, the design rationale for repeated {ADDs} often remains undocumented, leading to loss of architectural knowledge. To address these problems we propose to provide semi-automated support for decision making and documentation of reusable {ADDs} under uncertainty using a fuzzy logic expert system. We motivate our approach using a systems-of-systems example from the industry automation area in which our approach has been applied.},
	pages = {43--46},
	booktitle = {Proceedings of the First International Workshop on Software Engineering for Systems-of-Systems},
	publisher = {Association for Computing Machinery},
	author = {Lytra, Ioanna and Zdun, Uwe},
	urldate = {2020-12-21},
	date = {2013-07-02},
	keywords = {architectural design decisions, architectural knowledge, design pattern selection, fuzzy logic, systems-of-systems},
}

@thesis{lytra_supporting_2015,
	location = {wien},
	title = {Supporting reusable architectural design decisions},
	rights = {All rights reserved},
	url = {http://othes.univie.ac.at/38289/},
	abstract = {Jede Softwarearchitektur beinhaltet eine Reihe von Architekturentscheidungen. Die Dokumentation von Architekturentscheidungen erfasst nicht nur die sich daraus ergebenden Designstrukturen, sondern auch die Begründung, die Stärken und Schwächen, sowie die Alternativen zu den ausgewählten Designlösungen. Softwarearchitekten erfassen daher Architekturentscheidungen, um die Begründung und die Implikationen dieser Entscheidungen zu analysieren, zu verstehen, zu teilen und zu kommunizieren. Architekturentscheidungen zu erfassen verhindert folglich potentiellen Verlust von Architekturwissen, ein Phänomen das auch als ``Knowledge Vaporization'' bekannt ist. Die Entwicklung von verschiedenen Tools und Ansätzen für das Treffen und Dokumentieren von Architekturentscheidungen sowie die Einführung von Architekturentscheidungsmethoden in die Industrie in den letzten zehn Jahren belegen das steigende Interesse an der Erfassung und dem Management von Architekturentscheidungen beim Softwaredesign- und Softwareentwicklungsprozess. Manche Arbeiten stellen das Sammeln, Organisieren und das effektive Verwenden von wiederverwendbaren Architekturentscheidungen in den Fokus. Wiederverwendbare Architekturentscheidungen sind zum Beispiel in Form von Architekturentscheidungsmodellen dokumentiert, die das Architekturdesign von Softwareprojekten unterstützen. Diese Doktorarbeit ist durch die Herausforderungen, die in diesem Bereich entstehen, motiviert.

Trotz intensiver Forschung an Tools und Methoden für die Unterstützung von wiederverwendbarem Architekturwissen in der Software Community in letzter Zeit, gibt es immer noch sehr wenige empirische Studien und beschränkte empirische Evidenz über die Effektivität und Effizienz von Softwarearchitekten, die wiederverwendbare Architekturentscheidungen verwenden. Außerdem sind bis jetzt manche Aspekte, die während des Treffens von Architekturentscheidungen berücksichtigt werden müssen, wie zum Beispiel die Verwendung von Qualitätsattributen, die Ungewissheit von Architekturentscheidungen oder die Beziehungen zwischen applikationsgenerischem und applikationsspezifischem Wissen, für wiederverwendbare Architekturentscheidungen wenig untersucht worden. Eine andere Herausforderung, die wir identifiziert haben, bezieht sich auf das Konsistenzmanagement zwischen Architekturentscheidungen und Architekturdesigns, sodass das Treffen und die Dokumentation von Architekturentscheidungen, die auf wiederverwendbarem Wissen basieren, in anderen Softwaredesign-, Softwareentwicklungs- und Softwareevolutionsprozessen integriert werden.

In dieser Doktorarbeit haben wir die Modellierung und die Verwendung von wiederverwendbaren Architekturentscheidungsmodellen in einer Fallstudie in der Industrie sowie in zwei kontrollierten Experimenten beobachtet. Dafür haben wir einen Prototypen entwickelt, um das Treffen und das Dokumentieren von Architekturentscheidungen, die auf wiederverwendbaren Entscheidungsmodellen basieren, zu unterstützen. Für den Zweck der Fallstudie haben wir ein wiederverwendbares Architekturentscheidungsmodell über Service-basierte Plattformintegration entwickelt; dieses Modell wurde danach von Plattformexperten validiert. Diese Experten haben sich auch bei einer Fallstudie über die Integration von heterogenen Plattformen, die im Rahmen eines Softwaresystems für die Kontrolle eines Warehouse funktionieren, beteiligt. Weiters haben wir zwei Experimente mit angehenden Softwarearchitekten durchgeführt. Diese lieferten uns empirische Evidenz, dass die Verwendung von wiederverwendbaren Entscheidungsmodellen sowohl die Effizienz als auch die Effektivität von Softwarearchitekten erhöht.
Wir haben auch eine strukturierte Literaturrecherche über die Verwendung von Qualitätsattributen in Tools und Methoden für Architekturentscheidungen durchgeführt und herausgefunden, dass nur wenige Ansätze das Treffen von Architekturentscheidungen, basierend auf Qualitäten und wiederverwendbarem Architekturwissen, unterstützen. Diese Erkenntnisse haben uns dazu veranlasst, wiederverwendbare Architekturentscheidungsmodelle mit Qualitätsattributen zu erweitern und die Ungewissheit von Qualitätsattributen beim Treffen von Architekturentscheidungen zu untersuchen. Das Ziel war es, wiederverwendbare Architekturentscheidungen zusammen mit Qualitätsattributen besser zu unterstützen. Wir haben diesen Ansatz in einer Fallstudie im Rahmen eines industriellen Projekts über Softwareökosysteme für Smart Cities demonstriert. Einige andere Themen wie die Integration von Variabilitäts- und Architekturentscheidungen sind als Anforderungen im Rahmen der Unterstützung von Architekturentscheidungen im Product Line Engineering entstanden. Unser Ansatz für das Konsistenzmanagement zwischen Architekturentscheidungen und Architekturdesigns und die domänenspezifische Sprache zur Umwandlung wiederverwendbaren Architekturwissens in Designs ist als eine Verbesserung zur aktuellen Praxis der manuellen Verwaltung von Architekturentscheidungen und Architekturdesigns und als ein Schritt in die Richtung der Automatisierung der Integration von wiederverwendbaren Entscheidungen in Softwaredesign- und Softwareevolutionsprozessen zu sehen.
Unsere Methode und entsprechendes Tooling wurden für ihre Effizienz, die Skalierbarkeit, den Modellierungsaufwand und die Wiederverwendbarkeit im Rahmen einer industriellen Fallstudie evaluiert. Zusammenfassend hat diese Doktorarbeit zum besseren Verständnis und der besseren Unterstützung von wiederverwendbaren Architekturentscheidungen - deren Anwendung in der industriellen Praxis in den kommenden Jahren steigen sollte - erheblich beigetragen.},
	pagetotal = {{XXI}, 246 S. : Ill., graph. Darst.},
	institution = {uniwien},
	type = {phdthesis},
	author = {Lytra, Ioanna},
	urldate = {2020-12-21},
	date = {2015},
}

@inproceedings{esfahani_dealing_2012,
	location = {New York, {NY}, {USA}},
	title = {Dealing with uncertainty in early software architecture},
	isbn = {978-1-4503-1614-9},
	url = {https://doi.org/10.1145/2393596.2393621},
	doi = {10.1145/2393596.2393621},
	series = {{FSE} '12},
	abstract = {Changing early architectural decisions of a system is both difficult and costly. It is very important for the architect to get them "right". However, in early design, the architect is often forced to make these decisions under uncertainty, i.e., not knowing the precise impact of those decisions on system's properties (e.g., scalability) as well as stakeholder concerns (e.g., cost). In this paper, we provide an overview of {GuideArch}, a framework aimed at systematic exploration of the architectural solution space under uncertainty to help with making early architectural decisions.},
	pages = {1--4},
	booktitle = {Proceedings of the {ACM} {SIGSOFT} 20th International Symposium on the Foundations of Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Esfahani, Naeem and Razavi, Kaveh and Malek, Sam},
	urldate = {2020-12-21},
	date = {2012-11-11},
	keywords = {uncertainty, software architecture, decision making},
}

@inproceedings{sommestad_cyber_2009,
	title = {Cyber Security Risks Assessment with Bayesian Defense Graphs and Architectural Models},
	doi = {10.1109/HICSS.2009.141},
	abstract = {To facilitate rational decision making regarding cyber security investments, decision makers need to be able to assess expected losses before and after potential investments. This paper presents a model based assessment framework for analyzing the cyber security provided by different architectural scenarios. The framework uses the Bayesian statistics based extended influence diagrams to express attack graphs and related countermeasures. In this paper it is demonstrated how this structure can be captured in an abstract model to support analysis based on architectural models. The approach allows calculating the probability that attacks will succeed and the expected loss of these given the instantiated architectural scenario. Moreover, the framework can handle the uncertainties that are accompanied to the analyses. In architectural analysis there are uncertainties acquainted both to the scenario and its properties, as well as to the analysis framework that stipulates how security countermeasures contribute to cyber security.},
	eventtitle = {2009 42nd Hawaii International Conference on System Sciences},
	pages = {1--10},
	booktitle = {2009 42nd Hawaii International Conference on System Sciences},
	author = {Sommestad, T. and Ekstedt, M. and Johnson, P.},
	date = {2009-01},
	note = {{ISSN}: 1530-1605},
	keywords = {Uncertainty, Computer architecture, Computer security, Information security, Risk management, security of data, decision making, architectural model, Bayes methods, Bayesian defense graph, Bayesian methods, Bayesian statistics based extended influence diagram, cyber security investment, cyber security risk assessment management, decision maker, Decision making, graph theory, investment, Investments, Management information systems, probability, risk management, Tree graphs},
}

@article{raman_knowledge_2017,
	title = {Knowledge Based Decision Model for Architecting and Evolving Complex System-of-Systems},
	volume = {27},
	rights = {Copyright © 2017 by Ramakrishnan Raman, Meenakshi D'Souza. Published and used by {INCOSE} with permission},
	issn = {2334-5837},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.2334-5837.2017.00343.x},
	doi = {https://doi.org/10.1002/j.2334-5837.2017.00343.x},
	abstract = {Architecting complex System-of-System ({SoS}) has evinced keen interest recently, specifically towards factoring in the operational and managerial independence of the constituent systems, and the evolutionary and adaptive nature of {SoS} development. Architectural decisions have a significant bearing on the operational measures of success, referred to as Measures of Effectiveness ({MOEs}), of the {SoS}. There is inherent uncertainty while making an architectural decision for complex {SoS} due to the incomplete knowledge on the implications of the decision. The impact on the {MOEs} of the {SoS} may be realized only later in the development lifecycle, influencing the performance and the emergent behavior of the {SoS}. Further, when learning cycles on the architectural decisions are experienced, once the implication of decision is realized, there needs to be means for incorporating the feedback on the decisions taken, and to reflect back on the uncertainty associated with the decisions. This paper proposes a knowledge based decision model for architecting and evolving complex {SoS}, that takes into account the uncertainty associated with architectural decisions and the learning cycles and feedback loops experienced. It also enables augmenting the architectural knowledge base, both at a constituent system level as well as at the System-of-System level. The proposed model adopts a decision oriented view that enables factoring in uncertainty, learning cycles and feedback loops in architectural decisions. It facilitates exploring the implications of various {SoS} evolution scenarios on architectural decisions, while analyzing {MOEs} of the {SoS} in relation to the {MOEs} of the constituent systems.},
	pages = {30--44},
	number = {1},
	journaltitle = {{INCOSE} International Symposium},
	author = {Raman, Ramakrishnan and D'Souza, Meenakshi},
	urldate = {2020-12-21},
	date = {2017},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/j.2334-5837.2017.00343.x},
}

@inproceedings{alexeeva_design_2016,
	location = {Cham},
	title = {Design Decision Documentation: A Literature Overview},
	isbn = {978-3-319-48992-6},
	doi = {10.1007/978-3-319-48992-6_6},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Design Decision Documentation},
	abstract = {Despite the abundance of research on methodologies for the documentation of design decisions and the evidence linking documentation to the improvement in the systems evolution, their practical adoption seems to be sparse. To understand this issue, we have conducted an overview of state-of-the-art on documentation of design decisions. We pursue an identification of characteristics of the different techniques proposed in the literature, such as the final goal of the documentation, the quantity of information attached to each decision documentation, the rigour of the proposed technique or its level of automation. To unveil these, we propose six classification dimensions, relevant for the industrial application, and use them to structure and analyse the review results. This work contributes with a taxonomy of the area, a structured overview covering 96 publications and a summary of open questions, which can be addressed by future research to facilitate practical adoption.},
	pages = {84--101},
	booktitle = {Software Architecture},
	publisher = {Springer International Publishing},
	author = {Alexeeva, Zoya and Perez-Palacin, Diego and Mirandola, Raffaela},
	editor = {Tekinerdogan, Bedir and Zdun, Uwe and Babar, Ali},
	date = {2016},
	langid = {english},
	keywords = {Capture Design Decisions, Categorical Attributes, Decision Documentation, Industrial Applicability, Knowledge Management Architecture},
}

@inproceedings{sion_security_2020,
	location = {New York, {NY}, {USA}},
	title = {Security Threat Modeling: Are Data Flow Diagrams Enough?},
	isbn = {978-1-4503-7963-2},
	url = {https://doi.org/10.1145/3387940.3392221},
	doi = {10.1145/3387940.3392221},
	series = {{ICSEW}'20},
	shorttitle = {Security Threat Modeling},
	abstract = {Traditional threat modeling approaches such as Microsoft's {STRIDE} rely on Data Flow Diagrams ({DFDs}) as the main input. As {DFDs} are constructed from only five distinct model element types, these system models are deliberately kept simple. While this lowers the bar for practical adoption, there are a number of significant drawbacks. In this position paper, we identify and illustrate four key shortcomings of {DFD} models when used for security threat modeling, related to the inadequate representation of security concepts, data elements, abstraction levels, and deployment information. Based on these shortcomings, we posit the need for a dedicated, integrated language for threat modeling, and discuss the trade-offs that need to be made between the ease of adoption and the level of support for systematic and repeatable threat modeling.},
	pages = {254--257},
	booktitle = {Proceedings of the {IEEE}/{ACM} 42nd International Conference on Software Engineering Workshops},
	publisher = {Association for Computing Machinery},
	author = {Sion, Laurens and Yskout, Koen and Van Landuyt, Dimitri and van den Berghe, Alexander and Joosen, Wouter},
	urldate = {2021-01-04},
	date = {2020-06-27},
	keywords = {security, data flow diagrams, security by design, threat modeling},
}

@article{patel_service_2009,
	title = {Service Level Agreement in Cloud Computing},
	abstract = {Cloud computing that provides cheap and pay-as-you-go computing resources is rapidly gaining momentum as an alternative to traditional {IT} Infrastructure. As more and more consumers delegate their tasks to cloud providers, Service Level Agreements({SLA}) between consumers and providers emerge as a key aspect. Due to the dynamic nature of the cloud, continuous monitoring on Quality of Service ({QoS}) attributes is necessary to enforce {SLAs}. Also numerous other factors such as trust (on the cloud provider) come into consideration, particularly for enterprise customers that may outsource its critical data. This complex nature of the cloud landscape warrants a sophisticated means of managing {SLAs}. This paper proposes a mechanism for managing {SLAs} in a cloud computing environment using the Web Service Level Agreement({WSLA}) framework, developed for {SLA} monitoring and {SLA} enforcement in a Service Oriented Architecture ({SOA}). We use the third party support feature of {WSLA} to delegate monitoring and enforcement tasks to other entities in order to solve the trust issues. We also present a real world use case to validate our proposal.},
	pages = {11},
	journaltitle = {Kno.e.sis Publications},
	author = {Patel, Pankesh and Ranabahu, Ajith H and Sheth, Amit P},
	date = {2009-01-01},
	langid = {english},
}

@inproceedings{lee_ontology_2015,
	title = {Ontology of Secure Service Level Agreement},
	doi = {10.1109/HASE.2015.33},
	abstract = {Maintaining security and privacy in the Cloud is a complex task. The task is made even more challenging as the number of vulnerabilities associated with the cloud infrastructure and applications are increasing very rapidly. Understanding the security service level agreements ({SSLAs}) and privacy policies offered by service and infrastructure providers is critical for consumers to assess the risks of the Cloud before they consider migrating their {IT} operations to the Cloud. To address these concerns relative to the assessment of security and privacy risks of the Cloud, we have developed ontologies for representing security {SLAs} ({SSLA}) in this paper. Our ontologies for {SSLAs} can be used to understand the security agreements of a provider, to negotiate desired security levels, and to audit the compliance of a provider with respect to federal regulations (such as {HIPAA}).},
	eventtitle = {2015 {IEEE} 16th International Symposium on High Assurance Systems Engineering},
	pages = {166--172},
	booktitle = {2015 {IEEE} 16th International Symposium on High Assurance Systems Engineering},
	author = {Lee, C. and Kavi, K. M. and Paul, R. A. and Gomathisankaran, M.},
	date = {2015-01},
	note = {{ISSN}: 1530-2059},
	keywords = {security, Security, data privacy, Facebook, privacy, Privacy, security of data, Monitoring, ontologies (artificial intelligence), information technology, cloud computing, Cloud computing, Business, cloud infrastructure, contracts, federal regulations, {IT} operations, Ontologies, ontology, secure service level agreement, service level agreement, {SLA}, {SSLA}},
}

@inproceedings{marilly_requirements_2002,
	title = {Requirements for service level agreement management},
	doi = {10.1109/IPOM.2002.1045756},
	abstract = {The aim of the paper is to introduce and present the main drivers and basic concepts for {SLA} management. We discuss the business requirements according to two viewpoints: the customer's and the service provider's. We go into more detail on the technical requirements for both the {SLA} contract itself and the {SLA} management system. Finally, we give an overview of {SLA} management open issues in the industrial and research community.},
	eventtitle = {{IEEE} Workshop on {IP} Operations and Management},
	pages = {57--62},
	booktitle = {{IEEE} Workshop on {IP} Operations and Management},
	author = {Marilly, E. and Martinot, O. and Betge-Brezetz, S. and Delegue, G.},
	date = {2002-10},
	keywords = {Internet, quality of service, Quality of service, Context-aware services, Bandwidth, Companies, computer network management, contract, Contracts, customer, customer relationship management, e-commerce, electronic commerce, Internet services, {IP} networks, Laser sintering, Next generation networking, {QoS}, service level agreement management, service level specification, service provider, {SLA} management, Telecommunication network management, Web and internet services},
}

@incollection{brucker_securebpmn_2012,
	location = {New York, {NY}, {USA}},
	title = {{SecureBPMN}: modeling and enforcing access control requirements in business processes},
	isbn = {978-1-4503-1295-0},
	url = {https://doi.org/10.1145/2295136.2295160},
	shorttitle = {{SecureBPMN}},
	abstract = {Modern enterprise systems have to comply to regulations such as Basel {III} resulting in complex security requirements. These requirements need to be modeled at design-time and enforced at runtime. Moreover, modern enterprise systems are often business-process driven, i.e., the system behavior is described as high-level business processes that are executed by a business process execution engine. Consequently, there is a need for an integrated and tool-supported methodology that allows for specifying and enforcing compliance and security requirements for business process-driven enterprise systems. In this paper, we present a tool chain supporting both the design-time modeling as well as the run-time enforcement of security requirements for business process-driven systems.},
	pages = {123--126},
	booktitle = {Proceedings of the 17th {ACM} symposium on Access Control Models and Technologies},
	publisher = {Association for Computing Machinery},
	author = {Brucker, Achim D. and Hang, Isabelle and Lückemeyer, Gero and Ruparel, Raj},
	urldate = {2021-01-05},
	date = {2012-06-20},
	keywords = {bpmn, process security, rbac, securebpmn},
}

@thesis{cherdantseva_securebpmn_2014,
	title = {Secure*{BPMN} - a graphical extension for {BPMN} 2.0 based on a reference model of information assurance \& security},
	rights = {cc\_by\_nc\_sa},
	url = {http://orca.cf.ac.uk/74432/},
	abstract = {The main contribution of this thesis is Secure*{BPMN}, a graphical security modelling extension for the de-facto industry standard business process modelling language {BPMN} 2.0.1. Secure*{BPMN} enables a cognitively effective representation of security concerns in business process models. It facilitates the engagement of experts with different backgrounds, including non-security and nontechnical experts, in the discussion of security concerns and in security decision-making. The strength and novelty of Secure*{BPMN} lie in its comprehensive semantics based on a Reference Model of Information Assurance \& Security ({RMIAS}) and in its cognitively effective syntax. 
The {RMIAS}, which was developed in this project, is a synthesis of the existing knowledge of the Information Assurance \& Security domain. The {RMIAS} helps to build an agreed-upon understanding of Information Assurance \& Security, which experts with different backgrounds require before they may proceed with the discussion of security issues. The development process of the {RMIAS}, which was made explicit, and the multiphase evaluation carried out confirmed the completeness and accuracy of the {RMIAS}, and its suitability as a foundation for the semantics of Secure*{BPMN}. The {RMIAS}, which has multiple implications for research, education and practice is a secondary contribution of this thesis, and is a contribution to the Information Assurance \& Security domain in its own right.
The syntax of Secure*{BPMN} complies with the {BPMN} extensibility rules and with the scientific principles of cognitively effective notation design. The analytical and empirical evaluations corroborated the ontological completeness, cognitive effectiveness, ease of use and usefulness of Secure*{BPMN}. It was verified that Secure*{BPMN} has a potential to be adopted in practice.},
	pagetotal = {452},
	institution = {Cardiff University},
	type = {phdthesis},
	author = {Cherdantseva, Yulia},
	urldate = {2021-01-05},
	date = {2014-12},
	langid = {english},
}

@article{brucker_integrating_2013,
	title = {Integrating Security Aspects into Business Process Models},
	volume = {55},
	issn = {1611-2776, 2196-7032},
	url = {https://www.degruyter.com/view/journals/itit/55/6/article-p239.xml},
	doi = {10.1524/itit.2013.2004},
	abstract = {{\textless}section class="abstract"{\textgreater}{\textless}h2 class="{abstractTitle} text-title my-1" id="d1182e2"{\textgreater}Abstract{\textless}/h2{\textgreater}{\textless}p{\textgreater}Modern enterprise systems are often process-driven and, thus,
            rely heavily on process-aware information systems. In such
            systems, high-level process-models play an important role both for
            communicating business requirements between domain experts and
            system experts as well as basis for the system implementation.
            Since several years, enterprise system need to fulfil an
            increasing number of the security and compliance
            requirements. Thus, there is an increasing demand for integrating
            high-level security and compliance requirements into process
            models, i. e. a common language for domain experts, system
            experts, and security experts.  We present a security modelling
            language, called {SecureBPMN}, that can easily be integrated into
            business process modelling languages. In this paper, we exemplary
            integrate {SecureBPMN} into {BPMN} and, thus, present a common
            language for describing business process models together with
            their security and compliance requirements.{\textless}/p{\textgreater}{\textless}/section{\textgreater}},
	pages = {239--246},
	number = {6},
	journaltitle = {it - Information Technology},
	author = {Brucker, Achim D.},
	urldate = {2021-01-05},
	date = {2013-12-01},
	langid = {english},
	note = {Publisher: De Gruyter Oldenbourg
Section: it - Information Technology},
}

@article{bhatti_policy_2008,
	title = {Policy Mapper: Administering Location-Based Access-Control Policies},
	volume = {12},
	issn = {1941-0131},
	doi = {10.1109/MIC.2008.40},
	shorttitle = {Policy Mapper},
	abstract = {Simplifying the administration of location-based access-control policies requires a mechanism that supports both intuitive and scalable spatial constraint specifications and a flexible enforcement architecture. Policy mapper is an administrative tool that helps define access control at conceptual and logical levels to carry out constraint specification and enforcement. The tool also provides an interface definition language that couples the two levels. Policy mapper bridges a critical gap between the expressiveness and enforcement of spatial constraints in location-based access-control policies.},
	pages = {38--45},
	number = {2},
	journaltitle = {{IEEE} Internet Computing},
	author = {Bhatti, R. and Damiani, M. L. and Bettis, D. W. and Bertino, E.},
	date = {2008-03},
	note = {Conference Name: {IEEE} Internet Computing},
	keywords = {access control, Access control, authorisation, Information security, Bridges, Hospitals, Management information systems, Context modeling, interface definition language, location-based access control, location-based constraints, mobile computing, policy administration, policy mapper, Radiofrequency identification, Road accidents, Road transportation, spatial constraint specifications, Vocabulary},
}

@incollection{emig_model-driven_2008,
	location = {Orlando, Florida, {USA}},
	title = {Model-Driven Development of Access Control Policies for Web Services},
	rights = {https://epub.uni-regensburg.de/licenses/lic\_without\_pod.html},
	isbn = {978-0-88986-775-8},
	url = {http://digbib.ubka.uni-karlsruhe.de/volltexte/documents/578164},
	abstract = {Web service-oriented architecture ({WSOA}) is a promising paradigm for future software development. Necessary identity management ({IdM}) architectures for {WSOA} are just being prepared to enable fine-grained access control. With the loose coupling of Web services with crosscutting identity services the question arises how to develop access control policies for Web services. In this paper we present a model-driven approach defining access control policies which are independent from the {IdM} architecture to which they are later applied. Therefore we develop a platform-independent access control model for {WSOA} and derive a platform-specific model from a given {IdM} product. We show how to map both models to a concrete language. Access control policies are then defined using our platform-independent language and transformed to platform-specific policies using explicitly defined transformation rules. We present a case study that applies our approach.},
	pages = {165--171},
	booktitle = {Proceedings of the 9th {IASTED} International Conference Software Engineering and Applications},
	author = {Emig, Christian and Kreuzer, Sebastian and Abeck, Sebastian and Biermann, Jürgen and Klarl, Heiko},
	editor = {Khoshgoftaar, T.},
	urldate = {2021-01-05},
	date = {2008-11},
	langid = {english},
}

@inproceedings{evered_case_2004,
	location = {{AUS}},
	title = {A case study in access control requirements for a Health Information System},
	series = {{ACSW} Frontiers '04},
	abstract = {We present a detailed examination of the access constraints for a small real-world Health Information System with the aim of achieving minimal access rights for each of the involved principals. We show that, even for such a relatively simple system, the resulting constraints are very complex and cannot be expressed easily or clearly using the static per-method access control lists generally supported by component-based software. We derive general requirements for the expressiveness of access constraints and propose criteria for a more suitable access control mechanism in the context of component-based systems. We describe a two-level mechanism which can fulfil these criteria.},
	pages = {53--61},
	booktitle = {Proceedings of the second workshop on Australasian information security, Data Mining and Web Intelligence, and Software Internationalisation - Volume 32},
	publisher = {Australian Computer Society, Inc.},
	author = {Evered, Mark and Bögeholz, Serge},
	urldate = {2021-01-05},
	date = {2004-01-01},
	keywords = {access control, component, Health Information System},
}

@article{he_requirements-based_2009,
	title = {Requirements-based Access Control Analysis and Policy Specification ({ReCAPS})},
	volume = {51},
	issn = {0950-5849},
	url = {http://www.sciencedirect.com/science/article/pii/S0950584908001699},
	doi = {10.1016/j.infsof.2008.11.005},
	abstract = {Access control ({AC}) is a mechanism for achieving confidentiality and integrity in software systems. Access control policies ({ACPs}) express rules concerning who can access what information, and under what conditions. {ACP} specification is not an explicit part of the software development process and is often isolated from requirements analysis activities, leaving systems vulnerable to security breaches because policies are specified without ensuring compliance with system requirements. In this paper, we present the Requirements-based Access Control Analysis and Policy Specification ({ReCAPS}) method for deriving and specifying {ACPs}, and discuss three validation efforts. The method integrates policy specification into the software development process, ensures consistency across software artifacts, and provides prescriptive guidance for how to specify {ACPs}. It also improves the quality of requirements specifications and system designs by clarifying ambiguities and resolving conflicts across these artifacts during the analysis, making a significant step towards ensuring that policies are enforced in a manner consistent with a system’s requirements specifications. To date, the method has been applied within the context of four operational systems. Additionally, we have conducted an empirical study to evaluate its usefulness and effectiveness. A software tool, the Security and Privacy Requirements Analysis Tool ({SPRAT}), was developed to support {ReCAPS} analysis activities.},
	pages = {993--1009},
	number = {6},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {He, Qingfeng and Antón, Annie I.},
	urldate = {2021-01-05},
	date = {2009-06-01},
	langid = {english},
	keywords = {Access control, Security, Requirements analysis},
}

@inproceedings{lee_technology_2015,
	title = {Technology trends of access control in {IoT} and requirements analysis},
	doi = {10.1109/ICTC.2015.7354730},
	abstract = {Since {IoT} devices can cause problems, such as invasion of privacy and threat to our safety, security in {IoT} is the most important element. {IoT} is an environment in which various devices to communicate an environment in which various devices communicate with one another without user intervention or with minimal user intervention. Therefore, authentication and access control technology between {IoT} devices are important element in the {IoT} security. In this paper, we describe our survey of access control technique in {IoT} environment and requirements of it.},
	eventtitle = {2015 International Conference on Information and Communication Technology Convergence ({ICTC})},
	pages = {1031--1033},
	booktitle = {2015 International Conference on Information and Communication Technology Convergence ({ICTC})},
	author = {Lee, Y. and Lim, J. and Jeon, Y. and Kim, J.},
	date = {2015-10},
	keywords = {access control, Access control, authorisation, Servers, Internet of Things, authentication, Internet, data privacy, formal specification, access control in {IoT}, Consumer electronics, Context, {IoT} devices, {IoT} security, {IoT}(Internet of Things), Market research, minimal user intervention, privacy invasion, requirements analysis, safety threat, security threat},
}

@inproceedings{decker_requirements_2008,
	location = {New York, {NY}, {USA}},
	title = {Requirements for a location-based access control model},
	isbn = {978-1-60558-269-6},
	url = {https://doi.org/10.1145/1497185.1497259},
	doi = {10.1145/1497185.1497259},
	series = {{MoMM} '08},
	abstract = {Location-based access control ({LBAC}) takes a mobile user's current position into account when making the decision if he should be allowed to access a particular resource like a file or service. For example using {LBAC} we can enforce that a nurse is only allowed to view a patient's data using a {PDA} when she stays at the premises of the hospital. There are a couple of research papers that propose data models for {LBAC}; almost all of them are extensions of Role-based Access Control ({RBAC}). In the paper at hand we first motivate the employment of {LBAC} by some application scenarios before we review the most important {LBAC}-models. Despite the body of research in the field of {LBAC} we could identify requirements that cannot be covered with the available models; these requirements are discussed in detail.},
	pages = {346--349},
	booktitle = {Proceedings of the 6th International Conference on Advances in Mobile Computing and Multimedia},
	publisher = {Association for Computing Machinery},
	author = {Decker, Michael},
	urldate = {2021-01-05},
	date = {2008-11-24},
	keywords = {access control, location-based services, mobile computing, security model},
}

@inproceedings{crook_security_2002,
	title = {Security requirements engineering: when anti-requirements hit the fan},
	doi = {10.1109/ICRE.2002.1048527},
	shorttitle = {Security requirements engineering},
	abstract = {Everyone agrees that security is a problem, ranging from Microsoft to the banks that have been recent victims of rogue traders. What is paradoxical is that there does not seem to be a wholehearted commitment by both academics and industry to treat this topic systematically at the top level of requirements engineering. Our vision is of a future in which we inform the security requirements engineering process by organisational theory. This would act as the bridge between the well-ordered world of the software project informed by conventional requirements and the unexpected world of anti-requirements associated with the malicious user. We frame a vision for the requirements engineering community that would involve the community solving six difficult problems.},
	eventtitle = {Proceedings {IEEE} Joint International Conference on Requirements Engineering},
	pages = {203--205},
	booktitle = {Proceedings {IEEE} Joint International Conference on Requirements Engineering},
	author = {Crook, R. and Ince, D. and {Luncheng Lin} and Nuseibeh, B.},
	date = {2002-09},
	note = {{ISSN}: 1090-705X},
	keywords = {Access control, Information security, Electrical equipment industry, Bridges, systems analysis, Privacy, security of data, formal specification, Information systems, anti-requirements, Availability, Face detection, information security, Maintenance engineering, malicious user, organisational theory, Protection, security requirements engineering, software project},
}

@inproceedings{massacci_model-driven_2008,
	location = {Berlin, Heidelberg},
	title = {A Model-Driven Approach for the Specification and Analysis of Access Control Policies},
	isbn = {978-3-540-88873-4},
	doi = {10.1007/978-3-540-88873-4_11},
	series = {Lecture Notes in Computer Science},
	abstract = {The last years have seen the definition of many languages, models and standards tailored to specify and enforce access control policies, but such frameworks do not provide methodological support during the policy specification process. In particular, they do not provide facilities for the analysis of the social context where the system operates.In this paper we propose a model-driven approach for the specification and analysis of access control policies. We build this framework on top of {SI}*, a modeling language tailored to capture and analyze functional and security requirements of socio-technical systems. The framework also provides formal mechanisms to assist policy writers and system administrators in the verification of access control policies and of the actual user-permission assignment.},
	pages = {1087--1103},
	booktitle = {On the Move to Meaningful Internet Systems: {OTM} 2008},
	publisher = {Springer},
	author = {Massacci, Fabio and Zannone, Nicola},
	editor = {Meersman, Robert and Tari, Zahir},
	date = {2008},
	langid = {english},
	keywords = {Access Control, Policy Specification, Security Requirements Engineering},
}

@inproceedings{zhao_policy_2011,
	title = {Policy refinement of network services for {MANETs}},
	doi = {10.1109/INM.2011.5990681},
	abstract = {In this paper, we describe a framework for a refinement scheme located in a centralized policy server that consists of three components: a knowledge database, a refinement rule set, and a policy repository. The refinement process includes two successive steps: policy transformation and policy composition. Our refinement scheme takes policies written in our logic-based abstract policy language as input and generates low level rules directly implementable by individual enforcement points. We provide concrete policy examples in a coalition scenario that forms a mobile ad hoc network ({MANET}). We demonstrate policy composition using a distributed firewall scheme named {ROFL} ({ROuting} as the Firewall Layer) and access control list as enforcement mechanisms.},
	eventtitle = {12th {IFIP}/{IEEE} International Symposium on Integrated Network Management ({IM} 2011) and Workshops},
	pages = {113--120},
	booktitle = {12th {IFIP}/{IEEE} International Symposium on Integrated Network Management ({IM} 2011) and Workshops},
	author = {Zhao, H. and Lobo, J. and Roy, A. and Bellovin, S. M.},
	date = {2011-05},
	keywords = {authorisation, Databases, Authorization, access control list, Ad hoc networks, centralized policy server, Cryptography, distributed firewall scheme, enforcement mechanism, Fires, knowledge database, Laboratories, logic-based abstract policy language, {MANET}, {MANETs}, mobile ad hoc network, mobile ad hoc networks, Mobile computing, network services, Policy, policy composition, policy refinement, policy repository, policy transformation, Refinement, refinement rule set, routing as the firewall layer, telecommunication security},
}

@article{riekstin_survey_2016,
	title = {A Survey of Policy Refinement Methods as a Support for Sustainable Networks},
	volume = {18},
	issn = {1553-877X},
	doi = {10.1109/COMST.2015.2463811},
	abstract = {Green sustainability-oriented features have become common in network nodes and protocols. Running a network in an energy-efficient way is an important concern of network operators and datacenter networks. The implementation and coordination of the myriad of existing network features poses a challenging task. The energy efficiency capabilities must be selected according to the network conditions and can be combined to increase energy savings. However, they can conflict if not orchestrated in a proper manner. Policy-Based Network Management is a well-known approach to addressing the complexity of network management tasks. In conjunction with a refinement process to translate high-level policies down to low-level policies, it can bring business directives to the network, including sustainability goals. In this survey, we identify the major characteristics of sustainability-oriented policies, as well as the requirements a policy refinement method for such type of policies has to fulfill, including energy efficiency capabilities orchestration. We then analyze existing policy refinement techniques and discuss the challenges on how they address or need to be modified in order to be applicable to sustainability-oriented policies.},
	pages = {222--235},
	number = {1},
	journaltitle = {{IEEE} Communications Surveys Tutorials},
	author = {Riekstin, A. C. and Januário, G. C. and Rodrigues, B. B. and Nascimento, V. T. and Carvalho, T. C. M. d B. and Meirosu, C.},
	date = {2016},
	note = {Conference Name: {IEEE} Communications Surveys Tutorials},
	keywords = {Quality of service, Business, policy refinement, Automation, Complexity theory, computer centres, datacenter network protocol, energy conservation, energy efficiency, Energy Efficiency, green computing, Green products, green sustainability-oriented feature, management, Networks, Object oriented modeling, Policy Refinement, policy refinement method, policy-based network management, power aware computing, sustainability, sustainable network node, Tutorials},
}

@inproceedings{machado_towards_2014,
	title = {Towards {SLA} Policy Refinement for {QoS} Management in Software-Defined Networking},
	doi = {10.1109/AINA.2014.148},
	abstract = {Software-Defined Networking ({SDN}) is a dynamic, adaptable, controllable and flexible network architecture. It provides an extensible platform for delivery of network services, capable of responding quickly to service requirement changes. As a result, {SDN} has become a suitable scenario for the application of techniques and approaches for improved infrastructure management, such as Policy-Based Management ({PBM}). In {PBM}, using techniques such as refinement, a high-level policy-e.g., specified as a Service Level Agreement ({SLA}) - can be translated into a set of corresponding low-level rules, enforceable in various elements of a system. However, when using {SLAs}, their translation to low-level policies, e.g., for controller configuration, is not straightforward. If this translation is not done properly, the controller may not be able to meet the implicit requirements of the {SLA}, failing to satisfy the goals described in the high-level policy. This paper proposes a novel approach towards {SLA} policy refinement for Quality of Service ({QoS}) management (based on routing) in Software-Defined Networking. It consists of an initial manual process performed by an administrator, followed by an automatic policy refinement process executed by an {OpenFlow} controller. As a result, our approach is capable of identifying the requirements and resources that need to be configured in accordance with {SLA} refinement, and can successfully configure and execute reactive dynamic actions for supporting dynamic infrastructure reconfiguration.},
	eventtitle = {2014 {IEEE} 28th International Conference on Advanced Information Networking and Applications},
	pages = {397--404},
	booktitle = {2014 {IEEE} 28th International Conference on Advanced Information Networking and Applications},
	author = {Machado, C. C. and Granville, L. Z. and Schaeffer-Filho, A. and Wickboldt, J. A.},
	date = {2014-05},
	note = {{ISSN}: 2332-5658},
	keywords = {computer networks, quality of service, Quality of service, Process control, contracts, service level agreement, network services, management, Delays, infrastructure management, Jitter, Manuals, network architecture, openflow controller, {PBM}, Platinum, policy, policy-based management, Protocols, {QoS} management, refinement, sdn, {SDN}, {SLA} policy refinement, software-defined networking, virtualisation},
}

@article{cheminod_comprehensive_2019,
	title = {A comprehensive approach to the automatic refinement and verification of access control policies},
	volume = {80},
	issn = {0167-4048},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167404818303870},
	doi = {10.1016/j.cose.2018.09.013},
	abstract = {Access control is one of the building blocks of network security and is often managed by network administrators through the definition of sets of high-level policies meant to regulate network behavior (policy-based management). In this scenario, policy refinement and verification are important processes that have to be dealt with carefully, possibly relaying on computer-aided automated software tools. This paper presents a comprehensive approach for access control policy refinement, verification and, in case errors are detected in the policy implementation, their fixing. The proposed methodology is based on a twofold model able to describe both policies and system configurations and allows, by suitably processing the model, to either propose a system configuration that correctly enforces the policies, or determine whether a specific implementation matches the policy specification also providing hints on how possible anomalies can be fixed. Results on the average complexity of the solution confirm its feasibility in terms of computation time, even for complex networked systems consisting of several hundred nodes.},
	pages = {186--199},
	journaltitle = {Computers \& Security},
	shortjournal = {Computers \& Security},
	author = {Cheminod, Manuel and Durante, Luca and Seno, Lucia and Valenza, Fulvio and Valenzano, Adriano},
	urldate = {2021-01-05},
	date = {2019-01-01},
	langid = {english},
	keywords = {Access control, Policy refinement, Policy verification, Policy-based network management},
}

@report{moore_rfc_2001,
	title = {{RFC} 3060 - Policy Core Information Model -- Version 1 Specification},
	url = {https://www.rfc-editor.org/info/rfc3060},
	abstract = {This document presents the object-oriented information model for representing policy information developed jointly in the {IETF} Policy Framework {WG} and as extensions to the Common Information Model ({CIM}) activity in the Distributed Management Task Force ({DMTF}). This model defines two hierarchies of object classes: structural classes representing policy information and control of policies, and association classes that indicate how instances of the structural classes are related to each other. Subsequent documents will define mappings of this information model to various concrete implementations, for example, to a directory that uses {LDAPv}3 as its access protocol.},
	pages = {RFC3060},
	number = {{RFC}3060},
	institution = {{RFC} Editor},
	author = {Moore, B. and Ellesson, E. and Strassner, J. and Westerinen, A.},
	urldate = {2021-01-07},
	date = {2001-02},
	langid = {english},
	doi = {10.17487/rfc3060},
}

@inproceedings{ubayashi_when_2019,
	title = {When and Why Do Software Developers Face Uncertainty?},
	doi = {10.1109/QRS.2019.00045},
	abstract = {Recently, many developers begin to notice that uncertainty is a crucial problem in software development. Unfortunately, no one knows how often uncertainty appears or what kinds of uncertainty exist in actual projects, because there are no empirical studies on uncertainty. To deal with this problem, we conduct a large-scale empirical study analyzing commit messages and revision histories of 1,444 {OSS} projects randomly selected from the {GitHub} repositories. The main findings are as follows: 1) Uncertainty exists in the ratio of 1.44\% (average); 2) Uncertain program behavior, uncertain variable/value/name, and uncertain program defects are major kinds of uncertainty; and 3) Sometimes developers tend to take an action for not resolving but escaping or ignoring uncertainty. Uncertainty exists everywhere in a certain percentage and developers cannot ignore the existence of uncertainty.},
	eventtitle = {2019 {IEEE} 19th International Conference on Software Quality, Reliability and Security ({QRS})},
	pages = {288--299},
	booktitle = {2019 {IEEE} 19th International Conference on Software Quality, Reliability and Security ({QRS})},
	author = {Ubayashi, N. and Kamei, Y. and Sato, R.},
	date = {2019-07},
	keywords = {Uncertainty, Software, Unified modeling language, software developers, software development, software engineering, Dictionaries, Empirical Study, Face, {GitHub} repositories, History, large-scale empirical study, {OSS} projects, {OSS} Projects, public domain software, Solid modeling, uncertain program behavior, uncertain program defects},
}

@article{famelis_managing_2019,
	title = {Managing design-time uncertainty},
	volume = {18},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-017-0594-9},
	doi = {10.1007/s10270-017-0594-9},
	abstract = {Managing design-time uncertainty, i.e., uncertainty that developers have about making design decisions, requires creation of “uncertainty-aware” software engineering methodologies. In this paper, we propose a methodological approach for managing uncertainty using partial models. To this end, we identify the stages in the lifecycle of uncertainty-related design decisions and characterize the tasks needed to manage it. We encode this information in the Design-Time Uncertainty Management ({DeTUM}) model. We then use the {DeTUM} model to create a coherent, tool-supported methodology centred around partial model management. We demonstrate the effectiveness and feasibility of our methodology through case studies.},
	pages = {1249--1284},
	number = {2},
	journaltitle = {Software \& Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Famelis, Michalis and Chechik, Marsha},
	urldate = {2021-01-18},
	date = {2019-04-01},
	langid = {english},
}

@inproceedings{neisse_model-based_2013,
	title = {Model-based specification and refinement of usage control policies},
	doi = {10.1109/PST.2013.6596051},
	abstract = {In existing usage control policy frameworks, policies consisting of authorizations and obligations are specified at a low level of abstraction. As a consequence, these policy specifications become long and complex since they reference many technical elements of the system such as operating system calls or web-service invocations. Due to this complexity, it is difficult for policy authors to assess if the policies they specify are complete and correct in order to achieve their high-level usage control goals. In this paper we describe our approach for specification and refinement of usage control policies that addresses this complexity problem. In our approach, high-level usage control policies are specified considering an abstract system model and automatically refined with the help of policy refinement rules to implementation-level policies. The input of our refinement rules is the abstract system model, the concrete system model, the system refinement steps from abstract to concrete, and the abstract usage control policies. We show the application of our approach in a case study of a supply chain scenario implemented using {BPMN}. In our case study high-level usage control policies are automatically refined to implementation-level policies that can be enforced in a {BPMN} engine.},
	eventtitle = {2013 Eleventh Annual Conference on Privacy, Security and Trust},
	pages = {169--176},
	booktitle = {2013 Eleventh Annual Conference on Privacy, Security and Trust},
	author = {Neisse, R. and Doerr, J.},
	date = {2013-07},
	keywords = {authorisation, Security, formal specification, business data processing, Engines, abstract system model, Abstracts, authorizations, {BPMN} engine, business process model and notation, Concrete, concrete system model, high-level usage control policies, implementation-level policies, model-based specification, obligations, Operating systems, policy specifications, supply chain scenario, supply chains, Supply chains, System analysis and design, usage control policies refinement},
}

@inproceedings{linying_su_automated_2005,
	title = {Automated decomposition of access control policies},
	doi = {10.1109/POLICY.2005.10},
	abstract = {Modern dynamic distributed information systems need access control policies to address controlling access to multiple resources that are distributed. The resources may be considered as a single abstract hierarchical resource. An access control policy at a high level should be able to define who is allowed to use the resources. At tower levels, the policy will address controlling access to concrete resources. By modelling the resource hierarchy, it is possible that low level policies can be automatically produced from the high level policy. These low level policies can then be distributed to the concrete resources that use an existing policy based access control decision system so that the high level policy can be enforced throughout the system. In this paper a model for representing and refining high level policies is presented. Other relevant issues and examples for demonstrating the capability of the policy decomposition (refinement) process are also presented.},
	eventtitle = {Sixth {IEEE} International Workshop on Policies for Distributed Systems and Networks ({POLICY}'05)},
	pages = {3--13},
	booktitle = {Sixth {IEEE} International Workshop on Policies for Distributed Systems and Networks ({POLICY}'05)},
	author = {{Linying Su} and Chadwick, D. W. and Basden, A. and Cunningham, J. A.},
	date = {2005-06},
	keywords = {Access control, authorisation, Control systems, Security, Authorization, Internet, Decision making, Laboratories, information systems, Concrete, access control decision system, access control policy, automated decomposition, Automatic control, Distributed information systems, distributed processing, dynamic distributed information systems, policy decomposition, resource allocation, resource hierarchy modelling},
}

@inproceedings{jayaraman_automatic_2011,
	location = {New York, {NY}, {USA}},
	title = {Automatic error finding in access-control policies},
	isbn = {978-1-4503-0948-6},
	url = {https://doi.org/10.1145/2046707.2046727},
	doi = {10.1145/2046707.2046727},
	series = {{CCS} '11},
	abstract = {Verifying that access-control systems maintain desired security properties is recognized as an important problem in security. Enterprise access-control systems have grown to protect tens of thousands of resources, and there is a need for verification to scale commensurately. We present a new abstraction-refinement technique for automatically finding errors in Administrative Role-Based Access Control ({ARBAC}) security policies. {ARBAC} is the first and most comprehensive administrative scheme for Role-Based Access Control ({RBAC}) systems. Underlying our approach is a change in mindset: we propose that error finding complements verification, can be more scalable, and allows for the use of a wider variety of techniques. In our approach, we use an abstraction-refinement technique to first identify and discard roles that are unlikely to be relevant to the verification question (the abstraction step), and then restore such abstracted roles incrementally (the refinement steps). Errors are one-sided: if there is an error in the abstracted policy, then there is an error in the original policy. If there is an error in a policy whose role-dependency graph diameter is smaller than a certain bound, then we find the error. Our abstraction-refinement technique complements conventional state-space exploration techniques such as model checking. We have implemented our technique in an access-control policy analysis tool. We show empirically that our tool scales well to realistic policies, and is orders of magnitude faster than prior tools.},
	pages = {163--174},
	booktitle = {Proceedings of the 18th {ACM} conference on Computer and communications security},
	publisher = {Association for Computing Machinery},
	author = {Jayaraman, Karthick and Ganesh, Vijay and Tripunitara, Mahesh and Rinard, Martin and Chapin, Steve},
	urldate = {2021-01-18},
	date = {2011-10-17},
	keywords = {access control, model checking, program verification},
}

@inproceedings{solhaug_compositional_2008,
	location = {Berlin, Heidelberg},
	title = {Compositional Refinement of Policies in {UML} – Exemplified for Access Control},
	isbn = {978-3-540-88313-5},
	doi = {10.1007/978-3-540-88313-5_20},
	series = {Lecture Notes in Computer Science},
	abstract = {The {UML} is the de facto standard for system specification, but offers little specialized support for the specification and analysis of policies. This paper presents Deontic {STAIRS}, an extension of the {UML} sequence diagram notation with customized constructs for policy specification. The notation is underpinned by a denotational trace semantics. We formally define what it means that a system satisfies a policy specification, and introduce a notion of policy refinement. We prove that the refinement relation is transitive and compositional, thus supporting a stepwise and modular specification process. The approach is exemplified with access control policies.},
	pages = {300--316},
	booktitle = {Computer Security - {ESORICS} 2008},
	publisher = {Springer},
	author = {Solhaug, Bjørnar and Stølen, Ketil},
	editor = {Jajodia, Sushil and Lopez, Javier},
	date = {2008},
	langid = {english},
	keywords = {access control, policy refinement, policy adherence, Policy specification, {UML} sequence diagrams},
}

@inproceedings{yang_security_2013,
	title = {Security Policy Refinement: High-Level Specification to Low-Level Implementation},
	doi = {10.1109/SocialCom.2013.77},
	shorttitle = {Security Policy Refinement},
	abstract = {Security and privacy policies are stated in the context of abstract concepts such as users/roles, objects and actions that relate to a specific level of abstraction in the system design. Refinement of the abstract design down to lower level implementations can result in a disconnect between the implementation and the more abstract security policy. In this paper we introduce the concept of security policy refinement for access control policies that allows us to maintain a tighter coupling between the security policy and its implementation. We use a purpose-based privacy policy as an example to explain the concepts. The resulting refinement technique provides for improved verification and validation that the system, as implemented, satisfies the abstract security policy, and sets the stage for further research in this area.},
	eventtitle = {2013 International Conference on Social Computing},
	pages = {502--511},
	booktitle = {2013 International Conference on Social Computing},
	author = {Yang, X. and Alves-Foss, J.},
	date = {2013-09},
	keywords = {Access control, authorisation, Data privacy, Privacy, formal verification, formal specification, Hardware, refinement, Abstracts, access control policy, abstract design, Electronic mail, high-level specification, purpose-based privacy policy, purpose-based security, security policy, security policy refinement},
}

@inproceedings{hahner_dealing_2021,
	location = {Virtual},
	title = {Dealing with Uncertainty in Architectural Confidentiality Analysis},
	eventtitle = {8th Collaborative Workshop on Evolution and Maintenance of Long-Living Software Systems ({EMLS})},
	pages = {1--6},
	booktitle = {Proceedings of the Software Engineering 2021 Satellite Events},
	publisher = {Gesellschaft für Informatik},
	author = {Hahner, Sebastian},
	date = {2021},
}

@online{council_of_european_union_regulation_2016,
	title = {{REGULATION} ({EU}) 2016/679 (General Data Protection Regulation)},
	url = {https://eur-lex.europa.eu/eli/reg/2016/679/2016-05-04},
	author = {Council of European Union},
	urldate = {2021-01-19},
	date = {2016},
	langid = {english},
}

@incollection{bertolino_toolchain_2014,
	location = {Cham},
	title = {A Toolchain for Designing and Testing Access Control Policies},
	isbn = {978-3-319-07452-8},
	url = {https://doi.org/10.1007/978-3-319-07452-8_11},
	series = {Lecture Notes in Computer Science},
	abstract = {Security is an important aspect of modern information management systems. The crucial role of security in this systems demands the use of tools and applications that are thoroughly validated and verified. However, the testing phase is an effort consuming activity that requires reliable supporting tools for speeding up this costly stage. Access control systems, based on the integration of new and existing tools are available in the Service Development Environment ({SDE}). We introduce an Access Control Testing toolchain ({ACT}) for designing and testing access control policies that includes the following features: (i) the graphical specification of an access control model and its translation into an {XACML} policy; (ii) the derivation of test cases and their execution against the {XACML} policy; (iii) the assessment of compliance between the {XACML} policy execution and the access control model. In addition, we illustrate the use of the {ACT} toolchain on a case study.},
	pages = {266--286},
	booktitle = {Engineering Secure Future Internet Services and Systems: Current Research},
	publisher = {Springer International Publishing},
	author = {Bertolino, Antonia and Busch, Marianne and Daoudagh, Said and Lonetti, Francesca and Marchetti, Eda},
	editor = {Heisel, Maritta and Joosen, Wouter and Lopez, Javier and Martinelli, Fabio},
	urldate = {2021-01-22},
	date = {2014},
	langid = {english},
	doi = {10.1007/978-3-319-07452-8_11},
	keywords = {Access Control, Access Control System, Authorization Constraint, Policy Decision Point, Test Case Generation},
}

@report{camara_uncertainty_2017,
	title = {Uncertainty in Self-Adaptive Systems: Categories, Management, and Perspectives},
	url = {https://apps.dtic.mil/sti/citations/AD1086752},
	shorttitle = {Uncertainty in Self-Adaptive Systems},
	abstract = {Self-Adaptive systems are expected to adapt to unanticipated run-time events using imperfect information about their environment. This entails handling the effects of uncertainties in decision-making, which are not always considered as a first-class concern. This technical report summarizes a set of existing techniques and insights into addressing uncertainty in self-adaptive systems and outlines a future research agenda on uncertainty management in self-adaptive systems. The material in this report is strongly informed by our own research in the area, and is therefore not necessarily representative of other works.},
	author = {Camara, Javier and Garlan, David and Kang, Won G. and Peng, Wenxin and Schmerl, Bradley},
	urldate = {2021-01-26},
	date = {2017-07-01},
	langid = {english},
}

@article{platenius_imprecise_2017,
	title = {Imprecise Matching of Requirements Specifications for Software Services Using Fuzzy Logic},
	volume = {43},
	issn = {1939-3520},
	doi = {10.1109/TSE.2016.2632115},
	abstract = {Today, software components are provided by global markets in the form of services. In order to optimally satisfy service requesters and service providers, adequate techniques for automatic service matching are needed. However, a requester's requirements may be vague and the information available about a provided service may be incomplete. As a consequence, fuzziness is induced into the matching procedure. The contribution of this paper is the development of a systematic matching procedure that leverages concepts and techniques from fuzzy logic and possibility theory based on our formal distinction between different sources and types of fuzziness in the context of service matching. In contrast to existing methods, our approach is able to deal with imprecision and incompleteness in service specifications and to inform users about the extent of induced fuzziness in order to improve the user's decision-making. We demonstrate our approach on the example of specifications for service reputation based on ratings given by previous users. Our evaluation based on real service ratings shows the utility and applicability of our approach.},
	pages = {739--759},
	number = {8},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Platenius, M. C. and Shaker, A. and Becker, M. and Hüllermeier, E. and Schäfer, W.},
	date = {2017-08},
	note = {Conference Name: {IEEE} Transactions on Software Engineering},
	keywords = {uncertainty, Uncertainty, Fuzzy logic, Security, Software, software engineering, Software engineering, fuzzy logic, decision making, Decision making, Context, automatic service matching, fuzzy set theory, non-functional properties, pattern matching, possibility theory, requirement specification imprecise matching, requirements specifications, service matching, Service selection, software components, software services, user decision-making},
}

@inproceedings{tsigkanos_towards_2019,
	title = {Towards Resilient Internet of Things: Vision, Challenges, and Research Roadmap},
	doi = {10.1109/ICDCS.2019.00174},
	shorttitle = {Towards Resilient Internet of Things},
	abstract = {Internet of Things ({IoT}) systems open up massive versatility and opportunity to our world. Providing solutions for smart cities, healthcare, energy, and mobility, such systems increasingly permeate critical aspects of human activity. In a flourish of growth, these complex systems run software, are dynamic, without stable spatial and temporal boundaries, and involve mostly independent software components with different lifespans and evolution models. {IoT} systems provide data-centric, device-centric and service-centric functionalities that are subject to continuous disruption, under limitations such as resource-constrained devices, platforms heterogeneity, deployment in adverse environments and administrative domains. As these systems evolve and gain complexity, resilience becomes a crucial system property. Bolstering resilience entails understanding and systematically managing dynamic behavior and decentralizing operations. We advocate that to systematically engineer resilience in {IoT} systems, a complete rethink is necessary regarding their design and operation. In this paradigm shift, systems demand conceptual frameworks, techniques, and mathematically-backed formalisms to treat change and achieve decentralization. We outline a vision for addressing fundamental challenges that software engineering and distributed systems research encounters when building resilient {IoT} systems. Within a roadmap, we identify techniques and methods that can be leveraged to maintain resilience in the face of disruption, especially in the absence of central control and persistently at the system's runtime.},
	eventtitle = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	pages = {1754--1764},
	booktitle = {2019 {IEEE} 39th International Conference on Distributed Computing Systems ({ICDCS})},
	author = {Tsigkanos, C. and Nastic, S. and Dustdar, S.},
	date = {2019-07},
	note = {{ISSN}: 2575-8411},
	keywords = {Internet of Things, Software, software engineering, Cloud computing, bolstering resilience, building resilient {IoT} systems, complex systems, crucial system property, data-centric, Decentralization, decentralizing operations, Dependability, device-centric, different lifespans, distributed systems research, dynamic behavior, edge computing, evolution models, human activity, independent software components, massive versatility, Mobile handsets, providing solutions, Reliability, Resilience, resource-constrained devices, Runtime, self-adaptive systems, service-centric functionalities, smart cities, stable spatial boundaries, systems demand conceptual frameworks, systems evolve, temporal boundaries, towards resilient internet},
}

@report{al-ali_uncertainty-aware_2020,
	title = {Uncertainty-Aware Self-Adaptive Component Design in Cyber-Physical System},
	url = {/paper/Uncertainty-Aware-Self-Adaptive-Component-Design-in-Al-Ali/4db63d14abfa2cd427a20608517836140c1ab243},
	abstract = {Cyber-physical systems ({CPS}) need to be designed to deal with various forms of uncertainty associated with data contributing to the system’s knowledge of the environment. Dealing with uncertainty requires adopting an appropriate model which then allows making the right decisions and carrying out the right actions (possibly affecting the environment) based on imperfect information. However, choosing and incorporating a suitable model into {CPS} design is difficult, especially for non-experts, because it requires identifying the kind of uncertainty at hand as well as knowledge of suitable models and their application to dealing with the uncertainty. While inspiration can be found in other {CPS} designs, the details of dealing with uncertainty in another {CPS} can be confounded by domain-specific terminology, context, and requirements. To make this aspect of {CPS} design less daunting for non-experts, we aim at providing an overview of approaches dealing with uncertainty in the design of {CPS} targeting collective behavior. To this end, we present a systematic review of relevant scientific projects with industrial leadership and a synthesis of relations between system features, the kinds of uncertainty, and models and methods used to deal with it. The results provide an overview of uncertainty across different domains and challenges and reason about a guide for designing uncertainty-aware self-adaptive components in {CPS}. D3S, Technical Report no. D3S-{TR}-2019-02},
	institution = {Department of Distributed and Dependable Systems},
	author = {Al-Ali, Rima},
	urldate = {2021-01-26},
	date = {2020},
	langid = {english},
}

@inproceedings{calinescu_understanding_2020,
	title = {Understanding Uncertainty in Self-adaptive Systems},
	doi = {10.1109/ACSOS49614.2020.00047},
	abstract = {Ensuring that systems achieve their goals under uncertainty is a key driver for self-adaptation. Nevertheless, the concept of uncertainty in self-adaptive systems ({SAS}) is still insufficiently understood. Although several taxonomies of uncertainty have been proposed, taxonomies alone cannot convey the {SAS} research community's perception of uncertainty. To explore and to learn from this perception, we conducted a survey focused on the {SAS} ability to deal with unanticipated change and to model uncertainty, and on the major challenges that limit this ability. In this paper, we analyse the responses provided by the 51 participants in our survey. The insights gained from this analysis include the view-held by 71\% of our participants-that {SAS} can be engineered to cope with unanticipated change, e.g., through evolving their actions, synthesising new actions, or using default actions to deal with such changes. To handle uncertainties that affect {SAS} models, the participants recommended the use of confidence intervals and probabilities for parametric uncertainty, and the use of multiple models with model averaging or selection for structural uncertainty. Notwithstanding this positive outlook, the provision of assurances for safety-critical {SAS} continues to pose major challenges according to our respondents. We detail these findings in the paper, in the hope that they will inspire valuable future research on self-adaptive systems.},
	eventtitle = {2020 {IEEE} International Conference on Autonomic Computing and Self-Organizing Systems ({ACSOS})},
	pages = {242--251},
	booktitle = {2020 {IEEE} International Conference on Autonomic Computing and Self-Organizing Systems ({ACSOS})},
	author = {Calinescu, R. and Mirandola, R. and Perez-Palacin, D. and Weyns, D.},
	date = {2020-08},
	keywords = {models, uncertainty, Uncertainty, Taxonomy, Encoding, probability, Runtime, self-adaptive systems, Adaptation models, Adaptive systems, default actions, fault tolerant computing, learning (artificial intelligence), learning techniques, modeling formalism, online modeling, parametric uncertainty, probabilities, safety-critical {SAS}, safety-critical software, Self-adaptation, self-adjusting systems, software evolution, software maintenance, structural uncertainty, survey, Synthetic aperture sonar, taxonomies, unanticipated change, uncertainty handling},
}

@inproceedings{lupafya_framework_2019,
	location = {New York, {NY}, {USA}},
	title = {A framework for managing uncertainty in software architecture},
	isbn = {978-1-4503-7142-1},
	url = {https://doi.org/10.1145/3344948.3344954},
	doi = {10.1145/3344948.3344954},
	series = {{ECSA} '19},
	abstract = {Software architecture records key decisions about software systems. Changes to architecture decisions can, therefore, have significant costs. One of the main causes of architecture changes is uncertainty, which is an inherent feature in open, real-world software systems. We hypothesise that capturing uncertainties, as far as they can be predicted, pertaining to structure, behaviour and resources of systems in software architecture and treating them as first-class concerns, would make architecture decisions more resilient to change. Explicitly considering and representing uncertainty in architecture can help developers design for change and minimise architecture erosion as changes invariably occur. In this {PhD} project, we aim to develop a conceptual framework for the management of uncertainty in software architecture. The conceptual framework will be realised in the form of a workbench of tools for managing uncertainty at the architectural level. The effectiveness of the framework and the workbench will be evaluated using case studies. An ideal case study for evaluation will demonstrate different aspects of uncertainty in software architecture. Potential domains under consideration for case studies include wireless sensor networks and health care systems.},
	pages = {71--74},
	booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
	publisher = {Association for Computing Machinery},
	author = {Lupafya, Chawanangwa},
	urldate = {2021-01-26},
	date = {2019-09-09},
	keywords = {uncertainty, software architecture, conceptual framework},
}

@inproceedings{ubayashi_iarch-umc_2018,
	location = {Porto, Portugal},
	title = {{iArch}-U/{MC}: An Uncertainty-Aware Model Checker for Embracing Known Unknowns:},
	isbn = {978-989-758-320-9},
	url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0006889501760184},
	doi = {10.5220/0006889501760184},
	shorttitle = {{iArch}-U/{MC}},
	abstract = {Embracing uncertainty in software development is one of the crucial research topics in software engineering.},
	eventtitle = {13th International Conference on Software Technologies},
	pages = {176--184},
	booktitle = {Proceedings of the 13th International Conference on Software Technologies},
	publisher = {{SCITEPRESS} - Science and Technology Publications},
	author = {Ubayashi, Naoyasu and Kamei, Yasutaka and Sato, Ryosuke},
	urldate = {2021-01-26},
	date = {2018},
	langid = {english},
}

@thesis{busari_modelling_2019,
	title = {Modelling and Analysing Software Requirements and Architecture Decisions under Uncertainty},
	rights = {open},
	url = {https://discovery.ucl.ac.uk/id/eprint/10067421/},
	pagetotal = {364},
	institution = {{UCL} (University College London)},
	type = {Doctoral},
	author = {Busari, Saheed Abiola},
	urldate = {2021-01-26},
	date = {2019-02-28},
}

@thesis{gerking_model-driven_2020,
	title = {Model-Driven Information Flow Security Engineering for Cyber-Physical Systems},
	type = {phdthesis},
	author = {Gerking, Christopher},
	date = {2020},
	langid = {english},
}

@inproceedings{bruns_simple_2007,
	location = {New York, {NY}, {USA}},
	title = {A simple and expressive semantic framework for policy composition in access control},
	isbn = {978-1-59593-887-9},
	url = {https://doi.org/10.1145/1314436.1314439},
	doi = {10.1145/1314436.1314439},
	series = {{FMSE} '07},
	abstract = {In defining large, complex access control policies, one would like to compose sub-policies, perhaps authored by different organizations, into a single global policy. Existing policy composition approaches tend to be ad-hoc, and do not explain whether too many or too few policy combinators have been defined. We define an access controlpolicy as a four-valued predicate that maps accesses to either grant, deny, conflict, or unspecified. These correspond to the four elements of the Belnap bilattice. Functions on this bilattice are then extended to policies to serve as policy combinators. We argue that this approach provides a simple andnatural semantic framework for policy composition, with a minimal but functionally complete set of policy combinators. We define derived, higher-level operators that are convenient for the specification of access control policies, and enable the decoupling of conflict resolution from policy composition. Finally, we propose a basic query language and show that it can reduce important analyses (e.g., conflict analysis) to checks of policy refinement.},
	pages = {12--21},
	booktitle = {Proceedings of the 2007 {ACM} workshop on Formal methods in security engineering},
	publisher = {Association for Computing Machinery},
	author = {Bruns, Glenn and Dantas, Daniel S and Huth, Michael},
	urldate = {2021-01-27},
	date = {2007-11-02},
	keywords = {access-control policy languages, bilattices, multi-valued logic},
}

@article{mery_specication_2007,
	title = {Speciﬁcation and Reﬁnement of Access Control},
	abstract = {We consider the extension of fair event system speciﬁcations by concepts of access control (prohibitions, user rights, and obligations). We give proof rules for verifying that an access control policy is correctly implemented in a system, and consider preservation of access control by reﬁnement of event systems. Prohibitions and obligations are expressed as properties of traces and are preserved by standard reﬁnement notions of event systems. Preservation of user rights is not guaranteed by construction; we propose to combine implementation-level user rights and obligations to implement high-level user rights.},
	pages = {21},
	author = {Mery, Dominique and Merz, Stephan},
	date = {2007},
	langid = {english},
}

@inproceedings{tschantz_towards_2006,
	location = {New York, {NY}, {USA}},
	title = {Towards reasonability properties for access-control policy languages},
	isbn = {978-1-59593-353-9},
	url = {https://doi.org/10.1145/1133058.1133081},
	doi = {10.1145/1133058.1133081},
	series = {{SACMAT} '06},
	abstract = {The growing importance of access control has led to the definition of numerous languages for specifying policies. Since these languages are based on different foundations, language users and designers would benefit from formal means to compare them. We present a set of properties that examine the behavior of policies under enlarged requests, policy growth, and policy decomposition. They therefore suggest whether policies written in these languages are easier or harder to reason about under various circumstances. We then evaluate multiple policy languages, including {XACML} and Lithium, using these properties.},
	pages = {160--169},
	booktitle = {Proceedings of the eleventh {ACM} symposium on Access control models and technologies},
	publisher = {Association for Computing Machinery},
	author = {Tschantz, Michael Carl and Krishnamurthi, Shriram},
	urldate = {2021-01-27},
	date = {2006-06-07},
	keywords = {access control, policy, modularity},
}

@inproceedings{stouls_security_2006,
	location = {Berlin, Heidelberg},
	title = {Security Policy Enforcement Through Refinement Process},
	isbn = {978-3-540-68761-0},
	doi = {10.1007/11955757_18},
	series = {Lecture Notes in Computer Science},
	abstract = {In the area of networks, a common method to enforce a security policy expressed in a high-level language is based on an ad-hoc and manual rewriting process [24]. We argue that it is possible to build a formal link between concrete and abstract terms, which can be dynamically computed from the environment data. In order to progressively introduce configuration data and then simplify the proof obligations, we use the B refinement process. We present a case study modeling a network monitor. This program, described by refinement following the layers of the {TCP}/{IP} suite protocol, has to warn for all observed events which do not respect the security policy. To design this model, we use the event-B method because it is suitable for modeling network concepts.This work has been done within the framework of the {POTESTAT} project [9], based on the research of network testing methods from a high-level security policy.},
	pages = {216--231},
	booktitle = {B 2007: Formal Specification and Development in B},
	publisher = {Springer},
	author = {Stouls, Nicolas and Potet, Marie-Laure},
	editor = {Julliand, Jacques and Kouchnarenko, Olga},
	date = {2006},
	langid = {english},
	keywords = {refinement, Security policy enforcement, {TCP}/{IP} layers},
}

@article{mohammad_formal_2011,
	title = {A formal approach for the specification and verification of trustworthy component-based systems},
	volume = {84},
	issn = {0164-1212},
	url = {http://www.sciencedirect.com/science/article/pii/S0164121210002384},
	doi = {10.1016/j.jss.2010.08.048},
	series = {Information Networking and Software Services},
	abstract = {Software systems are increasingly becoming ubiquitous affecting the way we experience the world. Embedded software systems, especially those used in smart devices, have become an essential constituent of the technological infrastructure of modern societies. Such systems, in order to be trusted in society, must be proved to be trustworthy. Trustworthiness is a composite non-functional property that implies safety, timeliness, security, availability, and reliability. This paper presents a formal approach for the development of trustworthy component-based systems. The approach involves a formal component model for the specification of component’s structure, functional, and non-functional (trustworthiness) properties, a model transformation technique for the automatic generation of component behavior using the specified structure and restricted by the specified properties, and a unified formal verification method for safety, security, reliability and availability properties using model checking.},
	pages = {77--104},
	number = {1},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Mohammad, Mubarak and Alagar, Vangalur},
	urldate = {2021-01-28},
	date = {2011-01-01},
	langid = {english},
	keywords = {Component model, Component-based development, Formal verification, Trustworthiness},
}

@article{noppen_jar_software_2008,
	title = {Software development with imperfect information},
	volume = {12},
	issn = {1433-7479},
	url = {https://research.utwente.nl/en/publications/software-development-with-imperfect-information(8a5cc06d-5c44-4754-9e59-4861494184af).html},
	doi = {10.1007/s00500-007-0214-7},
	abstract = {Delivering software systems that fulfill all requirements of the stakeholders is very difficult, if not at all impossible. We consider the problem of coping with imperfect information, like interpreting incomplete requirement specifications or vagueness in decisions, one of the main reasons that makes software design difficult. We define a method for tracing design decisions under imperfect information. To model and compare requirements with estimations, we present fuzzy and stochastic techniques. This approach offers adequate decision support that can deal with imperfect information during software design. The approach is illustrated by a real-world example, based on a storm surge barrier system.},
	pages = {3--28},
	number = {1},
	journaltitle = {Soft computing},
	author = {{Noppen, J.A.R.} and {van den Broek, P.M.} and {Aksit, Mehmet}},
	urldate = {2021-01-28},
	date = {2008-01},
	note = {Publisher: Springer},
	keywords = {{EWI}-11952, {IR}-60221, {METIS}-255935},
}

@article{breu_model_2007,
	title = {Model based development of access policies},
	volume = {9},
	issn = {1433-2787},
	url = {https://doi.org/10.1007/s10009-007-0045-y},
	doi = {10.1007/s10009-007-0045-y},
	abstract = {In this paper we present a novel approach for the specification of user rights in the context of an object oriented use case driven development process. Basically, we extend the specification of methods by a permission section describing the right of some actor to call the method of an object. Our approach is both role based and context based while allowing for permissions to be specified at a fine-grained data-dependent level. We use first-order logic with a built-in notion of objects and classes (provided with an algebraic semantics) as our syntactic and semantic framework. In the second part of the paper, we demonstrate the application of this approach in a model-based context to generate permissions in distributed peer-to-peer networks.},
	pages = {457--470},
	number = {5},
	journaltitle = {International Journal on Software Tools for Technology Transfer},
	shortjournal = {Int J Softw Tools Technol Transf},
	author = {Breu, Ruth and Popp, Gerhard and Alam, Muhammad},
	urldate = {2021-01-28},
	date = {2007-10-01},
	langid = {english},
}

@inproceedings{ahn_towards_2007,
	location = {New York, {NY}, {USA}},
	title = {Towards realizing a formal {RBAC} model in real systems},
	isbn = {978-1-59593-745-2},
	url = {https://doi.org/10.1145/1266840.1266875},
	doi = {10.1145/1266840.1266875},
	series = {{SACMAT} '07},
	abstract = {There still exists an open question on how formal models can be fully realized in the system development phase. The Model Driven Development ({MDD}) approach has been recently introduced to deal with such a critical issue for building high assurance software systems. There still exists an open question on how formal models can be fully realized in the system development phase. The Model Driven Development ({MDD}) approach has been recently introduced to deal with such a critical issue for building high assurance software systems. The {MDD} approach focuses on the transformation of high-level design models to system implementation modules. However, this emerging development approach lacks an adequate procedure to address security issues derived from formal security models. In this paper, we propose an empirical framework to integrate security model representation, security policy specification, and systematic validation of security model and policy, which would be eventually used for accommodating security concerns during the system development. We also describe how our framework can minimize the gap between security models and the development of secure systems. In addition, we overview a proof-of-concept prototype of our tool that facilitates existing software engineering mechanisms to achieve the above-mentioned features of our framework.},
	pages = {215--224},
	booktitle = {Proceedings of the 12th {ACM} symposium on Access control models and technologies},
	publisher = {Association for Computing Machinery},
	author = {Ahn, Gail-Joon and Hu, Hongxin},
	urldate = {2021-01-28},
	date = {2007-06-20},
	keywords = {access control, policy specification, code generation, model validation},
}

@inproceedings{al_ali_dynamic_2018,
	location = {Cham},
	title = {Dynamic Security Specification Through Autonomic Component Ensembles},
	isbn = {978-3-030-03424-5},
	doi = {10.1007/978-3-030-03424-5_12},
	series = {Lecture Notes in Computer Science},
	abstract = {One of the key properties of autonomic component systems is their dynamicity and context-dependence of their behavior. In contrast to systems with a static architecture, their components interact and collaborate in an ad-hoc fashion depending on their internal state and location, the state of other components and their locations, timing and history of events/state of external (uncontrolled) environment. This high degree of dynamicity collides with traditional approaches to security, which typically rely on static hierarchies of roles and a static assignment of roles. To address this problem, we formulate security rules which are autonomically composable and context-dependent; in their evolution, they follow the dynamicity and context-dependence of the autonomic components. Based on our previous work with autonomic component ensembles, we show how ensembles can be exploited to define security rules to control interactions in a system of autonomic components.},
	pages = {172--185},
	booktitle = {Leveraging Applications of Formal Methods, Verification and Validation. Distributed Systems},
	publisher = {Springer International Publishing},
	author = {Al Ali, Rima and Bures, Tomas and Hnetynka, Petr and Krijt, Filip and Plasil, Frantisek and Vinarek, Jiri},
	editor = {Margaria, Tiziana and Steffen, Bernhard},
	date = {2018},
	langid = {english},
	keywords = {Architecture description language, Autonomic components, Component coalitions, Component ensembles, Smart systems},
}

@article{fink_mda_2006,
	title = {An {MDA} approach to Access Control Specifications Using {MOF} and {UML} Profiles},
	volume = {142},
	issn = {1571-0661},
	url = {http://www.sciencedirect.com/science/article/pii/S1571066105052175},
	doi = {10.1016/j.entcs.2004.12.045},
	series = {Proceedings of the First International Workshop on Views on Designing Complex Architectures ({VODCA} 2004)},
	abstract = {We present a Model Driven Development ({MDD}) approach to the development of access control policies for distributed systems. The models are expressed as Meta-Object Facility ({MOF}) models enriched by Unified Modeling Language ({UML}) profiles. The view-based access control model is used as an example, for which we present a platform independent meta-model and platform specific meta-models for the Java 2 Platform, Enterprise Edition (J2EE). A management application is used to build instance models for the platform independent and platform specific meta-models, respectively. We present in this paper how the platform independent models can be used to generate the platform specific models, and how the meta-models can be used to generate the models for the specific application. Finally, the platform specific models are used to generate the security policy to be deployed in the security infrastructure. We show how consistence requirements can be verified formally by using category-based graph transformations.},
	pages = {161--179},
	journaltitle = {Electronic Notes in Theoretical Computer Science},
	shortjournal = {Electronic Notes in Theoretical Computer Science},
	author = {Fink, Torsten and Koch, Manuel and Pauls, Karl},
	urldate = {2021-01-28},
	date = {2006-01-03},
	langid = {english},
	keywords = {Security, {CORBA}, J2EE, {MDA}, {MDD}, {UML}},
}

@inproceedings{mouelhi_model-based_2008,
	location = {Berlin, Heidelberg},
	title = {A Model-Based Framework for Security Policy Specification, Deployment and Testing},
	isbn = {978-3-540-87875-9},
	doi = {10.1007/978-3-540-87875-9_38},
	series = {Lecture Notes in Computer Science},
	abstract = {In this paper, we propose a model-driven approach for specifying, deploying and testing security policies in Java applications. First, a security policy is specified independently of the underlying access control language ({OrBAC}, {RBAC}). It is based on a generic security meta-model which can be used for early consistency checks in the security policy. This model is then automatically transformed into security policy for the {XACML} platform and integrated in the application using aspect-oriented programming. To qualify test cases that validate the security policy in the application, we inject faults into the policy. The fault model and the fault injection process are defined at the meta-model level, making the qualification process language-independent. Empirical results on 3 case studies explore both the feasibility of the approach and the efficiency of a full design \& test {MDE} process.},
	pages = {537--552},
	booktitle = {Model Driven Engineering Languages and Systems},
	publisher = {Springer},
	author = {Mouelhi, Tejeddine and Fleurey, Franck and Baudry, Benoit and Le Traon, Yves},
	editor = {Czarnecki, Krzysztof and Ober, Ileana and Bruel, Jean-Michel and Uhl, Axel and Völter, Markus},
	date = {2008},
	langid = {english},
	keywords = {Security, Metamodeling, Model-driven engineering methodology},
}

@article{pavlich-mariscal_framework_2010,
	title = {A framework of composable access control features: Preserving separation of access control concerns from models to code},
	volume = {29},
	issn = {0167-4048},
	url = {http://www.sciencedirect.com/science/article/pii/S0167404809001382},
	doi = {10.1016/j.cose.2009.11.005},
	series = {Special issue on software engineering for secure systems},
	shorttitle = {A framework of composable access control features},
	abstract = {Modeling of security policies, along with their realization in code, must be an integral part of the software development process, to achieve an acceptable level of security for a software application. Among all of the security concerns (e.g. authentication, auditing, access control, confidentiality, etc.), this paper addresses the incorporation of access control into software. The approach is to separate access control concerns from the rest of the design. To assist designers to visualize access control policies separated from non-security concerns, this paper proposes a set of access control diagrams, i.e., extensions to the {UML} to represent three main access control models: role-based access control ({RBAC}), mandatory access control ({MAC}), and discretionary access control ({DAC}). To better adapt to changing requirements, and assist designers to customize access control policies, this paper proposes a set of access control features, i.e., small components that realize specific capabilities of access control models. Designers can select the features they require, and compose them to yield different access control policies. When transitioning into code, the main focus is to preserve separation of access control concerns. This paper describes an approach to realize access control diagrams and features in code through structure-preserving mappings, describes three different approaches to enforce access control in code, and evaluates the way each of them separate access control from other concerns.},
	pages = {350--379},
	number = {3},
	journaltitle = {Computers \& Security},
	shortjournal = {Computers \& Security},
	author = {Pavlich-Mariscal, Jaime A. and Demurjian, Steven A. and Michel, Laurent D.},
	urldate = {2021-01-28},
	date = {2010-05-01},
	langid = {english},
	keywords = {Access controls, Software engineering, {UML}, Model-driven development, Separation of concerns},
}

@inproceedings{hinton_prism_2006,
	location = {Berlin, Heidelberg},
	title = {{PRISM}: A Tool for Automatic Verification of Probabilistic Systems},
	isbn = {978-3-540-33057-8},
	doi = {10.1007/11691372_29},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{PRISM}},
	abstract = {Probabilistic model checking is an automatic formal verification technique for analysing quantitative properties of systems which exhibit stochastic behaviour. {PRISM} is a probabilistic model checking tool which has already been successfully deployed in a wide range of application domains, from real-time communication protocols to biological signalling pathways. The tool has recently undergone a significant amount of development. Major additions include facilities to manually explore models, Monte-Carlo discrete-event simulation techniques for approximate model analysis (including support for distributed simulation) and the ability to compute cost- and reward-based measures, e.g. “the expected energy consumption of the system before the first failure occurs”. This paper presents an overview of all the main features of {PRISM}. More information can be found on the website: www.cs.bham.ac.uk/{\textasciitilde}dxp/prism.},
	pages = {441--444},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer},
	author = {Hinton, Andrew and Kwiatkowska, Marta and Norman, Gethin and Parker, David},
	editor = {Hermanns, Holger and Palsberg, Jens},
	date = {2006},
	langid = {english},
}

@inproceedings{gerking_model_2018,
	location = {Cham},
	title = {Model Checking the Information Flow Security of Real-Time Systems},
	isbn = {978-3-319-94496-8},
	doi = {10.1007/978-3-319-94496-8_3},
	series = {Lecture Notes in Computer Science},
	abstract = {Cyber-physical systems are processing large amounts of sensitive information, but are increasingly often becoming the target of cyber attacks. Thus, it is essential to verify the absence of unauthorized information flow at design time before the systems get deployed. Our paper addresses this problem by proposing a novel approach to model-check the information flow security of cyber-physical systems represented by timed automata. We describe the transformation into so-called test automata, reducing the verification to a reachability test that is carried out using the off-the-shelf model checker Uppaal. Opposed to related work, we analyze the real-time behavior of systems, allowing software engineers to precisely identify timing channels that would enable attackers to draw conclusions from the system’s response times. We illustrate the approach by detecting a timing channel in a simplified model of a cyber-manufacturing system.},
	pages = {27--43},
	booktitle = {Engineering Secure Software and Systems},
	publisher = {Springer International Publishing},
	author = {Gerking, Christopher and Schubert, David and Bodden, Eric},
	editor = {Payer, Mathias and Rashid, Awais and Such, Jose M.},
	date = {2018},
	langid = {english},
	keywords = {Security, Information flow, Model checking, Real time},
}

@online{katkalov_modeling_2013,
	title = {Modeling the Travel Planner Application with {IFlow}},
	url = {https://kiv.isse.de/projects/iflow/TravelPlannerSite/index.html},
	author = {Katkalov, Kuzman},
	urldate = {2024-08-15},
	date = {2013},
}

@thesis{laan_incremental_2021,
	title = {Incremental verification of physical access control systems},
	url = {http://essay.utwente.nl/85634/},
	abstract = {Managing physical access control policies is a complex task. To check that policy changes do not introduce security or configuration mistakes, formal verification can be employed. Unfortunately, most existing access control policy verifiers are not designed to analyze evolving policies. They reverify the policy and all policy invariants from scratch after each small change. This is highly inefficient when dealing with evolving policies.  A better approach would be to verify policies incrementally, i.e. to re-use intermediary computations from previous verification attempts.

In this research, we show how policy invariants on realistic evolving physical access control systems can be verified incrementally. This is done with the help of {VIATRA}: an open-source incremental model query and transformation framework based on incremental graph pattern matching. Through extensive benchmarking, we conclude that incremental verification is a promising avenue to speed-up reverification.},
	type = {Master's Thesis},
	author = {Laan, J. H. van der},
	urldate = {2021-02-01},
	date = {2021-01-29},
	langid = {english},
	note = {Publisher: University of Twente},
}

@book{shostack_threat_2014,
	title = {Threat Modeling: Designing for Security},
	isbn = {978-1-118-81005-7},
	shorttitle = {Threat Modeling},
	abstract = {The only security book to be chosen as a Dr. Dobbs Jolt Award Finalist since Bruce Schneier's Secrets and Lies and Applied Cryptography!Adam Shostack is responsible for security development lifecycle threat modeling at Microsoft and is one of a handful of threat modeling experts in the world. Now, he is sharing his considerable expertise into this unique book. With pages of specific actionable advice, he details how to build better security into the design of systems, software, or services from the outset. You'll explore various threat modeling approaches, find out how to test your designs against threats, and learn effective ways to address threats that have been validated at Microsoft and other top companies. Systems security managers, you'll find tools and a framework for structured thinking about what can go wrong. Software developers, you'll appreciate the jargon-free and accessible introduction to this essential skill. Security professionals, you'll learn to discern changing threats and discover the easiest ways to adopt a structured approach to threat modeling.  Provides a unique how-to for security and software developers who need to design secure products and systems and test their designs Explains how to threat model and explores various threat modeling approaches, such as asset-centric, attacker-centric and software-centric Provides effective approaches and techniques that have been proven at Microsoft and elsewhere Offers actionable how-to advice not tied to any specific software, operating system, or programming language Authored by a Microsoft professional who is one of the most prominent threat modeling experts in the world  As more software is delivered on the Internet or operates on Internet-connected devices, the design of secure software is absolutely critical. Make sure you're ready with Threat Modeling: Designing for Security.},
	pagetotal = {624},
	publisher = {John Wiley \& Sons},
	author = {Shostack, Adam},
	date = {2014-02-12},
	langid = {english},
	keywords = {Computers / Networking / General, Computers / Security / General},
}

@inproceedings{refsdal_uml-based_2008,
	location = {Boston, {MA}},
	title = {A {UML}-based Method for the Development of Policies to Support Trust Management},
	isbn = {978-0-387-09428-1},
	doi = {10.1007/978-0-387-09428-1_3},
	series = {{IFIP} – The International Federation for Information Processing},
	abstract = {Most of the existing approaches to trust management focus on the issues of assessing the trustworthiness of other entities and of establishing trust between entities. This is particularly relevant for dynamic, open and distributed systems, where the identity and intentions of other entities may be uncertain. These approaches offer methods to manage trust, and thereby to manage risk and security. The methods are, however, mostly concerned with trust management from the viewpoint of the trustor, and the issue of mitigating risks to which the trustor is exposed. This paper addresses the important, yet quite neglected, challenge of understanding the risks to which a whole system is exposed, in cases where some of the actors within the system make trust-based decisions. The paper contributes by proposing a method for the modeling and analysis of trust, as well as the identification and evaluation of the associated risks and opportunities. The analysis facilitates the capture of trust policies, the enforcement of which optimizes the trust-based decisions within the system. The method is supported by formal, {UML}-based languages for the modeling of trust scenarios and for trust policy specification.},
	pages = {33--49},
	booktitle = {Trust Management {II}},
	publisher = {Springer {US}},
	author = {Refsdal, Atle and Solhaug, Bjørnar and Stølen, Ketil},
	editor = {Karabulut, Yücel and Mitchell, John and Herrmann, Peter and Jensen, Christian Damsgaard},
	date = {2008},
	langid = {english},
	keywords = {Deontic Logic, Policy Rule, Sequence Diagram, Trust Level, Trust Management},
}

@inproceedings{guerriero_defining_2018,
	location = {New York, {NY}, {USA}},
	title = {Defining, Enforcing and Checking Privacy Policies In Data-Intensive Applications},
	isbn = {978-1-4503-5715-9},
	url = {https://doi.org/10.1145/3194133.3194140},
	doi = {10.1145/3194133.3194140},
	series = {{SEAMS} '18},
	abstract = {The rise of Big Data is leading to an increasing demand for large-scale data-intensive applications ({DIAs}), which have to analyse massive amounts of personal data (e.g. customers’ location, cars’ speed, people heartbeat, etc.), some of which can be sensitive, meaning that its conﬁdentiality has to be protected. In this context, {DIA} providers are responsible for enforcing privacy policies that account for the privacy preferences of data subjects as well as for general privacy regulations. This is the case, for instance, of data brokers, i.e. companies that continuously collect and analyse data in order to provide useful analytics to their clients. Unfortunately, the enforcement of privacy policies in modern {DIAs} tends to become cumbersome because (i) the number of policies can easily explode, depending on the number of data subjects, (ii) policy enforcement has to autonomously adapt to the application context, thus, requiring some non-trivial runtime reasoning, and (iii) designing and developing modern {DIAs} is complex per se. For the above reasons, we need speciﬁc design and runtime methods enabling so called privacy-by-design in a Big Data context. In this article we propose an approach for specifying, enforcing and checking privacy policies on {DIAs} designed according to the Google Dataﬂow model and we show that the enforcement approach behaves correctly in the considered cases and introduces a performance overhead that is acceptable given the requirements of a typical {DIA}.},
	pages = {11},
	booktitle = {Proceedings of the 13th International Conference on Software Engineering for Adaptive and Self-Managing Systems},
	publisher = {Association for Computing Machinery},
	author = {Guerriero, Michele},
	date = {2018},
	langid = {english},
	keywords = {data privacy, big data, context-aware privacy, dataflow applications},
}

@inproceedings{esfahani_guidearch_2013,
	title = {{GuideArch}: Guiding the exploration of architectural solution space under uncertainty},
	doi = {10.1109/ICSE.2013.6606550},
	shorttitle = {{GuideArch}},
	abstract = {A system's early architectural decisions impact its properties (e.g., scalability, dependability) as well as stakeholder concerns (e.g., cost, time to delivery). Choices made early on are both difficult and costly to change, and thus it is paramount that the engineer gets them “right”. This leads to a paradox, as in early design, the engineer is often forced to make these decisions under uncertainty, i.e., not knowing the precise impact of those decisions on the various concerns. How could the engineer make the “right” choices in such circumstances? This is precisely the question we have tackled in this paper. We present {GuideArch}, a framework aimed at quantitative exploration of the architectural solution space under uncertainty. It provides techniques founded on fuzzy math that help the engineer with making informed decisions.},
	eventtitle = {2013 35th International Conference on Software Engineering ({ICSE})},
	pages = {43--52},
	booktitle = {2013 35th International Conference on Software Engineering ({ICSE})},
	author = {Esfahani, N. and Malek, S. and Razavi, K.},
	date = {2013-05},
	keywords = {Uncertainty, Computer architecture, software architecture, Hardware, Software engineering, decision making, Synthetic aperture sonar, architectural solution space, Batteries, Decision Making, {GuideArch}, quantitative exploration, Software Architecture, Time factors},
}

@thesis{esfahani_management_2014,
	title = {Management of Uncertainty in Self-Adaptive Software},
	url = {http://mars.gmu.edu/handle/1920/8985},
	abstract = {The ever-growing complexity of software systems coupled with the need to maintain their quality of service ({QoS}) characteristics, even under adverse conditions and highly uncertain environments, have instigated the emergence of {\textless}italic{\textgreater}self-adaptive{\textless}/italic{\textgreater} software systems. A self-adaptive software system has the mechanisms that automate and simplify the management and modification of software systems after they are deployed, (i.e., during run-time) to achieve certain functional or {QoS} goals.},
	type = {phdthesis},
	author = {Esfahani, Naeem},
	urldate = {2021-02-09},
	date = {2014-08},
	langid = {english},
}

@article{tracz_dssa_1995,
	title = {{DSSA} (Domain-Specific Software Architecture): pedagogical example},
	volume = {20},
	issn = {0163-5948},
	url = {https://doi.org/10.1145/219308.219318},
	doi = {10.1145/219308.219318},
	shorttitle = {{DSSA} (Domain-Specific Software Architecture)},
	abstract = {A Domain-Specific Software Architecture ({DSSA}) has been defined as:\&bull; "an assemblage of software components, specialized for a particular type of task (domain), generalized for effective use across that domain, composed in a standardized structure (topology) effective for building successful applications" [Hay94] or, alternately\&bull; "a context for patterns of problem elements, solution elements, and situations that define mappings between them [Hid90].The following small example illustrates these definitions as well as provides the reader with some insight into the types of processes and tools needed to support the creation and use of a {DSSA}.},
	pages = {49--62},
	number = {3},
	journaltitle = {{ACM} {SIGSOFT} Software Engineering Notes},
	shortjournal = {{SIGSOFT} Softw. Eng. Notes},
	author = {Tracz, Will},
	urldate = {2021-02-17},
	date = {1995-07-01},
}

@article{falessi_decision-making_2011,
	title = {Decision-making techniques for software architecture design: A comparative survey},
	volume = {43},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/1978802.1978812},
	doi = {10.1145/1978802.1978812},
	shorttitle = {Decision-making techniques for software architecture design},
	abstract = {The architecture of a software-intensive system can be defined as the set of relevant design decisions that affect the qualities of the overall system functionality; therefore, architectural decisions are eventually crucial to the success of a software project. The software engineering literature describes several techniques to choose among architectural alternatives, but it gives no clear guidance on which technique is more suitable than another, and in which circumstances. As such, there is no systematic way for software engineers to choose among decision-making techniques for resolving tradeoffs in architecture design. In this article, we provide a comparison of existing decision-making techniques, aimed to guide architects in their selection. The results show that there is no “best” decision-making technique; however, some techniques are more susceptible to specific difficulties. Hence architects should choose a decision-making technique based on the difficulties that they wish to avoid. This article represents a first attempt to reason on meta-decision-making, that is, the issue of deciding how to decide.},
	pages = {33:1--33:28},
	number = {4},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Falessi, Davide and Cantone, Giovanni and Kazman, Rick and Kruchten, Philippe},
	urldate = {2021-02-17},
	date = {2011-10-18},
	keywords = {architecture, Decision-making, design decisions},
}

@article{tang_software_2009,
	title = {Software Architecture Design Reasoning: A Case for Improved Methodology Support},
	volume = {26},
	issn = {1937-4194},
	doi = {10.1109/MS.2009.46},
	shorttitle = {Software Architecture Design Reasoning},
	abstract = {This paper presents the capturing and recording of reasoning behind software architecture design to encourage architects to more carefully consider design decisions and better support future maintenance.},
	pages = {43--49},
	number = {2},
	journaltitle = {{IEEE} Software},
	author = {Tang, A. and Han, J. and Vasa, R.},
	date = {2009-03},
	note = {Conference Name: {IEEE} Software},
	keywords = {Computer architecture, software architecture, Software architecture, software engineering, Decision making, Context, software maintenance, design decisions, Design methodology, design reasoning, improved methodology support, Process design, Productivity, service interactions, software architecture design reasoning, Software design, speech acts},
}

@article{van_heesch_documentation_2012,
	title = {A documentation framework for architecture decisions},
	volume = {85},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121211002755},
	doi = {10.1016/j.jss.2011.10.017},
	pages = {795--820},
	number = {4},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {van Heesch, U. and Avgeriou, P. and Hilliard, R.},
	urldate = {2021-02-17},
	date = {2012-04},
	langid = {english},
}

@inproceedings{shahin_architectural_2009,
	title = {Architectural design decision: Existing models and tools},
	doi = {10.1109/WICSA.2009.5290823},
	shorttitle = {Architectural design decision},
	abstract = {In the field of software architecture, there has been a paradigm shift from describing the outcome of architecting process mostly described by component and connector (know-what) to documenting architectural design decisions and their rationale (know-how) which leads to the production of an architecture. This paradigm shift results in emergence of various models and related tools for capturing, managing and sharing architectural design decisions and their rationale explicitly. This paper analyzes existing architectural design decisions models and provides a criteria-based comparison on tools that support these models. The major contribution of this paper is twofold: to show that all of these models have a consensus on capturing the essence of an architectural design decision; and to clarify the major difference among the tools and show what desired features are missing in these tools.},
	eventtitle = {2009 Joint Working {IEEE}/{IFIP} Conference on Software Architecture European Conference on Software Architecture},
	pages = {293--296},
	booktitle = {2009 Joint Working {IEEE}/{IFIP} Conference on Software Architecture European Conference on Software Architecture},
	author = {Shahin, M. and Liang, P. and Khayyambashi, M. R.},
	date = {2009-09},
	keywords = {Mathematical model, Computer architecture, software architecture, Software architecture, Connectors, Ontologies, Context modeling, architectural design decision, criteria-based comparison, Design engineering, Disaster management, Mathematics, Production, software tools, tools},
}

@article{buring_was_2019,
	title = {Was Admins und Dienstleistern bei mangelhafter Absicherung gegen Datenangriffe blüht},
	pages = {4},
	author = {Büring, Von Harald},
	date = {2019},
	langid = {german},
}

@book{anderson_security_2020,
	location = {Indianapolis},
	title = {Security Engineering: A Guide to Building Dependable Distributed Systems},
	isbn = {978-1-119-64278-7},
	shorttitle = {Security Engineering},
	publisher = {John Wiley and Sons},
	author = {Anderson, Ross},
	date = {2020},
	langid = {english},
}

@inproceedings{gurses_eliciting_2005,
	title = {Eliciting confidentiality requirements in practice},
	abstract = {Abstract Confidentiality, the protection of unauthorized disclosure of information, plays an important role in information security of software systems. Security researchers have developed numerous approaches on how to implement confidentiality, typically based on cryptographic algorithms and tight access control. However, less work has been done on defining systematic methods on how to elicit and define confidentiality requirements in the first place. Moreover, most of these approaches are illustrated with simulated examples that do not capture the richness of real world experience. This paper reports on our experiences eliciting confidentiality requirements in a real world project in the health care area. The method,applied originates from the M.Sc. thesis of one of the authors and is still considered work in progress. Still, valuable insight into issues of confidentiality requirements engineering can be gained Copyright c 2005 S. G¨uerses and all other authors},
	pages = {101--116},
	booktitle = {Proceedings of the 2005 conference of the Centre for Advanced Studies on Collaborative research},
	author = {Gürses, Seda and Jahnke, Jens H and Obry, Christina and Onabajo, Adeniyi and Santen, Thomas and Price, Morgan},
	date = {2005},
}

@inproceedings{nugraha_towards_2017,
	title = {Towards the Classification of Confidentiality Capabilities in Trustworthy Service Level Agreements},
	doi = {10.1109/IC2E.2017.48},
	abstract = {Many governments are increasingly reliant on externalservice providers to process, store or transmit sensitivedata on behalf of the government. This study is motivated by the problem of preserving the confidentiality of sensitive government data, particularly following Edward Snowden's revelations of alleged pervasive surveillance, a problem posed by foreign intelligence services to the Indonesian government in 2013. In this paper, we discuss the idea of proposing {TrustworthyService} Level Agreements ({TSLA}) as a means of incorporating security considerations (considering confidentiality) into a Service Level Agreement ({SLA}) between a service provider and the customer (e.g. government). In particular, we classify confidentialityrequirements and capabilities according to a typical threat profile for government data classification, by describing five discrete levels of security precautions that can be negotiated between the government and service providers to ensure the confidentiality of sensitive data handled by the providers. It further provides an evaluation framework for assessing and clarifying security considerations in {SLAs}. The levels of assurance should serve as a foundation for expressing security considerations (including threats, requirements, and capabilities) in {SLAs} as well as fordesigning information system services regarding security. The contribution of this paper is in developing five distinctive levels of increasing assurance that can be applied to the formulation of security-related {SLAs}, as well as in discussing the discrete levels, using the context of a government cloud.},
	eventtitle = {2017 {IEEE} International Conference on Cloud Engineering ({IC}2E)},
	pages = {304--310},
	booktitle = {2017 {IEEE} International Conference on Cloud Engineering ({IC}2E)},
	author = {Nugraha, Y. and Martin, A.},
	date = {2017-04},
	keywords = {trusted computing, data security, Government, Information systems, cloud computing, Cloud computing, contracts, Context, Cryptography, confidentiality capability classification, data confidentiality, Edward Snowden revelations, government cloud, government data classification, government data processing, Indonesian government, levels of assurance, pattern classification, security considerations, security-related {SLA}, sensitive government data, threat profile, Trustworthy service level agreement, trustworthy service level agreements, {TSLA}},
}

@inproceedings{whittle_relax_2009,
	title = {{RELAX}: Incorporating Uncertainty into the Specification of Self-Adaptive Systems},
	doi = {10.1109/RE.2009.36},
	shorttitle = {{RELAX}},
	abstract = {Self-adaptive systems have the capability to autonomously modify their behaviour at run-time in response to changes in their environment. Self-adaptation is particularly necessary for applications that must run continuously, even under adverse conditions and changing requirements; sample domains include automotive systems, telecommunications, and environmental monitoring systems. While a few techniques have been developed to support the monitoring and analysis of requirements for adaptive systems, limited attention has been paid to the actual creation and specification of requirements of self-adaptive systems. As a result, self-adaptivity is often constructed in an ad-hoc manner. In this paper, we argue that a more rigorous treatment of requirements explicitly relating to self-adaptivity is needed and that, in particular, requirements languages for self-adaptive systems should include explicit constructs for specifying and dealing with the uncertainty inherent in self-adaptive systems. We present {RELAX}, a new requirements language for self-adaptive systems and illustrate it using examples from the smart home domain.},
	eventtitle = {2009 17th {IEEE} International Requirements Engineering Conference},
	pages = {79--88},
	booktitle = {2009 17th {IEEE} International Requirements Engineering Conference},
	author = {Whittle, J. and Sawyer, P. and Bencomo, N. and Cheng, B. H. C. and Bruel, J.},
	date = {2009-08},
	keywords = {uncertainty, Uncertainty, Computer science, formal specification, specification languages, Adaptive systems, Automotive engineering, Biomedical monitoring, Condition monitoring, Humans, {RELAX} requirement specification language, requirements, run-time behaviour modification, Runtime environment, self-adaptation, self-adaptive system specification, Smart homes, system monitoring, {USA} Councils},
}

@article{cheminod_semiautomated_2015,
	title = {Semiautomated Verification of Access Control Implementation in Industrial Networked Systems},
	volume = {11},
	issn = {1941-0050},
	doi = {10.1109/TII.2015.2489181},
	abstract = {Access control is a necessary building block in the security of any kind of cyber system and, in this sense, industrial networked systems ({INSs}) make no exception. Typically, access control policies are specified at a high implementation-independent level of abstraction and then mapped onto the real system by leveraging available policy enforcement mechanisms. Unfortunately, different from general-purpose {ICT} systems, enforcement mechanisms are generally very basic in {INS}. As a consequence, verifying the correctness of policy implementation becomes a crucial task, especially cumbersome when it needs to be carried out entirely by hand. This paper presents a new methodology, which also serves as the basis of a purposely developed software tool conceived to cope with the lack of policy enforcement mechanisms in {INS} and to allow semiautomatic verification of policy implementation. Our approach is based on a twofold system model that enables both the abstract specification of access control policies and the detailed description of the target physical system. These two separate views are then combined to automatically determine whether the current system implementation matches the policy specification.},
	pages = {1388--1399},
	number = {6},
	journaltitle = {{IEEE} Transactions on Industrial Informatics},
	author = {Cheminod, M. and Durante, L. and Seno, L. and Valenzano, A.},
	date = {2015-12},
	note = {Conference Name: {IEEE} Transactions on Industrial Informatics},
	keywords = {Automata, Computational modeling, Data models, Access control, authorisation, formal verification, formal specification, access control policies, abstract specification, access control implementation, Access control policies, automated verification, computer network security, cyber system, implementation-independent abstraction level, industrial networked systems, industrial system security, Industrial system security, Informatics, {INS}, policy enforcement mechanisms, policy implementation, policy specification, Ports (Computers), role-based access control ({RBAC}), Role-Based Access Control ({RBAC}), semiautomated verification, System implementation, target physical system, twofold system model},
}

@thesis{jansen_architectural_2008,
	location = {S.l.},
	title = {Architectural design decisions},
	type = {phdthesis},
	author = {Jansen, Anton},
	date = {2008},
	langid = {english},
}

@article{barreto_software_2011,
	title = {Software Process Definition: a Reuse-based Approach},
	abstract = {Software product development has been taking advantage of reuse techniques for some decades. Concepts like software components, architectures, and product lines have been successfully applied in several contexts to develop software products, although some difficulties are still faced. Software processes have strong similarities with software products, and some researchers argue that they are software too. Therefore, we believe that software processes may take advantage of some benefits expected by the use of existing software products reuse techniques, adapted to software processes. It is also possible that similar difficulties are faced. This paper presents a software process definition approach based on reuse techniques, which aims at making some of the benefits expected by software product reuse available to software process definition activities. Concepts such as process components, architectures, process lines and features are described and used. We describe the proposed approach, tools developed to support it, and also results of a survey on the expected benefits and difficulties on software process reuse in the point of view of experienced software process engineers.},
	pages = {35},
	author = {Barreto, Ahilton Silva and Murta, Leonardo Gresta Paulino},
	date = {2011},
	langid = {english},
}

@article{meredith_theory_1993,
	title = {Theory Building through Conceptual Methods},
	volume = {13},
	issn = {0144-3577},
	url = {https://doi.org/10.1108/01443579310028120},
	doi = {10.1108/01443579310028120},
	abstract = {Identifies the significant role of conceptual research methods in theory building and contrasts it with the theory‐testing research currently prevalent in operations management. The research stages of description, explanation and testing are used to distinguish between theory building and theory testing. Short‐circuiting any one of these stages results in dysfunctional research activities which produce war stories, black boxes, or ivory‐tower prescriptions. Defines some terms relevant to conceptual research methods and describes different conceptual classification schemes. Finally, discusses the differences between conceptual models, frameworks, and theories and illustrates each method with examples from the literature.},
	pages = {3--11},
	number = {5},
	journaltitle = {International Journal of Operations \& Production Management},
	author = {Meredith, Jack},
	urldate = {2021-03-24},
	date = {1993-01-01},
	note = {Publisher: {MCB} {UP} Ltd},
	keywords = {Modelling, Operations management, Research},
}

@inproceedings{clarkson_hyperproperties_2008,
	location = {Pittsburgh, {PA}, {USA}},
	title = {Hyperproperties},
	isbn = {978-0-7695-3182-3},
	url = {http://ieeexplore.ieee.org/document/4556678/},
	doi = {10.1109/CSF.2008.7},
	abstract = {Properties, which have long been used for reasoning about systems, are sets of traces. Hyperproperties, introduced here, are sets of properties. Hyperproperties can express security policies, such as secure information ﬂow, that properties cannot. Safety and liveness are generalized to hyperproperties, and every hyperproperty is shown to be the intersection of a safety hyperproperty and a liveness hyperproperty. A veriﬁcation technique for safety hyperproperties is given and is shown to generalize prior techniques for verifying secure information ﬂow. Reﬁnement is shown to be valid for safety hyperproperties. A topological characterization of hyperproperties is given.},
	eventtitle = {2008 21st {IEEE} Computer Security Foundations Symposium},
	pages = {51--65},
	booktitle = {2008 21st {IEEE} Computer Security Foundations Symposium},
	publisher = {{IEEE}},
	author = {Clarkson, Michael R. and Schneider, Fred B.},
	urldate = {2021-03-25},
	date = {2008},
	langid = {english},
}

@inproceedings{perez-palacin_dealing_2014,
	location = {New York, {NY}, {USA}},
	title = {Dealing with uncertainties in the performance modelling of software systems},
	isbn = {978-1-4503-2576-9},
	url = {https://doi.org/10.1145/2602576.2602582},
	doi = {10.1145/2602576.2602582},
	series = {{QoSA} '14},
	abstract = {Models play a central role in the assessment of software non-functional properties like performance and reliability. Models can be used both in the initial phases of development to support the designer decisions and at runtime to evaluate the impact of changes in the existing software. However, being abstraction, the models include per-se a certain degree of uncertainty. Nevertheless, often this aspect is neglected and models are used beyond their capabilities. Recognising the presence of uncertainties and managing them, would increase the level of trust in a given software model. In this paper we exploit a recently defined taxonomy that classifies the different types of uncertainties and we define a method that, starting from a given model, helps in recognising the existence of uncertainty, in classifying and managing it. We show the method at work on an example application considering the performance of the application as target non-functional property.},
	pages = {33--42},
	booktitle = {Proceedings of the 10th international {ACM} Sigsoft conference on Quality of software architectures},
	publisher = {Association for Computing Machinery},
	author = {Perez-Palacin, Diego and Mirandola, Raffaela},
	urldate = {2021-03-26},
	date = {2014},
	keywords = {models, uncertainty, performance},
}

@inproceedings{leicht_survey_2019,
	title = {A Survey on Privacy Policy Languages: Expressiveness Concerning Data Protection Regulations},
	doi = {10.1109/CMI48017.2019.8962144},
	shorttitle = {A Survey on Privacy Policy Languages},
	abstract = {Privacy policies are a widely used way of expressing the data handling by service providers. However, the legalese used in these documents hinders many users in understanding the important information about what is happening with their data. A privacy policy language and corresponding easy to understand visualization can help users in understanding these policies. In this survey we compare 18 policy languages that can be used in the context of privacy policies. The focus of this survey lies on compatibility with legislation like the General Data Protection Regulation of the European Union and the formalization of such languages.},
	eventtitle = {2019 12th {CMI} Conference on Cybersecurity and Privacy ({CMI})},
	pages = {1--6},
	booktitle = {2019 12th {CMI} Conference on Cybersecurity and Privacy ({CMI})},
	author = {Leicht, J. and Heisel, M.},
	date = {2019-11},
	keywords = {Access control, Privacy, Legislation, Time factors, Data protection, data protection regulation, formal policies, privacy policy languages, Regulation},
}

@inproceedings{priebe_abac_2005,
	location = {Bonn},
	title = {{ABAC} – Ein Referenzmodell für attributbasierte Zugriffskontrolle},
	pages = {285--296},
	booktitle = {Sicherheit 2005, Sicherheit – Schutz und Zuverlässigkeit},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Priebe, Torsten and Dobmeier, Wolfgang and Muschall, Björn and Pernul, Günther},
	editor = {Federrath, Hannes},
	date = {2005},
}

@book{boyens_privacy_2002,
	title = {Privacy Conflicts in {CRM} Services for Online Shops: A Case Study},
	shorttitle = {Privacy Conflicts in {CRM} Services for Online Shops},
	abstract = {Sophisticated Data Mining tools are able to provide valuable information for online retailers. But especially when an external data mining service provider is contracted, important questions arise concerning the privacy preservation of the shop customers. This paper discusses the specific case of an online retailer who aims at usefully analysing customers' data for product and capacity planning while still preserving its users' privacy. We expose several privacy-sensitive areas and propose protection measures in order to face these problems'.},
	author = {Boyens, Claus and Günther, Oliver and Teltzrow, Maximilian},
	date = {2002},
}

@inproceedings{gruschka_privacy_2018,
	title = {Privacy Issues and Data Protection in Big Data: A Case Study Analysis under {GDPR}},
	doi = {10.1109/BigData.2018.8622621},
	shorttitle = {Privacy Issues and Data Protection in Big Data},
	abstract = {Big data has become a great asset for many organizations, promising improved operations and new business opportunities. However, big data has increased access to sensitive information that when processed can directly jeopardize the privacy of individuals and violate data protection laws. As a consequence, data controllers and data processors may be imposed tough penalties for non-compliance that can result even to bankruptcy. In this paper, we discuss the current state of the legal regulations and analyse different data protection and privacy-preserving techniques in the context of big data analysis. In addition, we present and analyse two real-life research projects as case studies dealing with sensitive data and actions for complying with the data regulation laws. We show which types of information might become a privacy risk, the employed privacy-preserving techniques in accordance with the legal requirements, and the influence of these techniques on the data processing phase and the research results.},
	eventtitle = {2018 {IEEE} International Conference on Big Data (Big Data)},
	pages = {5027--5033},
	booktitle = {2018 {IEEE} International Conference on Big Data (Big Data)},
	author = {Gruschka, N. and Mavroeidis, V. and Vishi, K. and Jensen, M.},
	date = {2018-12},
	keywords = {privacy, Law, information security, big data, Data protection, Big Data, biometric privacy, data analysis, data anonymization, data protection, {GDPR}},
}

@inproceedings{casalino_refactoring_2013,
	title = {Refactoring multi-layered access control policies through (De)composition},
	doi = {10.1109/CNSM.2013.6727843},
	abstract = {Policy-based access control is a well-established paradigm for securing layered {IT} systems. Access control policies, however, often do not focus on dedicated architecture layers, but increasingly employ concepts of multiple layers. Web application servers, for instance, typically support request filtering on the basis of network addresses. The resulting flexibility comes with increased management complexity and the risk of security-relevant misconfiguration when looking at the various policies in isolation. We therefore propose a flexible access control framework able to provide a comprehensive view of the global access control policy implemented in a given system. The focus of this paper is to lay down the theoretical foundations of this framework that allows (i) to describe authorization policies from different architecture layers, (ii) to capture the semantics of dependencies between layers in order to create a composed view of the global policy, and (iii) to decompose the global policy again into a collection of simpler ones by means of algebraic techniques inspired from database normalization theory.},
	eventtitle = {Proceedings of the 9th International Conference on Network and Service Management ({CNSM} 2013)},
	pages = {243--250},
	booktitle = {Proceedings of the 9th International Conference on Network and Service Management ({CNSM} 2013)},
	author = {Casalino, M. M. and Thion, R.},
	date = {2013-10},
	note = {{ISSN}: 2165-963X},
	keywords = {Access control, {IP} networks, Ports (Computers), Aerospace electronics, Couplings, Web servers},
}

@inproceedings{craven_decomposition_2010,
	title = {Decomposition techniques for policy refinement},
	doi = {10.1109/CNSM.2010.5691331},
	abstract = {The automation of policy refinement, whilst promising great benefits for policy-based management, has hitherto received relatively little treatment in the literature, with few concrete approaches emerging. In this paper we present initial steps towards a framework for automated distributed policy refinement for both obligation and authorization policies. We present examples drawn from military scenarios, describe details of our formalism and methods for action decomposition, and discuss directions for future research.},
	eventtitle = {2010 International Conference on Network and Service Management},
	pages = {72--79},
	booktitle = {2010 International Conference on Network and Service Management},
	author = {Craven, R. and Lobo, J. and Lupu, E. and Russo, A. and Sloman, M.},
	date = {2010-10},
	keywords = {Servers, Unified modeling language, Authorization, Educational institutions, Organizations, Performance evaluation},
}

@inproceedings{johnson_usable_2010,
	location = {Fairfax, {VA}, {USA}},
	title = {Usable Policy Template Authoring for Iterative Policy Refinement},
	isbn = {978-1-4244-8206-1},
	url = {http://ieeexplore.ieee.org/document/5629950/},
	doi = {10.1109/POLICY.2010.28},
	abstract = {People must have usable tools in order to author and maintain high-quality policies. In this paper we discuss policy templates as a mechanism for policy authoring. We believe that policy templates can be leveraged to make policy authoring more usable and to provide consistent policy authoring interfaces across a wide variety of policy domains. Templates provide users with a structured format for authoring policies; however, a general approach for creating policy templates has not been described in published research to date. Based on research in policy management, we propose an iterative policy reﬁnement process that consists of three user roles and spans policy authoring, template authoring, and policy element deﬁnition. We designed a {GUI}-based prototype that enables users to create policy templates. In this paper we describe our proposed policy reﬁnement process, the necessary user roles, a template authoring prototype, and the results of an empirical study of template authoring.},
	eventtitle = {2010 {IEEE} International Symposium on Policies for Distributed Systems and Networks},
	pages = {18--21},
	booktitle = {2010 {IEEE} International Symposium on Policies for Distributed Systems and Networks},
	publisher = {{IEEE}},
	author = {Johnson, Maritza and Karat, John and Karat, Clare-Marie and Grueneberg, Keith},
	urldate = {2021-04-01},
	date = {2010},
	langid = {english},
}

@inproceedings{bandara_goal-based_2004,
	title = {A goal-based approach to policy refinement},
	doi = {10.1109/POLICY.2004.1309175},
	abstract = {As the interest in using policy-based approaches for systems management grows, it is becoming increasingly important to develop methods for performing analysis and refinement of policy specifications. Although this is an area that researchers have devoted some attention to, none of the proposed solutions address the issue of deriving implementable policies from high-level goals. A key part of the solution to this problem is having the ability to identify the operations, available on the underlying system, which can achieve a given goal. This work presents an approach by which a formal representation of a system, based on the event calculus, can be used in conjunction with abductive reasoning techniques to derive the sequence of operations that will allow a given system to achieve a desired goal. Additionally it outlines how this technique might be used for providing tool support and partial automation for policy refinement. Building on previous work on using formal techniques for policy analysis, the approach presented here applies a transformation of both policy and system behaviour specifications into a formal notation that is based on event calculus. Finally, it shows how the overall process could be used in conjunction with {UML} modelling and illustrates this by means of an example.},
	eventtitle = {Proceedings. Fifth {IEEE} International Workshop on Policies for Distributed Systems and Networks, 2004. {POLICY} 2004.},
	pages = {229--239},
	booktitle = {Proceedings. Fifth {IEEE} International Workshop on Policies for Distributed Systems and Networks, 2004. {POLICY} 2004.},
	author = {Bandara, A. K. and Lupu, E. C. and Moffett, J. and Russo, A.},
	date = {2004-06},
	keywords = {Quality of service, Computer science, Environmental management, Automation, Concrete, Educational institutions, Calculus, Electronic commerce, Gold, Performance analysis},
}

@inproceedings{craven_security_2009,
	location = {New York, {NY}, {USA}},
	title = {Security policy refinement using data integration: a position paper},
	isbn = {978-1-60558-778-3},
	url = {https://doi.org/10.1145/1655062.1655068},
	doi = {10.1145/1655062.1655068},
	series = {{SafeConfig} '09},
	shorttitle = {Security policy refinement using data integration},
	abstract = {In spite of the wide adoption of policy-based approaches for security management, and many existing treatments of policy verification and analysis, relatively little attention has been paid to policy refinement: the problem of deriving lower-level, runnable policies from higher-level policies, policy goals, and specifications. In this paper we present our initial ideas on this task, using and adapting concepts from data integration. We take a view of policies as governing the performance of an action on a target by a subject, possibly with certain conditions. Transformation rules are applied to these components of a policy in a structured way, in order to translate the policy into more refined terms; the transformation rules we use are similar to those of `global-as-view' database schema mappings, or to extensions thereof. We illustrate our ideas with an example.},
	pages = {25--28},
	booktitle = {Proceedings of the 2nd {ACM} workshop on Assurable and usable security configuration},
	publisher = {Association for Computing Machinery},
	author = {Craven, Robert and Lobo, Jorge and Lupu, Emil and Russo, Alessandra and Sloman, Morris},
	urldate = {2021-04-01},
	date = {2009-11-09},
	keywords = {security, refinement, authorization, policies},
}

@inproceedings{craven_policy_2011,
	title = {Policy refinement: Decomposition and operationalization for dynamic domains},
	shorttitle = {Policy refinement},
	abstract = {We describe a method for policy refinement. The refinement process involves stages of decomposition, operationalization, deployment and re-refinement, and operates on policies expressed in a logical language flexible enough to be translated into many different enforceable policy dialects. We illustrate with examples from a coalition scenario, and describe how the stages of decomposition and operationaliztion work internally, and fit together in an interleaved fashion. Domains are represented in a logical formalization of {UML} diagrams. Both authorization and obligation policies are supported.},
	eventtitle = {2011 7th International Conference on Network and Service Management},
	pages = {1--9},
	booktitle = {2011 7th International Conference on Network and Service Management},
	author = {Craven, R. and Lobo, J. and Lupu, E. and Russo, A. and Sloman, M.},
	date = {2011-10},
	note = {{ISSN}: 2165-963X},
}

@thesis{tobias_evaluierung_2021,
	title = {Evaluierung architektureller Datenflussanalyse mittels einer Fallstudie anhand der Corona-Warn-App},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Bachelor's Thesis},
	author = {Tobias, Michael},
	date = {2021},
	langid = {german},
}

@inproceedings{onabajo_properties_2006,
	title = {Properties of Confidentiality Requirements},
	doi = {10.1109/CBMS.2006.133},
	abstract = {There is a growing concern to ensure personal information is protected in the emerging information society, and this can be attributed to the increasing incident of identity theft and confidentiality breach. There are also potential risks associated with mishandling personal information in the healthcare sector, for example, medical conditions, which should remain confidential, can be disclosed to unauthorized persons, subsequently leading to negative social and psychological effects on the affected individuals. Many governments and international agencies have developed legislations and guidelines to prevent misuse of personal information by organizations in their jurisdictions. However, there is a challenge in properly integrating the complex nature and interaction of confidentiality concerns in many information systems. This is because the concerns involve multiple interests - the data owner, the data custodian, potential users of the system, as well as government agencies, and they can be conflicting. In addition, the requirements are usually specified in free text form, which can be ambiguous and difficult to translate to software systems. A better understanding of confidentiality requirement properties will assist information system designers and developers in specifying and analyzing the requirements, and ultimately result in good "confidentiality-aware" systems. This research is aimed at developing an approach for improved specification, modelling and analysis of confidentiality requirements. In this paper, we describe the study to identify key confidentiality properties, which will enable precise specification of confidentiality requirements},
	eventtitle = {19th {IEEE} Symposium on Computer-Based Medical Systems ({CBMS}'06)},
	pages = {841--846},
	booktitle = {19th {IEEE} Symposium on Computer-Based Medical Systems ({CBMS}'06)},
	author = {Onabajo, A. and Jahnke, J.H.},
	date = {2006-06},
	keywords = {Software systems, Information analysis, Government, Legislation, Information systems, Protection, Guidelines, Medical conditions, Medical services, Psychology},
}

@article{pfitzmann_terminology_2010,
	title = {A terminology for talking about privacy by data minimization: Anonymity, Unlinkability, Undetectability, Unobservability, Pseudonymity, and Identity Management},
	abstract = {Based on the nomenclature of the early papers in the field privacy by data minimization, we develop a terminology which is both expressive and precise. More particularly, we define anonymity, unlinkability, linkability, undetectability, unobservability, pseudonymity (pseudonyms and digital pseudonyms, and their attributes), identifiability, identity, partial identity, digital identity and identity management. In addition, we describe the relationships between these terms, give a rationale why we define them as we do, and sketch the main mechanisms to provide for the properties defined.},
	pages = {98},
	author = {Pfitzmann, Andreas and Dresden, {TU} and Hansen, Marit},
	date = {2010},
	langid = {english},
}

@thesis{koziolek_automated_2011,
	title = {Automated Improvement of Software Architecture Models for Performance and Other Quality Attributes},
	url = {https://publikationen.bibliothek.kit.edu/1000024955},
	type = {phdthesis},
	author = {Koziolek, Anne},
	urldate = {2021-04-27},
	date = {2011},
	langid = {german},
	doi = {10.5445/IR/1000024955},
}

@inproceedings{nergaard_scratch-based_2015,
	title = {A scratch-based graphical policy editor for {XACML}},
	abstract = {This paper proposes a policy-maker-friendly editor for the extensible Access Control Markup Language ({XACML}) based on the programming language Scratch. Scratch is a blocks-based programming language designed for teaching children programming, which allows users to build programs like a puzzle. We take this concept one step further with an {XACML} policy editor based on the graphic programming elements of Scratch implemented in Smalltalk. This allows for aiding the user on how to build policies by grouping blocks and operators that fit together and also indicating which blocks that will stick together. It simplifies building the {XACML} policies while still having an {XACML} “feel” of the graphic policies.},
	eventtitle = {2015 International Conference on Information Systems Security and Privacy ({ICISSP})},
	pages = {1--9},
	booktitle = {2015 International Conference on Information Systems Security and Privacy ({ICISSP})},
	author = {Nergaard, Henrik and Ulltveit-Moe, Nils and Gj⊘sæter, Terje},
	date = {2015-02},
	keywords = {Authorization, {XACML}, Privacy, Authorisation, {XML}, Editor, Programming, Smalltalk, Standards, Syntactics, Writing},
}

@inproceedings{gaaloul_access_2013,
	title = {An Access Control Model for Organisational Management in Enterprise Architecture},
	doi = {10.1109/SKG.2013.12},
	abstract = {Enterprise architecture ({EA}) aims to provide management with appropriate indicators and controls to steer and model service-oriented enterprises. {EA} offers a suitable operating platform to support an organisation's future goals and the roadmap for moving towards this vision. Despite significant research interest in the domain, common enterprises architecture frameworks lack of access control mechanisms supporting security requirements within organisations. Security has become a matter of paramount concern when managing organisations resources such as stakeholders' authorisation or sensitive data. In this paper, we propose an innovative approach for managing organisational resources in enterprise architecture. In doing so, we reason about task-based resources in the {EA} language {ArchiMate}. The idea is to build a conceptual model supporting access control when modelling a business process (set of tasks) in {ArchiMate}. We then map the common concepts with the role-based access control model ({RBAC}) to specify the required authorisation policies as part of the security specifications and guidelines in {EA}. Finally, a case study illustration will be used for the evaluation as part of the research approach.},
	eventtitle = {2013 Ninth International Conference on Semantics, Knowledge and Grids},
	pages = {37--43},
	booktitle = {2013 Ninth International Conference on Semantics, Knowledge and Grids},
	author = {Gaaloul, Khaled and Proper, H. A.},
	date = {2013-10},
	keywords = {Access control, Unified modeling language, Authorization, {RBAC}, Authorisation, Information systems, Business, Standards, {ArchiMate}, Enterprise architecture, Task},
}

@inproceedings{dan_attribute_2012,
	title = {Attribute Based Access Control ({ABAC})-Based Cross-Domain Access Control in Service-Oriented Architecture ({SOA})},
	doi = {10.1109/CSSS.2012.354},
	abstract = {The traditional role-based access control model ({RBAC}) can not meet the requirements of Service Oriented Architectures ({SOA}) on the distribution and openness, Attribute-Based Access Control ({ABAC}), which is more fine-grained in access control, is more fit into the {SOA} open environment. This paper presents an {ABAC}-based cross-domain access control system, together with the security domain as a attribute with the subject, object, authority, environment attributes as the basis for access to the decision-making, eliminating integration constraints for the {SOA} framework based on the {RBAC}, somehow improves the scalability and alterability of the system, solved the problem of cross-domain access control.},
	eventtitle = {2012 International Conference on Computer Science and Service System},
	pages = {1405--1408},
	booktitle = {2012 International Conference on Computer Science and Service System},
	author = {Dan, Ni and Hua-Ji, Shi and Yuan, Chen and Jia-Hu, Guo},
	date = {2012-08},
	keywords = {access control, Access control, Authentication, {SOA}, Computer science, Process control, Attribute-Based Access Control ({ABAC}), Service oriented architecture},
}

@inproceedings{lodderstedt_secureuml_2002,
	location = {Berlin, Heidelberg},
	title = {{SecureUML}: A {UML}-Based Modeling Language for Model-Driven Security},
	isbn = {978-3-540-45800-5},
	doi = {10.1007/3-540-45800-X_33},
	series = {Lecture Notes in Computer Science},
	shorttitle = {{SecureUML}},
	abstract = {We present a modeling language for the model-driven development of secure, distributed systems based on the Unified Modeling Language ({UML}). Our approach is based on role-based access control with additional support for specifying authorization constraints. We show how {UML} can be used to specify information related to access control in the overall design of an application and how this information can be used to automatically generate complete access control infrastructures. Our approach can be used to improve productivity during the development of secure distributed systems and the quality of the resulting systems.},
	pages = {426--441},
	booktitle = {{UML} 2002 — The Unified Modeling Language},
	publisher = {Springer},
	author = {Lodderstedt, Torsten and Basin, David and Doser, Jürgen},
	editor = {Jézéquel, Jean-Marc and Hussmann, Heinrich and Cook, Stephen},
	date = {2002},
	langid = {english},
}

@article{keromytis_requirements_2007,
	title = {Requirements for scalable access control and security management architectures},
	volume = {7},
	issn = {1533-5399},
	url = {https://doi.org/10.1145/1239971.1239972},
	doi = {10.1145/1239971.1239972},
	abstract = {Maximizing local autonomy by delegating functionality to end nodes when possible (the end-to-end design principle) has led to a scalable Internet. Scalability and the capacity for distributed control have unfortunately not extended well to resource access-control policies and mechanisms. Yet management of security is becoming an increasingly challenging problem in no small part due to scaling up of measures such as number of users, protocols, applications, network elements, topological constraints, and functionality expectations. In this article, we discuss scalability challenges for traditional access-control mechanisms at the architectural level and present a set of fundamental requirements for authorization services in large-scale networks. We show why existing mechanisms fail to meet these requirements and investigate the current design options for a scalable access-control architecture. We argue that the key design options to achieve scalability are the choice of the representation of access control policy, the distribution mechanism for policy, and the choice of the access-rights revocation scheme. Although these ideas have been considered in the past, current access-control systems in use continue to use simpler but restrictive architectural models. With this article, we hope to influence the design of future access-control systems towards more decentralized and scalable mechanisms.},
	pages = {8--es},
	number = {2},
	journaltitle = {{ACM} Transactions on Internet Technology},
	shortjournal = {{ACM} Trans. Internet Technol.},
	author = {Keromytis, Angelos D. and Smith, Jonathan M.},
	urldate = {2021-04-30},
	date = {2007-05-01},
	keywords = {access control, trust management, security policy, authorization, credentials, delegation, distributed systems, Large-scale systems},
}

@article{basin_automated_2009,
	title = {Automated analysis of security-design models},
	volume = {51},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S095058490800075X},
	doi = {10.1016/j.infsof.2008.05.011},
	series = {{SPECIAL} {ISSUE}: Model-Driven Development for Secure Information Systems},
	abstract = {We have previously proposed {SecureUML}, an expressive {UML}-based language for constructing security-design models, which are models that combine design specifications for distributed systems with specifications of their security policies. Here, we show how to automate the analysis of such models in a semantically precise and meaningful way. In our approach, models are formalized together with scenarios that represent possible run-time instances. Queries about properties of the security policy modeled are expressed as formulas in {UML}’s Object Constraint Language. The policy may include both declarative aspects, i.e., static access-control information such as the assignment of users and permissions to roles, and programmatic aspects, which depend on dynamic information, namely the satisfaction of authorization constraints in a given scenario. We show how such properties can be evaluated, completely automatically, in the context of the metamodel of the security-design language. We demonstrate, through examples, that this approach can be used to formalize and check non-trivial security properties. The approach has been implemented in the {SecureMOVA} tool and all of the examples presented have been checked using this tool.},
	pages = {815--831},
	number = {5},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Basin, David and Clavel, Manuel and Doser, Jürgen and Egea, Marina},
	urldate = {2021-05-06},
	date = {2009-05-01},
	langid = {english},
	keywords = {{OCL}, {UML}, Formal analysis, Metamodels, {SecureUML}, Security policies},
}

@inproceedings{pilipchuk_aligning_2018,
	location = {New York, {NY}, {USA}},
	title = {Aligning Business Process Access Control Policies with Enterprise Architecture},
	isbn = {978-1-4503-6515-4},
	url = {https://doi.org/10.1145/3277570.3277588},
	doi = {10.1145/3277570.3277588},
	series = {{CECC} 2018},
	abstract = {Access control policies are a fundamental building block in meeting security and privacy requirements in organizations across business processes, enterprise architectures, and software architectures. Usage of different models for business processes and software makes eliciting and enforcing access control policies hard. Approaches like enterprise architecture management target complex mutual interdependencies between business and {IT} models but can be hard to apply. We suggest an approach to derive access control requirements from business processes and test compliance of software designs by data flow analyses. As a result, business processes and software designs are aligned w.r.t. access control requirements.},
	pages = {1--4},
	booktitle = {Proceedings of the Central European Cybersecurity Conference 2018},
	publisher = {Association for Computing Machinery},
	author = {Pilipchuk, Roman and Seifermann, Stephan and Heinrich, Robert},
	urldate = {2021-05-07},
	date = {2018-11-15},
	keywords = {role-based access control, Business process, enterprise architecture},
}

@article{nahar_developing_2021,
	title = {Developing an access control management metamodel for secure digital enterprise architecture modeling},
	volume = {n/a},
	issn = {2475-6725},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spy2.160},
	doi = {https://doi.org/10.1002/spy2.160},
	abstract = {There is an increasing interest in embedding the security in the design of digital enterprise architecture ({EA}) modeling platform to secure the digital assets. Access control management ({ACM}) is one of the key aspects of a secure digital enterprise architecture modeling platform design. Typical enterprise architecture modeling approaches mainly focus on the modeling of business, information, and technology elements. This draws our attention to this important question: how to model {ACM} for a secure digital {EA} modeling platform to ensure secure access to digital assets? This article aims to address this important research question in collaboration with our industry partner and developed an ontology-based {ACM} metamodel that can be used by enterprises to model their {ACM} for a particular situation. This research has been conducted using the well-known action-design research ({ADR}) method to develop and evaluate the {ACM} metamodel for the secure digital {EA} modeling platform.},
	pages = {e160},
	issue = {n/a},
	journaltitle = {Security and Privacy},
	author = {Nahar, Kamrun and Gill, Asif Qumer and Roach, Terry},
	urldate = {2021-05-25},
	date = {2021},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spy2.160},
	keywords = {ontology, enterprise architecture, access control management, action design research, meta, model},
}

@article{keith_survey_2021,
	title = {A survey of decision making and optimization under uncertainty},
	volume = {300},
	issn = {1572-9338},
	url = {https://doi.org/10.1007/s10479-019-03431-8},
	doi = {10.1007/s10479-019-03431-8},
	abstract = {Recent advances in decision making have incorporated both risk and ambiguity in decision theory and optimization methods. These methods implement a variety of uncertainty representations from probabilistic and non-probabilistic foundations, including traditional probability theory, sets of probability measures, uncertainty sets, ambiguity sets, possibility theory, evidence theory, fuzzy measures, and imprecise probability. The choice of uncertainty representation impacts the expressiveness and tractability of the decision models. We survey recent approaches for representing uncertainty in both decision making and optimization to clarify the trade-offs among the alternative representations. Robust and distributionally robust optimization are surveyed, with particular attention to standard form ambiguity sets. Applications of uncertainty and decision models are also reviewed, with a focus on recent optimization applications. These applications highlight common practices and potential research gaps. The intersection of behavioral decision making and robust optimization is a promising area for future research and there is also opportunity for further advances in distributionally robust optimization in sequential and multi-agent settings.},
	pages = {319--353},
	number = {2},
	journaltitle = {Annals of Operations Research},
	shortjournal = {Ann Oper Res},
	author = {Keith, Andrew J. and Ahner, Darryl K.},
	urldate = {2021-05-28},
	date = {2021-05-01},
	langid = {english},
}

@inproceedings{ramirez_taxonomy_2012,
	title = {A taxonomy of uncertainty for dynamically adaptive systems},
	doi = {10.1109/SEAMS.2012.6224396},
	abstract = {Self-reconfiguration enables a dynamically adaptive system ({DAS}) to satisfy requirements even as detrimental system and environmental conditions arise. A {DAS}, especially one intertwined with physical elements, must increasingly reason about and cope with unpredictable events in its execution environment. Unfortunately, it is often infeasible for a human to exhaustively explore, anticipate, or resolve all possible system and environmental conditions that a {DAS} will encounter as it executes. While uncertainty can be difficult to define, its effects can hinder the adaptation capabilities of a {DAS}. The concept of uncertainty has been extensively explored by other scientific disciplines, such as economics, physics, and psychology. As such, the software engineering {DAS} community can benefit from leveraging, reusing, and refining such knowledge for developing a {DAS}. By synthesizing uncertainty concepts from other disciplines, this paper revisits the concept of uncertainty from the perspective of a {DAS}, proposes a taxonomy of potential sources of uncertainty at the requirements, design, and execution phases, and identifies existing techniques for mitigating specific types of uncertainty. This paper also introduces a template for describing different types of uncertainty, including fields such as source, occurrence, impact, and mitigating strategies. We use this template to describe each type of uncertainty and illustrate the uncertainty source in terms of an example {DAS} application from the intelligent vehicle systems ({IVS}) domain.},
	eventtitle = {2012 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems ({SEAMS})},
	pages = {99--108},
	booktitle = {2012 7th International Symposium on Software Engineering for Adaptive and Self-Managing Systems ({SEAMS})},
	author = {Ramirez, Andres J. and Jensen, Adam C. and Cheng, Betty H. C.},
	date = {2012-06},
	keywords = {uncertainty, Uncertainty, Taxonomy, Communities, requirements engineering, Context, Adaptive systems, design, Dynamically adaptive systems, Physics, runtime, taxonomy, Vehicles},
}

@inproceedings{hahner_modeling_2021,
	location = {Stuttgart, Germany},
	title = {Modeling Data Flow Constraints for Design-Time Confidentiality Analyses},
	doi = {10.1109/ICSA-C52384.2021.00009},
	eventtitle = {2021 {IEEE} 18th International Conference on Software Architecture ({ICSA})},
	pages = {15--21},
	booktitle = {2021 {IEEE} 18th International Conference on Software Architecture Companion ({ICSA}-C)},
	publisher = {{IEEE}},
	author = {Hahner, Sebastian and Seifermann, Stephan and Heinrich, Robert and Walter, Maximilian and Bureš, Tomáš and Hnětynka, Petr},
	date = {2021},
	keywords = {Computer architecture, Software, Software architecture, Analytical models, Conferences, Manifolds, Terminology},
}

@article{uzunov_assessing_2018,
	title = {Assessing and improving the quality of security methodologies for distributed systems},
	volume = {30},
	issn = {2047-7481},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.1980},
	doi = {https://doi.org/10.1002/smr.1980},
	abstract = {Security methodologies represent systematic approaches for introducing security attributes into a system throughout the development lifecycle. While isolated attempts have been made to demonstrate the value of particular security methodologies, the “quality” of security methodologies, as such, has never been given due consideration; indeed, it has never been studied as a self-standing topic. The literature therefore entirely lacks supportive artifacts that can provide a basis for assessing, and hence for improving, a security methodology's quality. In this paper, we fill the aforementioned gap by proposing a comprehensive quality framework and accompanying process, within the context of an existing approach to engineering security methodologies, which can be used for both (bottom-up) quality assessment and (top-down) quality improvement. The main framework elements can be extended and customized to allow an essentially arbitrary range of methodology features to be considered, thus forming a basis for flexible, fine-grained quality control. We demonstrate the bottom-up application of the latter framework and process on three real-life security methodologies for distributed systems, taken as case studies. Based on the assessment results, we subsequently show in detail (for one) and briefly discuss (for the remaining set) how the case study methodologies can be re-engineered to improve their quality.},
	pages = {e1980},
	number = {11},
	journaltitle = {Journal of Software: Evolution and Process},
	author = {Uzunov, Anton V. and Fernandez, Eduardo B. and Falkner, Katrina},
	urldate = {2021-05-31},
	date = {2018},
	langid = {english},
	keywords = {engineering security methodologies, quality assessment, quality framework, quality improvement, security engineering, security methodology quality, security process modeling},
}

@article{sobhy_evaluation_2021,
	title = {Evaluation of Software Architectures under Uncertainty:  A Systematic Literature Review},
	pages = {50},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	author = {Sobhy, Dalia and Bahsoon, Rami and Minku, Leandro and Kazman, Rick},
	date = {2021},
}

@inproceedings{letier_uncertainty_2014,
	location = {New York, {NY}, {USA}},
	title = {Uncertainty, risk, and information value in software requirements and architecture},
	isbn = {978-1-4503-2756-5},
	url = {https://doi.org/10.1145/2568225.2568239},
	doi = {10.1145/2568225.2568239},
	series = {{ICSE} 2014},
	abstract = {Uncertainty complicates early requirements and architecture decisions and may expose a software project to significant risk. Yet software architects lack support for evaluating uncertainty, its impact on risk, and the value of reducing uncertainty before making critical decisions. We propose to apply decision analysis and multi-objective optimisation techniques to provide such support. We present a systematic method allowing software architects to describe uncertainty about the impact of alternatives on stakeholders' goals; to calculate the consequences of uncertainty through Monte-Carlo simulation; to shortlist candidate architectures based on expected costs, benefits and risks; and to assess the value of obtaining additional information before deciding. We demonstrate our method on the design of a system for coordinating emergency response teams. Our approach highlights the need for requirements engineering and software cost estimation methods to disclose uncertainty instead of hiding it.},
	pages = {883--894},
	booktitle = {Proceedings of the 36th International Conference on Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Letier, Emmanuel and Stefan, David and Barr, Earl T.},
	urldate = {2021-06-21},
	date = {2014-05-31},
	keywords = {Software engineering decision analysis},
}

@inproceedings{bhat_evolution_2020,
	title = {The Evolution of Architectural Decision Making as a Key Focus Area of Software Architecture Research: A Semi-Systematic Literature Study},
	doi = {10.1109/ICSA47634.2020.00015},
	shorttitle = {The Evolution of Architectural Decision Making as a Key Focus Area of Software Architecture Research},
	abstract = {Literature review studies are essential and form the foundation for any type of research. They serve as the point of departure for those seeking to understand a research topic, as well as, helps research communities to reflect on the ideas, fundamentals, and approaches that have emerged, been acknowledged, and formed the state-of-the-art. In this paper, we present a semi-systematic literature review of 218 papers published over the last four decades that have contributed to a better understanding of architectural design decisions ({ADDs}). These publications cover various related topics including tool support for managing {ADDs}, human aspects in architectural decision making ({ADM}), and group decision making. The results of this paper should be treated as a getting-started guide for researchers who are entering the investigation phase of research on {ADM}. In this paper, the readers will find a brief description of the contributions made by the established research community over the years. Based on those insights, we recommend our readers to explore the publications and the topics in depth.},
	eventtitle = {2020 {IEEE} International Conference on Software Architecture ({ICSA})},
	pages = {69--80},
	booktitle = {2020 {IEEE} International Conference on Software Architecture ({ICSA})},
	author = {Bhat, Manoj and Shumaiev, Klym and Hohenstein, Uwe and Biesdorf, Andreas and Matthes, Florian},
	date = {2020-03},
	keywords = {Computer architecture, Software architecture, Decision making, Bibliographies, Biological system modeling, Data mining, software architecture, decision making, architectural design decisions, literature review, Tools},
}

@inproceedings{walkinshaw_reasoning_2020,
	location = {Trondheim Norway},
	title = {Reasoning about Uncertainty in Empirical Results},
	isbn = {978-1-4503-7731-7},
	url = {https://dl.acm.org/doi/10.1145/3383219.3383234},
	doi = {10.1145/3383219.3383234},
	abstract = {Conclusions that are drawn from experiments are subject to varying degrees of uncertainty. For example, they might rely on small data sets, employ statistical techniques that make assumptions that are hard to verify, or there may be unknown confounding factors. In this paper we propose an alternative but complementary mechanism to explicitly incorporate these various sources of uncertainty into reasoning about empirical indings, by applying Subjective Logic. To do this we show how typical traditional results can be encoded as łsubjective opinionsž ś the building blocks of Subjective Logic. We demonstrate the value of the approach by using Subjective Logic to aggregate empirical results from two large published studies that explore the relationship between programming languages and defects or failures.},
	eventtitle = {{EASE} '20: Evaluation and Assessment in Software Engineering},
	pages = {140--149},
	booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
	publisher = {{ACM}},
	author = {Walkinshaw, Neil and Shepperd, Martin},
	urldate = {2021-06-22},
	date = {2020-04-15},
	langid = {english},
}

@book{mcconnell_software_1998,
	location = {Redmond, Wash.},
	title = {Software project survival guide},
	publisher = {Microsoft Press},
	author = {{McConnell}, Steve},
	date = {1998},
	langid = {english},
}

@incollection{mori_current_2019,
	location = {Cham},
	title = {The Current State of the Holistic Privacy and Security Modelling Approach in Business Process and Software Architecture Modelling},
	volume = {977},
	isbn = {978-3-030-25108-6 978-3-030-25109-3},
	url = {http://link.springer.com/10.1007/978-3-030-25109-3_6},
	abstract = {Modelling is central for business process and software architecture documentation and analysis. However, business processes and software architectures are specified with their own highly developed languages, methods and tools. There are approaches in the literature for modelling privacy and security issues using existing business process or architecture modelling languages to express different requirements by enriching these languages with annotations. Nevertheless, there is a lack of formalization and therefore the potential use for tool-based analyses are limited. In addition, the continuity between business and software models is not granted, but when modelling compliance requirements like privacy, traceability is very important, e.g. for compliance checks. In this contribution, approaches for modelling security and privacy in business and software models are examined. One key finding is that there is currently no comprehensive modelling approach which covers the necessary aspects and perspectives. This could include processes as well as, for example, organizational and data structure questions. In conclusion, we suggest developing a new holistic modelling approach which includes the needed aspects and with a concept for the traceability of the requirements from business models to software architecture models.},
	pages = {109--124},
	booktitle = {Information Systems Security and Privacy},
	publisher = {Springer International Publishing},
	author = {Alpers, Sascha and Pilipchuk, Roman and Oberweis, Andreas and Reussner, Ralf},
	editor = {Mori, Paolo and Furnell, Steven and Camp, Olivier},
	urldate = {2021-06-23},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-25109-3_6},
	note = {Series Title: Communications in Computer and Information Science},
}

@inproceedings{goudalo_toward_2008,
	title = {Toward the Engineering of Security of Information Systems ({ESIS}): {UML} and the {IS} Confidentiality},
	doi = {10.1109/SECURWARE.2008.66},
	shorttitle = {Toward the Engineering of Security of Information Systems ({ESIS})},
	abstract = {Managing the security of information systems ({SIS}) is at once a tedious task and the cornerstone of business in a highly competitive environment. Successful control of the {SIS} in a business requires many years of experience, expertise and continuous improvement. This implies real know-how for the employees who are responsible for {SIS} control. This article focuses on the encapsulation of this know-how into {UML} models through profiles according to the meta-object facility ({MOF}) standards from the object management group ({OMG}). The main idea is to understand, manipulate and exploit this delicate and valuable know-how without being necessarily an expert on {SIS}. This challenge is threefold: firstly, to find a common language, as well as approaches and tools for Engineering of both {IS} and {SIS}; secondly, to generate earnings and make use of the enormous progress in Engineering of {IS}, to establish and improve Engineering of {SIS}; and thirdly, to achieve homogeneous management and follow-up of {IT} projects and their security. This paper presents the context of the Engineering of Security of Information Systems, its importance and the feasibility of this challenge.},
	eventtitle = {2008 Second International Conference on Emerging Security Information, Systems and Technologies},
	pages = {248--256},
	booktitle = {2008 Second International Conference on Emerging Security Information, Systems and Technologies},
	author = {Goudalo, Wilson and Seret, Dominique},
	date = {2008-08},
	note = {{ISSN}: 2162-2116},
	keywords = {Access control, Security, Unified modeling language, Sensitivity, Information systems, Engineering of Security, {IS} Confidentiality, Management of Security, Modeling, Security of Information Systems, Silicon, {UML} profiles},
}

@article{buckovich_driving_1999,
	title = {Driving Toward Guiding Principles: A Goal for Privacy, Confidentiality, and Security of Health Information},
	volume = {6},
	issn = {1067-5027, 1527-974X},
	url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/jamia.1999.0060122},
	doi = {10.1136/jamia.1999.0060122},
	shorttitle = {Driving Toward Guiding Principles},
	pages = {122--133},
	number = {2},
	journaltitle = {Journal of the American Medical Informatics Association},
	shortjournal = {Journal of the American Medical Informatics Association},
	author = {Buckovich, S. A. and Rippen, H. E. and Rozen, M. J.},
	urldate = {2021-06-23},
	date = {1999-03-01},
	langid = {english},
}

@inproceedings{gerdes_decision_2015,
	title = {Decision buddy: tool support for constraint-based design decisions during system evolution},
	shorttitle = {Decision buddy},
	abstract = {Designing a software architecture is a highly complex task and associated with a high degree of uncertainty. There are a variety of reusable and established solutions, but they differ in their impact on the system's functionality and quality. The architect has to consider different aspects like stakeholders' requirements as well as numerous constraints coming, among others, from the technical environment and organization. The context of software evolution sheds a different light on constraints. The existing system with its structure based on previous decisions is a limiting factor constraining the ongoing development. However, current approaches do not sufficiently consider constraints induced by an existing system until now. To assist the architect in taking the right design decisions efficiently, tool support for the recommendation of solutions and structured documentation of the design decisions are indispensable. In our paper, we propose a decision process focusing on the consideration of constraints in evolving systems. Furthermore, we introduce our tool Decision Buddy and show how it contributes to the application of our constraint-based decision process.},
	eventtitle = {2015 1st International Workshop on Future of Software Architecture Design Assistants ({FoSADA})},
	pages = {1--6},
	booktitle = {2015 1st International Workshop on Future of Software Architecture Design Assistants ({FoSADA})},
	author = {Gerdes, Sebastian and Soliman, Mohamed and Riebisch, Matthias},
	date = {2015-05},
	keywords = {Computer architecture, Measurement, Software, Software architecture, Context, Documentation, Limiting},
}

@inproceedings{jasser_reusing_2016,
	location = {New York, {NY}, {USA}},
	title = {Reusing security solutions: a repository for architectural decision support},
	isbn = {978-1-4503-4781-5},
	url = {https://doi.org/10.1145/2993412.3007556},
	doi = {10.1145/2993412.3007556},
	series = {{ECSAW} '16},
	shorttitle = {Reusing security solutions},
	abstract = {Today, the interplay of security design and architecting is still poorly understood and architects lack knowledge about security and architectural security design. Yet, architectural knowledge on security design and its impact on other architectural properties is essential for making right decisions in architecture design. Knowledge is covered within solutions such as architectural patterns, tactics, and tools. Sharing it including the experience other architects gained using these solutions would enable better reuse of security solutions. In this paper, we present a repository for security solutions that supports architectural decisions including quality goal trade-offs. Its metamodel was adapted to special demands of security as a quality goal. The repository supports architecture decisions not only through populating approved solutions but through a recommender system that documents knowledge and experiences of architecture and security experts. We provide a case study to illustrate the repository's features and its application during architecture design.},
	pages = {1--7},
	booktitle = {Proccedings of the 10th European Conference on Software Architecture Workshops},
	publisher = {Association for Computing Machinery},
	author = {Jasser, Stefanie and Riebisch, Matthias},
	urldate = {2021-06-28},
	date = {2016-11-28},
	keywords = {software architecture, security by design, security engineering, reusing security solutions, secure architecture, secure software development},
}

@inproceedings{jasser_constraining_2019,
	location = {Cham},
	title = {Constraining the Implementation Through Architectural Security Rules: An Expert Study},
	isbn = {978-3-030-35333-9},
	doi = {10.1007/978-3-030-35333-9_15},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Constraining the Implementation Through Architectural Security Rules},
	abstract = {Today, security is still considered to late in the process of software engineering. Architectural rules for security can support software architects and developers in consciously taking security into account during design and implementation phase. They allow to monitor a software system’s security level. As a step towards monitoring and controlling the erosion of an architecture’s security specifications we present a set of rules derived from well-known security building blocks such as patterns along with our identification process. Through these rules we aim to support architects in monitoring the implementation’s conformance with security measures and, hence, in building secure software systems. The architectural security rules we identified are evaluated through expert interviews with industrial software engineers.},
	pages = {203--219},
	booktitle = {Product-Focused Software Process Improvement},
	publisher = {Springer International Publishing},
	author = {Jasser, Stefanie},
	editor = {Franch, Xavier and Männistö, Tomi and Martínez-Fernández, Silverio},
	date = {2019},
	langid = {english},
	keywords = {Software architecture, Architectural constraints, Architecture erosion, Architecture violations, Secure architecture, Security by design, Security constraints},
}

@online{reussner_palladio_2011,
	title = {The Palladio Component Model},
	url = {https://publikationen.bibliothek.kit.edu/1000022503},
	author = {Reussner, Ralf and Becker, Steffen and Burger, Erik and Happe, Jens and Hauck, Michael and Koziolek, Anne and Koziolek, Heiko and Krogmann, Klaus and Kuperberg, Michael},
	urldate = {2021-07-01},
	date = {2011},
	langid = {german},
}

@inproceedings{heinrich_methodology_2018,
	title = {A Methodology for Domain-Spanning Change Impact Analysis},
	doi = {10.1109/SEAA.2018.00060},
	abstract = {When modifying a cyber-physical system, the consequences of changes need to be understood beforehand to adequately assess risks and costs. Model-based change impact analysis is key for estimating the impact of a change before actually modifying the system. Existing change impact analysis approaches apply very similar algorithms for change propagation to instances of domain-specific metamodels. However, they lack fundamental concepts for domain-spanning change impact analysis. In this paper, we propose a generic methodology for domain-spanning change impact analysis to address limitations of existing approaches. Evaluation results show the relevancy and comprehensives of the methodology for several domains.},
	eventtitle = {2018 44th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	pages = {326--330},
	booktitle = {2018 44th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	author = {Heinrich, Robert and Busch, Kiana and Koch, Sandro},
	date = {2018-08},
	keywords = {Software, Analytical models, Task analysis, Adaptation models, Change Impact Analysis, Consistency, Cyber-physical systems, Prediction algorithms, Reuse, Software algorithms},
}

@article{debreceni_enforcing_2019,
	title = {Enforcing fine-grained access control for secure collaborative modelling using bidirectional transformations},
	volume = {18},
	issn = {1619-1366, 1619-1374},
	url = {http://link.springer.com/10.1007/s10270-017-0631-8},
	doi = {10.1007/s10270-017-0631-8},
	pages = {1737--1769},
	number = {3},
	journaltitle = {Software \& Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Debreceni, Csaba and Bergmann, Gábor and Ráth, István and Varró, Dániel},
	urldate = {2021-07-14},
	date = {2019-06},
	langid = {english},
}

@article{bergmann_towards_2017,
	title = {Towards Efﬁcient Evaluation of Rule-based Permissions for Fine-grained Access Control in Collaborative Modeling},
	abstract = {In case of collaborative modeling, complex systems are developed by diﬀerent stakeholders, in oﬄine submissions or online sessions. To guarantee security, access control policies need to be enforced during the collaboration. Levels of required conﬁdentiality and integrity may vary across modeling artifacts, and even features of a single model element. Fine-grained rule-based access control was proposed for ﬂexible and concise policies. Multiple rules in a policy are inherently subject to conﬂicts; we have previously shown how to interpret such conﬂicts in a consistent but also predictable way. However, in online collaboration scenarios, this interpretation has to be repeated upon each small change of the model, thus the computational cost can be prohibitive.},
	pages = {10},
	author = {Bergmann, Gábor and Debreceni, Csaba and Ráth, István and Varró, Dániel},
	date = {2017},
	langid = {english},
}

@article{camilli_runtime_2021,
	title = {Runtime Equilibrium Veriﬁcation for Resilient Cyber-Physical Systems},
	abstract = {Cyber-Physical Systems are the basis of more and more activities in our modern society. Therefore, providing comprehensive, ideally provable, evidence that they continuously exhibit acceptable behavior even in case of unexpected events represents a major challenge that is not completely addressed by existing veriﬁcation approaches. To this end, in this paper we exploit the notion of equilibrium, i.e., the ability of the system to maintain an acceptable behavior within its multidimensional viability zone and we propose {RUNE} ({RUNtime} Equilibrium veriﬁcation), an approach able to verify at runtime if the system satisﬁes the equilibrium condition. {RUNE} includes (i) a system speciﬁcation that takes into account the uncertainties related to partial knowledge and possible changes by adopting parametric Markov decision processes; (ii) the computation of the equilibrium condition to deﬁne the boundaries of the viability zone; and (iii) a runtime equilibrium veriﬁcation method that leverages on Bayesian inference to reduce the uncertainty under the required level and quantitatively reason about the ability of the system to remain inside the boundaries of the viability zone. We demonstrate the beneﬁts of the proposed approach on a running example from the robotics domain.},
	pages = {10},
	journaltitle = {{IEEE} {ACSOS}},
	author = {Camilli, Matteo and Mirandola, Raffaela and Scandurra, Patrizia},
	date = {2021},
	langid = {english},
}

@article{de_bruijn_antifragility_2020,
	title = {Antifragility as a design criterion for modelling dynamic systems},
	volume = {37},
	issn = {10927026},
	url = {http://doi.wiley.com/10.1002/sres.2574},
	doi = {10.1002/sres.2574},
	abstract = {Highly improbable events can have a substantial impact on complex socioeconomic systems and are frequently difficult to predict beforehand but easy to explain afterwards. Antifragile systems can withstand and benefit from this kind of outlier events, whereas merely robust systems cannot in any case. Yet the aim to design robust systems is almost as old as the system dynamics field itself. This research therefore aims to investigate the extent to which an antifragile system design criterion is more valuable than a robust one. By means of an extensive literature review, a simulation model was constructed, which is demonstrated to be antifragile. Comparing the antifragile and robust versions of the model shows that the former—as theorized—yields more favourable results in an environment with impactful outlier events. Implementing antifragility in systems involves the difficult task of changing policies (and, eventually, the mental models) of decisionmakers. Consequently, this research concludes that antifragility should not and cannot always be attained; its feasibility is to be assessed at the start of a system dynamics modelling project.},
	pages = {23--37},
	number = {1},
	journaltitle = {Systems Research and Behavioral Science},
	shortjournal = {Syst Res Behav Sci},
	author = {de Bruijn, Harald and Größler, Andreas and Videira, Nuno},
	urldate = {2021-07-16},
	date = {2020-01},
	langid = {english},
}

@inproceedings{gorgeon_anti-fragile_2015,
	title = {Anti-Fragile Information Systems},
	abstract = {As complex socio-technical systems composed of many interconnected parts, interacting in non-linear, dynamic, emergent and often unexpected ways Information Systems are fragile. In this paper we introduce the concept of antifragility as an alternative mean of apprehending the fragility of Information Systems and a novel way of dealing with risk, uncertainty and the unknown. Antifragility is the opposite of fragility. Antifragility allows to go beyond robustness or resilience by moving away from a predictive mode of thinking and decision making to a mode that embraces the unknown and randomness and focuses on the characteristics that render systems fragile rather than trying to assess and predict the chain of events that may harm them. We propose a set of guidelines for moving from the fragile toward the antifragile, and explore, for the processes of the {IS} function, their applications and the questions they raise for practice and research.},
	pages = {19},
	booktitle = {Proceedings of the International Conference on Information Systems - Exploring the Information Frontier, {ICIS} 2015, Fort Worth, Texas, {USA}, December 13-16, 2015},
	publisher = {Association for Information Systems},
	author = {Gorgeon, Arnaud},
	date = {2015},
	langid = {english},
}

@article{ramezani_approaches_2020,
	title = {Approaches for resilience and antifragility in collaborative business ecosystems},
	volume = {151},
	issn = {00401625},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0040162519304494},
	doi = {10.1016/j.techfore.2019.119846},
	abstract = {Contemporary business ecosystems are continuously challenged by unexpected disruptive events, which are increasing in their frequency and effects. A critical question is why do some organizations collapse in face of extreme events, while others not? On the other hand, current engineering and socio-technical systems were designed to operate in “mostly stable” situations; sporadic instability and disturbances are at best captured by exception handling mechanisms, focusing on reliability and robustness. Recent and more ambitious design goals, however, aim at building systems that are expected to cope with severe disruptions, and survive or even thrive in a context of volatility and uncertainty. This led to an increasing attention to the concepts of resilience and antifragility. As such, this article introduces the findings of a comprehensive literature survey aimed at shedding light on emerging concepts and approaches to handle disruptions in business ecosystems. Main contributions include a clarification of related concepts, identification and classification of disruption sources and drivers, and extensive lists of strategies and underlying capabilities to cope with disruptions. Related perspectives and approaches developed in multiple knowledge areas are also analysed and synthesized. Finally, a collection of engineered systems implementing promising approaches to increase resilience and antifragility are presented.},
	pages = {119846},
	journaltitle = {Technological Forecasting and Social Change},
	shortjournal = {Technological Forecasting and Social Change},
	author = {Ramezani, Javaneh and Camarinha-Matos, Luis M.},
	urldate = {2021-07-16},
	date = {2020-02},
	langid = {english},
}

@article{pagliari_engineering_2020,
	title = {Engineering cyber‐physical systems through performance‐based modelling and analysis: A case study experience report},
	volume = {32},
	issn = {2047-7473, 2047-7481},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/smr.2179},
	doi = {10.1002/smr.2179},
	shorttitle = {Engineering cyber‐physical systems through performance‐based modelling and analysis},
	abstract = {The process of engineering cyber-physical systems ({CPS}) is inevitably challenging because of the intrinsic problem of merging the specification of different ensembles that indicate hardware, software, and physical aspects of such systems. This intrinsic complexity is exacerbated when modelling and analysing the performance characteristics of {CPS} since multiple models need to coexist in order to get meaningful performance indicators. In this paper, we present a case study, a delivery robots system, whose experience is exploited towards building a guided process for engineering {CPS} through performance-based modelling and analysis. Model-based performance results are provided while analysing different design alternatives, thus to support architects in the process of better understanding the performance characteristics of {CPS} under development.},
	number = {1},
	journaltitle = {Journal of Software: Evolution and Process},
	shortjournal = {J Softw Evol Proc},
	author = {Pagliari, Lorenzo and Mirandola, Raffaela and Trubiani, Catia},
	urldate = {2021-07-16},
	date = {2020-01},
	langid = {english},
}

@inproceedings{pagliari_what_2019,
	location = {Paris, France},
	title = {To what extent formal methods are applicable for performance analysis of smart cyber-physical systems?},
	isbn = {978-1-4503-7142-1},
	url = {http://dl.acm.org/citation.cfm?doid=3344948.3344990},
	doi = {10.1145/3344948.3344990},
	abstract = {The dynamic nature of complex Cyber-Physical Systems ({CPS}) introduces new research challenges since they need to smartly deal with changing situations in their environment. This triggers the usage of methodologies that keep track of changes and raise alarms whether extra-functional requirements (e.g., safety, reliability, performance) are violated. In this context, we investigate the usage of formal methods as support to provide a model-based performance evaluation of smart {CPS}. The main goal is to understand to what extent well-known performance models, specifically Queueing Networks, are suitable to represent these dynamic scenarios.},
	eventtitle = {the 13th European Conference},
	pages = {139--144},
	booktitle = {Proceedings of the 13th European Conference on Software Architecture - {ECSA} '19 - volume 2},
	publisher = {{ACM} Press},
	author = {Pagliari, Lorenzo and D'Angelo, Mirko and Caporuscio, Mauro and Mirandola, Raffaela and Trubiani, Catia},
	urldate = {2021-07-16},
	date = {2019},
	langid = {english},
}

@inproceedings{grassi_tao_2021,
	location = {Stuttgart, Germany},
	title = {The Tao way to anti-fragile software architectures: the case of mobile applications},
	isbn = {978-1-66543-910-7},
	url = {https://ieeexplore.ieee.org/document/9425842/},
	doi = {10.1109/ICSA-C52384.2021.00021},
	shorttitle = {The Tao way to anti-fragile software architectures},
	abstract = {In an ever-changing world software architects need to embrace uncertainty and changes to exploit them in building better systems. We suggest that looking at the Taoist philosophy and its incarnation in the martial arts domain can help to promote this mental attitude and to get a better understanding of the potentialities of existing architectural approaches, using as a testbed the ﬁeld of mobile applications design.},
	eventtitle = {2021 {IEEE} 18th International Conference on Software Architecture Companion ({ICSA}-C)},
	pages = {86--89},
	booktitle = {2021 {IEEE} 18th International Conference on Software Architecture Companion ({ICSA}-C)},
	publisher = {{IEEE}},
	author = {Grassi, Vincenzo and Mirandola, Raffaela},
	urldate = {2021-07-16},
	date = {2021-03},
	langid = {english},
}

@incollection{de_lemos_perpetual_2017,
	location = {Cham},
	title = {Perpetual Assurances for Self-Adaptive Systems},
	volume = {9640},
	isbn = {978-3-319-74182-6 978-3-319-74183-3},
	url = {http://link.springer.com/10.1007/978-3-319-74183-3_2},
	abstract = {Providing assurances for self-adaptive systems is challenging. A primary underlying problem is uncertainty that may stem from a variety of different sources, ranging from incomplete knowledge to sensor noise and uncertain behavior of humans in the loop. Providing assurances that the self-adaptive system complies with its requirements calls for an enduring process spanning the whole lifetime of the system. In this process, humans and the system jointly derive and integrate new evidence and arguments, which we coined perpetual assurances for self-adaptive systems. In this paper, we provide a background framework and the foundation for perpetual assurances for self-adaptive systems. We elaborate on the concrete challenges of offering perpetual assurances, requirements for solutions, realization techniques and mechanisms to make solutions suitable. We also present benchmark criteria to compare solutions. We then present a concrete exemplar that researchers can use to assess and compare approaches for perpetual assurances for self-adaptation.},
	pages = {31--63},
	booktitle = {Software Engineering for Self-Adaptive Systems {III}. Assurances},
	publisher = {Springer International Publishing},
	author = {Weyns, Danny and Bencomo, Nelly and Calinescu, Radu and Camara, Javier and Ghezzi, Carlo and Grassi, Vincenzo and Grunske, Lars and Inverardi, Paola and Jezequel, Jean-Marc and Malek, Sam and Mirandola, Raffaela and Mori, Marco and Tamburrelli, Giordano},
	editor = {de Lemos, Rogério and Garlan, David and Ghezzi, Carlo and Giese, Holger},
	urldate = {2021-07-16},
	date = {2017},
	langid = {english},
	doi = {10.1007/978-3-319-74183-3_2},
	note = {Series Title: Lecture Notes in Computer Science},
}

@article{andersson_conceptual_2021,
	title = {A conceptual framework for resilience: fundamental definitions, strategies and metrics},
	volume = {103},
	issn = {0010-485X, 1436-5057},
	url = {http://link.springer.com/10.1007/s00607-020-00874-x},
	doi = {10.1007/s00607-020-00874-x},
	shorttitle = {A conceptual framework for resilience},
	abstract = {The resilience system property has become more and more relevant, mainly because of the increasing dependance on a rapidly growing number of software-intensive, complex, socio-technical systems, which are facing uncertainty about changes they are expected to experience during their lifecycle and ways to deal with them. Methodologies for the systematic design and validation of resilience for such systems are thus highly necessary, and require contributions from several diﬀerent ﬁelds. This paper contributes to current resilience research by providing a conceptual framework intended to serve as a common ground for the development of such methodologies. Its main points are: the identiﬁcation of the main categories of changes a system should face; a clear deﬁnition of the diﬀerent facets of resilience one could want to achieve, expressed in terms of the system dynamics; a mapping of each of these facets to design strategies that are better suited to achieve it; and the corresponding identiﬁcation of possible metrics that can be used to assess its achievement.},
	pages = {559--588},
	number = {4},
	journaltitle = {Computing},
	shortjournal = {Computing},
	author = {Andersson, Jesper and Grassi, Vincenzo and Mirandola, Raffaela and Perez-Palacin, Diego},
	urldate = {2021-07-16},
	date = {2021-04},
	langid = {english},
}

@inproceedings{espana_responsible_2016,
	location = {Amsterdam, the Netherlands},
	title = {Responsible software: A research agenda to help enterprises become more sustainable},
	isbn = {978-94-6252-224-4},
	url = {http://www.atlantis-press.com/php/paper-details.php?id=25860377},
	doi = {10.2991/ict4s-16.2016.17},
	shorttitle = {Responsible software},
	abstract = {{BACKGROUND}] Responsible enterprises are key to reaching a sustainable economy that cares about the people and the planet. Their spectrum is wide and it encompasses, among others, non-profit non-governmental organisations, social economy enterprises and companies with a committed corporate social responsibility. Responsible enterprises face many challenges, such as complying with governmental regulations, defining sustainable business models, having a positive social and environmental impact, and fostering ethical consumption. [{OBJECTIVE}] Our premise is that responsible enterprises need responsible software, which is software that assists enterprises in becoming increasingly responsible. We intend to discover the challenges that responsible enterprises face during the process of becoming more sustainable and to envision how enterprise modellers and software developers can use their competences and knowledge repositories to support enterprise missions. [{METHODOLOGY}] We have conducted a literature review and interviewed relevant stakeholders in the area in order to elicit a number of problematic phenomena related to enterprise responsibility. We then filtered the elicited issues to focus on those that are related to and can be tackled by applying software. [{RESULTS}] We have elaborated a roadmap for future research endeavours on responsible software. Interestingly, a core practice to be properly supported is socio-environmental auditing. [{CONCLUSION}] This research agenda will surely require close collaboration between academia and industry, as well as a close collaboration among experts from different disciplines. Let this paper be a call for action.},
	eventtitle = {{ICT} for Sustainability 2016},
	booktitle = {Proceedings of {ICT} for Sustainability 2016},
	publisher = {Atlantis Press},
	author = {Espana, Sergio and Brinkkemper, Sjaak},
	urldate = {2021-07-16},
	date = {2016},
	langid = {english},
}

@book{hummert_new_2005,
	title = {New Programming Language Concepts for Confidentiality.},
	abstract = {Programming languages scarcely support protection requirements, because this usually is considered to be the domain of the operating system. The paper discusses how protection of confidential data can benefit from new programming language concepts, comparing the characteristics of an aspect oriented and a component oriented approach to improve access control. Using the language Aspect! access control can be embedded in a single aspect, which can easily be programmed. Using the language Timor a combination of security mechanisms is applied. Thus more effort has to be made but security and maintainability of data are substantially increased.},
	pagetotal = {158},
	author = {Hummert, Christian and Menger, Gisela},
	date = {2005-01-01},
	note = {Journal Abbreviation: Proceedings of the 2005 International Conference on Programming Languages and Compilers, {PLC}'05
Pages: 164
Publication Title: Proceedings of the 2005 International Conference on Programming Languages and Compilers, {PLC}'05},
}

@article{jabal_methods_2019,
	title = {Methods and Tools for Policy Analysis},
	volume = {51},
	issn = {0360-0300},
	url = {https://doi.org/10.1145/3295749},
	doi = {10.1145/3295749},
	abstract = {Policy-based management of computer systems, computer networks and devices is a critical technology especially for present and future systems characterized by large-scale systems with autonomous devices, such as robots and drones. Maintaining reliable policy systems requires efficient and effective analysis approaches to ensure that the policies verify critical properties, such as correctness and consistency. In this paper, we present an extensive overview of methods for policy analysis. Then, we survey policy analysis systems and frameworks that have been proposed and compare them under various dimensions. We conclude the paper by outlining novel research directions in the area of policy analysis.},
	pages = {121:1--121:35},
	number = {6},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Jabal, Amani Abu and Davari, Maryam and Bertino, Elisa and Makaya, Christian and Calo, Seraphin and Verma, Dinesh and Russo, Alessandra and Williams, Christopher},
	urldate = {2021-07-20},
	date = {2019-02-04},
	keywords = {access control policies, change impact analysis, network policies, Policy analysis, policy design and organization, policy quality requirements, similarity analysis},
}

@inproceedings{hitz_developing_1998,
	title = {Developing with {UML} - Goodies, Pitfalls, Workarounds},
	abstract = {Abstract. The object-oriented modeling language {UML} offers various notations for all phases of application development. The user is left alone, however, when applying {UML} in up-to-date application development involving distribution, data management, and component-oriented mechanisms. Moreover, various shortcomings have been encountered, most notably w.r.t. refinement of model elements throughout the development life cycle and employment of interaction diagrams to formalize use cases. The paper will shed some light on how these issues may be handled with {UML}. 1},
	booktitle = {in ‼{UML}??'98: Beyond the Notation, 1st Int. Workshop on {UML}, ed. Jean Bezivin and Pierre-Allain Muller, Springer {LNCS}},
	author = {Hitz, Martin},
	date = {1998},
}

@inproceedings{hahner_architectural_2021,
	location = {Växjö, Sweden},
	title = {Architectural Access Control Policy Refinement and Verification under Uncertainty},
	eventtitle = {15th European Conference on Software Architecture ({ECSA} 2021)},
	pages = {1--5},
	booktitle = {Companion Proceedings of the 15th European Conference on Software Architecture ({ECSA}-C)},
	publisher = {{CEUR} Workshop Proceedings},
	author = {Hahner, Sebastian},
	date = {2021},
}

@article{grunwald_technology_2021,
	title = {Technology Assessment in post-pandemic times: investigating vulnerabilities for exploring strategies for resilience},
	volume = {1},
	doi = {10.31249/bisot/2020.12.15},
	pages = {193--2010},
	journaltitle = {Bioethics and Technology Assessment},
	author = {Grunwald, Armin},
	date = {2021},
}

@online{robert_koch_institute_open-source_2020,
	title = {Open-Source Project Corona-Warn-App},
	url = {https://www.coronawarn.app/en/},
	author = {Robert Koch Institute},
	urldate = {2021-07-29},
	date = {2020},
}

@book{taleb_antifragile_2012,
	title = {Antifragile: Things that gain from disorder},
	publisher = {Random House Incorporated},
	author = {Taleb, Nassim Nicholas},
	date = {2012},
}

@article{hasselbring_toward_2006,
	title = {Toward trustworthy software systems},
	volume = {39},
	issn = {1558-0814},
	doi = {10.1109/MC.2006.142},
	abstract = {Organizations such as Microsoft's Trusted Computing Group and Sun Microsystems' Liberty Alliance are currently leading the debate on "trustworthy computing." However, these and other initiatives primarily focus on security, and trustworthiness depends on many other attributes. To address this problem, the University of Oldenburg's {TrustSoft} Graduate School aims to provide a holistic view of trustworthiness in software - one that considers system construction, evaluation/analysis, and certification - in an interdisciplinary setting. Component technology is the foundation of our research program. The choice of a component architecture greatly influences the resulting software systems' nonfunctional properties. We are developing new methods for the rigorous design of trustworthy software systems with predictable, provable, and ultimately legally certifiable system properties. We are well aware that it is impossible to build completely error-free complex software systems. We therefore complement fault-prevention and fault-removal techniques with fault-tolerance methods that introduce redundancy and diversity into software systems. Quantifiable attributes such as availability, reliability, and performance call for analytical prediction models, which require empirical studies for calibration and validation. To consider the legal aspects of software certification and liability, {TrustSoft} integrates the disciplines of computer science and computer law.},
	pages = {91--92},
	number = {4},
	journaltitle = {Computer},
	author = {Hasselbring, W. and Reussner, R.},
	date = {2006-04},
	note = {Conference Name: Computer},
	keywords = {Security, Software systems, Law, Availability, Software design, Certification, Component architectures, Fault tolerant systems, Redundancy, Software technologies, Sun, {TrustSoft}},
}

@inproceedings{stol_grounded_2016,
	title = {Grounded Theory in Software Engineering Research: A Critical Review and Guidelines},
	doi = {10.1145/2884781.2884833},
	shorttitle = {Grounded Theory in Software Engineering Research},
	abstract = {Grounded Theory ({GT}) has proved an extremely useful research approach in several fields including medical sociology, nursing, education and management theory. However, {GT} is a complex method based on an inductive paradigm that is fundamentally different from the traditional hypothetico-deductive research model. As there are at least three variants of {GT}, some ostensibly {GT} research suffers from method slurring, where researchers adopt an arbitrary subset of {GT} practices that are not recognizable as {GT}. In this paper, we describe the variants of {GT} and identify the core set of {GT} practices. We then analyze the use of grounded theory in software engineering. We carefully and systematically selected 98 articles that mention {GT}, of which 52 explicitly claim to use {GT}, with the other 46 using {GT} techniques only. Only 16 articles provide detailed accounts of their research procedures. We offer guidelines to improve the quality of both conducting and reporting {GT} studies. The latter is an important extension since current {GT} guidelines in software engineering do not cover the reporting process, despite good reporting being necessary for evaluating a study and informing subsequent research.},
	eventtitle = {2016 {IEEE}/{ACM} 38th International Conference on Software Engineering ({ICSE})},
	pages = {120--131},
	booktitle = {2016 {IEEE}/{ACM} 38th International Conference on Software Engineering ({ICSE})},
	author = {Stol, Klaas-Jan and Ralph, Paul and Fitzgerald, Brian},
	date = {2016-05},
	note = {{ISSN}: 1558-1225},
	keywords = {Software, Encoding, Computer science, software engineering, Software engineering, Guidelines, Grounded theory, guidelines, Interviews, review, Sorting},
}

@inproceedings{gidey_grounded_2017,
	title = {Grounded Architectures: Using Grounded Theory for the Design of Software Architectures},
	doi = {10.1109/ICSAW.2017.41},
	shorttitle = {Grounded Architectures},
	abstract = {Context: Designing new architectures is a challenging task. A common and also effective approach for this task is to apply architectural design experience. Problem: If, however, architectural design experience is not available, two major problems arise: (i) how can we identify architecturally significant requirements ({ASRs}) and (ii) how can we identify architectural design decisions ({ADDs}) which address those {ASRs}?Approach: To address these problems, we propose an approach to systematically elicit {ASRs} and identify {ADDs} based on grounded theory ({GT}). By using {GT}, our approach provides transparency and fosters objectivity: {ASRs} as well as {ADDs} are elicited by qualitative data analysis and each {ADD} is motivated by corresponding {ASRs}. While objectivity addresses the correctness of the identified {ASRs} and {ADDs}, transparency allows for assessing {ADDs} with respect to the corresponding {ASRs}. Evaluation: We evaluate our approach by a case study in which we apply it to develop an architecture in the context of the technology trend "appification".},
	eventtitle = {2017 {IEEE} International Conference on Software Architecture Workshops ({ICSAW})},
	pages = {141--148},
	booktitle = {2017 {IEEE} International Conference on Software Architecture Workshops ({ICSAW})},
	author = {Gidey, Habtom Kahsay and Marmsoler, Diego and Eckhardt, Jonas},
	date = {2017-04},
	keywords = {Computer architecture, software architecture, Software architecture, Encoding, architectural design decisions, Context, Market research, design decisions, Tools, Interviews, appification, architectural design experience, architecturally significant requirements, grounded architecture, grounded theory, reference architecture},
}

@inproceedings{onabajo_modeling_2006,
	title = {Modeling and reasoning for confidentiality requirements in software development},
	doi = {10.1109/ECBS.2006.50},
	abstract = {Requirements engineering has attained an important role in software development over the last few years as developers and other stakeholders have realized the importance of adequate requirement analysis and design in software development processes. However, the specification and analysis of functional requirements is better established compared to non-functional requirements. This could be attributed to the fact that nonfunctional requirements, such as reliability, accuracy, performance, usability and security are often subjective. Security requirements are often incorporated in an ad hoc manner or considered at post-requirement phase. It is believed that addressing these requirements during the early phase of system development improves the quality of developed applications. Confidentiality is an aspect of a system's security requirements aimed at preventing unauthorized use of personal or corporate data. Concerns from the different stakeholders which can be diverging, have to be addressed, in realizing confidentiality requirements. These concerns are also usually influenced by proposed system functions. This research is aimed at precisely defining confidentiality requirements and applying this for modelling and reasoning in confidentiality requirements engineering},
	eventtitle = {13th Annual {IEEE} International Symposium and Workshop on Engineering of Computer-Based Systems ({ECBS}'06)},
	pages = {8 pp.--467},
	booktitle = {13th Annual {IEEE} International Symposium and Workshop on Engineering of Computer-Based Systems ({ECBS}'06)},
	author = {Onabajo, A. and Jahnke, J.H.},
	date = {2006-03},
	keywords = {Data security, Information security, Application software, Computer science, Software design, Design engineering, Programming, Biomedical engineering, Online Communities/Technical Collaboration, Usability},
}

@article{firesmith_specifying_2004,
	title = {Specifying Reusable Security Requirements.},
	volume = {3},
	issn = {1660-1769},
	url = {http://www.jot.fm/contents/issue_2004_01/column6.html},
	doi = {10.5381/jot.2004.3.1.c6},
	abstract = {Unlike typical functional requirements, security requirements can potentially be highly reusable, especially if specified as instances of reusable templates. In this column, I will discuss the concepts underlying security engineering including its quality subfactors. I will then address the issue of security requirements and how they differ from the architectural mechanisms that will fulfill them. Then, I will discuss the value of reusable parameterized templates for specifying security requirements and provide an example of such a template and its associated usage. Finally, I will outline an asset-based riskdriven analysis approach for determining the appropriate actual parameters to use when reusing such parameterized templates to specify security requirements.},
	pages = {61},
	number = {1},
	journaltitle = {The Journal of Object Technology},
	shortjournal = {{JOT}},
	author = {Firesmith, Donald},
	urldate = {2021-09-02},
	date = {2004},
	langid = {english},
}

@inproceedings{taspolatoglu_context-based_2016,
	title = {Context-Based Architectural Security Analysis},
	doi = {10.1109/WICSA.2016.55},
	abstract = {It is a challenging task to achieve security for software-intensive systems and to preserve it as systems change. Security degrades a lot faster than other non-functional properties, as it depends not only on the software, but also on software's context deeply. This degradation arises drastically, when developers do not include such security-related context information in their designs and neglect corresponding change impacts. In this paper, we propose our approach to document explicit context information of software systems formally and integrate them into an architecture description language ({ADL}) for security analysis. We show how these architectural improvements can support maintaining security properties by foreseeing impacts of evolutionary changes and reacting accordingly.},
	eventtitle = {2016 13th Working {IEEE}/{IFIP} Conference on Software Architecture ({WICSA})},
	pages = {281--282},
	booktitle = {2016 13th Working {IEEE}/{IFIP} Conference on Software Architecture ({WICSA})},
	author = {Taspolatoglu, Emre and Heinrich, Robert},
	date = {2016-04},
	keywords = {Security, Computer architecture, Software, Software architecture, Companies, Context, Stakeholders},
}

@article{becker_palladio_2009,
	title = {The Palladio component model for model-driven performance prediction},
	volume = {82},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121208001015},
	doi = {10.1016/j.jss.2008.03.066},
	series = {Special Issue: Software Performance - Modeling and Analysis},
	abstract = {One aim of component-based software engineering ({CBSE}) is to enable the prediction of extra-functional properties, such as performance and reliability, utilising a well-defined composition theory. Nowadays, such theories and their accompanying prediction methods are still in a maturation stage. Several factors influencing extra-functional properties need additional research to be understood. A special problem in {CBSE} stems from its specific development process: Software components should be specified and implemented independently from their later context to enable reuse. Thus, extra-functional properties of components need to be specified in a parametric way to take different influencing factors like the hardware platform or the usage profile into account. Our approach uses the Palladio component model ({PCM}) to specify component-based software architectures in a parametric way. This model offers direct support of the {CBSE} development process by dividing the model creation among the developer roles. This paper presents our model and a simulation tool based on it, which is capable of making performance predictions. Within a case study, we show that the resulting prediction accuracy is sufficient to support the evaluation of architectural design decisions.},
	pages = {3--22},
	number = {1},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Becker, Steffen and Koziolek, Heiko and Reussner, Ralf},
	urldate = {2021-09-03},
	date = {2009-01-01},
	langid = {english},
	keywords = {Software architecture, Performance prediction, Component-based software engineering},
}

@article{klare_enabling_2021,
	title = {Enabling consistency in view-based system development — The Vitruvius approach},
	volume = {171},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121220302144},
	doi = {10.1016/j.jss.2020.110815},
	abstract = {During the development of large software-intensive systems, developers use several modeling languages and tools to describe a system from different viewpoints. Model-driven and view-based technologies have made it easier to define domain-specific languages and transformations. Nevertheless, using several languages leads to fragmentation of information, to redundancies in the system description, and eventually to inconsistencies. Inconsistencies have negative impacts on the system’s quality and are costly to fix. Often, there is no support for consistency management across multiple languages. Using a single language is no practicable solution either, as it is overly complex to define, use, and evolve such a language. View-based development is a suitable approach to deal with complex systems, and is widely used in other engineering disciplines. Still, we need to cope with the problems of fragmentation and consistency. In this paper, we present the Vitruvius approach for consistency in view-based modeling. We describe the approach by formalizing the notion of consistency, presenting languages for consistency preservation, and defining a model-driven development process. Furthermore, we show how existing models can be integrated. We have evaluated our approach at two case studies from component-based and embedded automotive software development, using our prototypical implementation based on the Eclipse Modeling Framework.},
	pages = {110815},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Klare, Heiko and Kramer, Max E. and Langhammer, Michael and Werle, Dominik and Burger, Erik and Reussner, Ralf},
	urldate = {2021-09-03},
	date = {2021-01-01},
	langid = {english},
	keywords = {Consistency, Model transformations, Model views, Model-driven software development},
}

@inproceedings{martens_automatically_2010,
	location = {New York, {NY}, {USA}},
	title = {Automatically improve software architecture models for performance, reliability, and cost using evolutionary algorithms},
	isbn = {978-1-60558-563-5},
	url = {https://doi.org/10.1145/1712605.1712624},
	doi = {10.1145/1712605.1712624},
	series = {{WOSP}/{SIPEW} '10},
	abstract = {Quantitative prediction of quality properties (i.e. extra-functional properties such as performance, reliability, and cost) of software architectures during design supports a systematic software engineering approach. Designing architectures that exhibit a good trade-off between multiple quality criteria is hard, because even after a functional design has been created, many remaining degrees of freedom in the software architecture span a large, discontinuous design space. In current practice, software architects try to find solutions manually, which is time-consuming, can be error-prone and can lead to suboptimal designs. We propose an automated approach to search the design space for good solutions. Starting with a given initial architectural model, the approach iteratively modifies and evaluates architectural models. Our approach applies a multi-criteria genetic algorithm to software architectures modelled with the Palladio Component Model. It supports quantitative performance, reliability, and cost prediction and can be extended to other quantitative quality criteria of software architectures. We validate the applicability of our approach by applying it to an architecture model of a component-based business information system and analyse its quality criteria trade-offs by automatically investigating more than 1200 alternative design candidates.},
	pages = {105--116},
	booktitle = {Proceedings of the first joint {WOSP}/{SIPEW} international conference on Performance engineering},
	publisher = {Association for Computing Machinery},
	author = {Martens, Anne and Koziolek, Heiko and Becker, Steffen and Reussner, Ralf},
	urldate = {2021-09-03},
	date = {2010-01-28},
	keywords = {software architecture, performance, reliability, optimisation, cost, quality attribute prediction},
}

@inproceedings{koziolek_peropteryx_2011,
	location = {New York, {NY}, {USA}},
	title = {{PerOpteryx}: automated application of tactics in multi-objective software architecture optimization},
	isbn = {978-1-4503-0724-6},
	url = {https://doi.org/10.1145/2000259.2000267},
	doi = {10.1145/2000259.2000267},
	series = {{QoSA}-{ISARCS} '11},
	shorttitle = {{PerOpteryx}},
	abstract = {Designing software architectures that exhibit a good trade-off between multiple quality attributes is hard. Even with a given functional design, many degrees of freedom in the software architecture (e.g. component deployment or server configuration) span a large design space. In current practice, software architects try to find good solutions manually, which is time-consuming, can be error-prone and can lead to suboptimal designs. We propose an automated approach guided by architectural tactics to search the design space for good solutions. Our approach applies multi-objective evolutionary optimization to software architectures modelled with the Palladio Component Model. Software architects can then make well-informed trade-off decisions and choose the best architecture for their situation. To validate our approach, we applied it to the architecture models of two systems, a business reporting system and an industrial control system from {ABB}. The approach was able to find meaningful trade-offs leading to significant performance improvements or costs savings. The novel use of tactics decreased the time needed to find good solutions by up to 80\%.},
	pages = {33--42},
	booktitle = {Proceedings of the joint {ACM} {SIGSOFT} conference -- {QoSA} and {ACM} {SIGSOFT} symposium -- {ISARCS} on Quality of software architectures -- {QoSA} and architecting critical systems -- {ISARCS}},
	publisher = {Association for Computing Machinery},
	author = {Koziolek, Anne and Koziolek, Heiko and Reussner, Ralf},
	urldate = {2021-09-03},
	date = {2011-06-20},
	keywords = {software architecture, performance, optimization, reliability, architectural tactics, costs, multi-objective optimization},
}

@inproceedings{ahmad_towards_2018,
	location = {Cham},
	title = {Towards a Requirements Engineering Approach for Capturing Uncertainty in Cyber-Physical Systems Environment},
	isbn = {978-3-030-02852-7},
	doi = {10.1007/978-3-030-02852-7_11},
	series = {Communications in Computer and Information Science},
	abstract = {By nature, Cyber-physical systems are very often subjected to uncertainty events that can occur in their environment. This paper presents the first results of our work on how to deal with environment uncertainty in goal-based requirements engineering. This work is motivated by the fact that current goal-based approaches do not natively allow for unanticipated adaptations. To do so, we explore the introduction of {RELAX} concepts into {SysMLKaos}. {RELAX} is a Requirements Engineering language for Dynamically Adaptive Systems that includes explicit constructs to handle the inherent uncertainty in these systems. On the other hand, {SysMLKaos} is a Goal Based Requirements Engineering approach that takes into account Non-Functional Requirements at the same level of abstraction as Functional Requirements and models the impact of Non-Functional Requirements on Functional Requirements. We use an extract of a Landing Gear System case study to illustrate the proposed approach.},
	pages = {115--129},
	booktitle = {New Trends in Model and Data Engineering},
	publisher = {Springer International Publishing},
	author = {Ahmad, Manzoor and Gnaho, Christophe and Bruel, Jean-Michel and Laleau, Régine},
	editor = {Abdelwahed, El Hassan and Bellatreche, Ladjel and Benslimane, Djamal and Golfarelli, Matteo and Jean, Stéphane and Mery, Dominique and Nakamatsu, Kazumi and Ordonez, Carlos},
	date = {2018},
	langid = {english},
	keywords = {Cyber-physical systems, Critical systems, Goal oriented requirements modeling, Unanticipated adaptations},
}

@article{cheng_stitch_2012,
	title = {Stitch: A language for architecture-based self-adaptation},
	volume = {85},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121212000714},
	doi = {10.1016/j.jss.2012.02.060},
	series = {Self-Adaptive Systems},
	shorttitle = {Stitch},
	abstract = {Requirements for high availability in computing systems today demand that systems be self-adaptive to maintain expected qualities-of-service in the presence of system faults, variable environmental conditions, and changing user requirements. Autonomic computing tackles the challenge of automating tasks that humans would otherwise have to perform to achieve this goal. However, existing approaches to autonomic computing lack the ability to capture routine human repair tasks in a way that takes into account the business context humans use in selecting an appropriate form of adaptation, while dealing with timing delays and uncertainties in outcome of repair actions. In this article, we present Stitch, a language for representing repair strategies within the context of an architecture-based self-adaptation framework. Stitch supports the explicit representation of repair decision trees together with the ability to express business objectives, allowing a self-adaptive system to select a strategy that has optimal utility in a given context, even in the presence of potential timing delays and outcome uncertainty.},
	pages = {2860--2875},
	number = {12},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Cheng, Shang-Wen and Garlan, David},
	urldate = {2021-09-03},
	date = {2012-12-01},
	langid = {english},
	keywords = {Uncertainty, Self-adaptation, Rainbow, Strategy, Tactic, Utility},
}

@article{krupitzer_survey_2015,
	title = {A survey on engineering approaches for self-adaptive systems},
	volume = {17},
	issn = {1574-1192},
	url = {https://www.sciencedirect.com/science/article/pii/S157411921400162X},
	doi = {10.1016/j.pmcj.2014.09.009},
	series = {10 years of Pervasive Computing' In Honor of Chatschik Bisdikian},
	abstract = {The complexity of information systems is increasing in recent years, leading to increased effort for maintenance and configuration. Self-adaptive systems ({SASs}) address this issue. Due to new computing trends, such as pervasive computing, miniaturization of {IT} leads to mobile devices with the emerging need for context adaptation. Therefore, it is beneficial that devices are able to adapt context. Hence, we propose to extend the definition of {SASs} and include context adaptation. This paper presents a taxonomy of self-adaptation and a survey on engineering {SASs}. Based on the taxonomy and the survey, we motivate a new perspective on {SAS} including context adaptation.},
	pages = {184--206},
	journaltitle = {Pervasive and Mobile Computing},
	shortjournal = {Pervasive and Mobile Computing},
	author = {Krupitzer, Christian and Roth, Felix Maximilian and {VanSyckel}, Sebastian and Schiele, Gregor and Becker, Christian},
	urldate = {2021-09-03},
	date = {2015-02-01},
	langid = {english},
	keywords = {Taxonomy, Self-adaptation, Survey, Context adaptation, Self-adaptive systems},
}

@article{ding_modeling_2018,
	title = {Modeling Self-Adaptive Software Systems by Fuzzy Rules and Petri Nets},
	volume = {26},
	issn = {1941-0034},
	doi = {10.1109/TFUZZ.2017.2700286},
	abstract = {A self-adaptive software system is one that can autonomously modify its behavior at runtime in response to changes in the system and its environment. It is a challenge to model such a kind of systems since it is hard to predict runtime environmental changes at the design phase. In this paper, a formal model called intelligent Petri net (I-{PN}) is proposed to model a self-adaptive software system. I-{PN} is formed by incorporating fuzzy rules to a regular Petri net. The proposed net has the following advantages. 1) Since fuzzy rules can express the behavior of a system in an interpretable way and their variables can be reconfigured by the runtime data, the proposed model can model runtime environment and system behavior. 2) Since a fuzzy inference system with well-defined semantics can be used in a complementary way with other model languages for the analysis, thus the proposed model can be analyzed, even though it is described in two different languages: component behaviors in Petri nets while logic control in fuzzy rules. 3) The proposed model has self-adaption ability and can make adaptive decisions at runtime with the help of fuzzy inference reasoning. We adopt a manufacturing system to show the feasibility of the proposed model.},
	pages = {967--984},
	number = {2},
	journaltitle = {{IEEE} Transactions on Fuzzy Systems},
	author = {Ding, Zuohua and Zhou, Yuan and Zhou, Mengchu},
	date = {2018-04},
	note = {Conference Name: {IEEE} Transactions on Fuzzy Systems},
	keywords = {Computational modeling, Data models, Software systems, Adaptation models, Adaptive software system, fuzzy rule, Petri net ({PN}), Petri nets, Production facilities, Raw materials, requirement modeling},
}

@article{kruijff_designing_2014,
	title = {Designing, developing, and deploying systems to support human–robot teams in disaster response},
	volume = {28},
	issn = {0169-1864},
	url = {https://doi.org/10.1080/01691864.2014.985335},
	doi = {10.1080/01691864.2014.985335},
	abstract = {This paper describes our experience in designing, developing and deploying systems for supporting human–robot teams during disaster response. It is based on R\&D performed in the {EU}-funded project {NIFTi}. {NIFTi} aimed at building intelligent, collaborative robots that could work together with humans in exploring a disaster site, to make a situational assessment. To achieve this aim, {NIFTi} addressed key scientific design aspects in building up situation awareness in a human–robot team, developing systems using a user-centric methodology involving end users throughout the entire R\&D cycle, and regularly deploying implemented systems under real-life circumstances for experimentation and testing. This has yielded substantial scientific advances in the state-of-the-art in robot mapping, robot autonomy for operating in harsh terrain, collaborative planning, and human–robot interaction. {NIFTi} deployed its system in actual disaster response activities in Northern Italy, in July 2012, aiding in structure damage assessment.},
	pages = {1547--1570},
	number = {23},
	journaltitle = {Advanced Robotics},
	author = {Kruijff, G.J.M. and Kruijff-Korbayová, I. and Keshavdas, S. and Larochelle, B. and Janíček, M. and Colas, F. and Liu, M. and Pomerleau, F. and Siegwart, R. and Neerincx, M.A. and Looije, R. and Smets, N.J.J.M and Mioch, T. and van Diggelen, J. and Pirri, F. and Gianni, M. and Ferri, F. and Menna, M. and Worst, R. and Linder, T. and Tretyakov, V. and Surmann, H. and Svoboda, T. and Reinštein, M. and Zimmermann, K. and Petříček, T. and Hlaváč, V.},
	urldate = {2021-09-03},
	date = {2014-12-02},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/01691864.2014.985335},
	keywords = {disaster response, human–robot team, robot-assisted disaster response, user-centric design},
}

@article{cicchetti_multi-view_2019,
	title = {Multi-view approaches for software and system modelling: a systematic literature review},
	volume = {18},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-018-00713-w},
	doi = {10.1007/s10270-018-00713-w},
	shorttitle = {Multi-view approaches for software and system modelling},
	abstract = {Over the years, a number of approaches have been proposed on the description of systems and software in terms of multiple views represented by models. This modelling branch, so-called multi-view software and system modelling, praises a differentiated and complex scientific body of knowledge. With this study, we aimed at identifying, classifying, and evaluating existing solutions for multi-view modelling of software and systems. To this end, we conducted a systematic literature review of the existing state of the art related to the topic. More specifically, we selected and analysed 40 research studies among over 8600 entries. We defined a taxonomy for characterising solutions for multi-view modelling and applied it to the selected studies. Lastly, we analysed and discussed the data extracted from the studies. From the analysed data, we made several observations, among which: (i) there is no uniformity nor agreement in the terminology when it comes to multi-view artefact types, (ii) multi-view approaches have not been evaluated in industrial settings and (iii) there is a lack of support for semantic consistency management and the community does not appear to consider this as a priority. The study results provide an exhaustive overview of the state of the art for multi-view software and systems modelling useful for both researchers and practitioners.},
	pages = {3207--3233},
	number = {6},
	journaltitle = {Software and Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Cicchetti, Antonio and Ciccozzi, Federico and Pierantonio, Alfonso},
	urldate = {2021-09-06},
	date = {2019-12-01},
	langid = {english},
}

@article{derakhshanmanesh_model-integrating_2019,
	title = {Model-integrating development of software systems: a flexible component-based approach},
	volume = {18},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-018-0682-5},
	doi = {10.1007/s10270-018-0682-5},
	shorttitle = {Model-integrating development of software systems},
	abstract = {A promising way to develop flexible software systems is to include models that are analyzed, modified and executed at runtime as an integrated part of the system. Building such model-integrating systems is a challenging task since the respective modeling languages have to be supported comprehensively at runtime, and these systems still need to be developable in a modular way by composing them from basic building blocks. Model-driven ({MDD}) and component-based development ({CBD}) are two established orthogonal approaches that can tackle the mentioned challenges. {MDD} is based on the use of models and modeling languages as first-class entities to systematically engineer software systems. {CBD} enables the engineering of modular systems by facilitating a divide-and-conquer approach with reuse. However, combining and aligning the individual principles from both approaches is an open research problem. In this article, we describe model-integrating development ({MID}), an engineering approach that enables the systematic development of component-based, model-integrating software. {MID} combines principles from {MDD} and {CBD} and is based on the central assumption that models and code shall be treated equally as first-class entities of software throughout its life cycle. In particular, {MID} leverages the added flexibility that comes with models at runtime, i.e., when models are an integral part of running software. The practicability of the proposed solution concept is rationalized based on a reference implementation that provides the basis for a thoroughly described and critically discussed feasibility study: a dynamic access control product line. The obtained benefits are presented in a distilled way, and future research challenges are identified.},
	pages = {2557--2586},
	number = {4},
	journaltitle = {Software \& Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Derakhshanmanesh, Mahdi and Ebert, Jürgen and Grieger, Marvin and Engels, Gregor},
	urldate = {2021-09-06},
	date = {2019-08-01},
	langid = {english},
}

@article{vantendeloo_multi-paradigm_2019,
	title = {A Multi-Paradigm Modelling approach to live modelling},
	volume = {18},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-018-0700-7},
	doi = {10.1007/s10270-018-0700-7},
	abstract = {To develop complex systems and tackle their inherent complexity, (executable) modelling takes a prominent role in the development cycle. But whereas good tool support exists for programming, tools for executable modelling have not yet reached the same level of functionality and maturity. In particular, live programming is seeing increasing support in programming tools, allowing users to dynamically change the source code of a running application. This significantly reduces the edit–compile–debug cycle and grants the ability to gauge the effect of code changes instantly, aiding in debugging and code comprehension in general. In the modelling domain, however, live modelling only has limited support for a few formalisms. In this paper, we propose a Multi-Paradigm Modelling approach to add liveness to modelling languages in a generic way, which is reusable across multiple formalisms. Live programming concepts and techniques are transposed to (domain-specific) executable modelling languages, clearly distinguishing between generic and language-specific concepts. To evaluate our approach, live modelling is implemented for three modelling languages, for which the implementation of liveness substantially differs. For all three cases, the exact same structured process was used to enable live modelling, which only required a “sanitization” operation to be defined.},
	pages = {2821--2842},
	number = {5},
	journaltitle = {Software \& Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Van Tendeloo, Yentl and Van Mierlo, Simon and Vangheluwe, Hans},
	urldate = {2021-09-06},
	date = {2019-10-01},
	langid = {english},
}

@inproceedings{kramer_self-managed_2007,
	title = {Self-Managed Systems: an Architectural Challenge},
	doi = {10.1109/FOSE.2007.19},
	shorttitle = {Self-Managed Systems},
	abstract = {Self-management is put forward as one of the means by which we could provide systems that are scalable, support dynamic composition and rigorous analysis, and are flexible and robust in the presence of change. In this paper, we focus on architectural approaches to self-management, not because the language-level or network-level approaches are uninteresting or less promising, but because we believe that the architectural level seems to provide the required level of abstraction and generality to deal with the challenges posed. A self-managed software architecture is one in which components automatically configure their interaction in a way that is compatible with an overall architectural specification and achieves the goals of the system. The objective is to minimise the degree of explicit management necessary for construction and subsequent evolution whilst preserving the architectural properties implied by its specification. This paper discusses some of the current promising work and presents an outline three-layer reference model as a context in which to articulate some of the main outstanding research challenges.},
	eventtitle = {Future of Software Engineering ({FOSE} '07)},
	pages = {259--268},
	booktitle = {Future of Software Engineering ({FOSE} '07)},
	author = {Kramer, Jeff and Magee, Jeff},
	date = {2007-05},
	keywords = {Software architecture, Software systems, Books, Software engineering, Adaptive systems, Software design, Design engineering, Educational institutions, Computer networks, Concurrent computing},
}

@inproceedings{jackson_world_1995,
	title = {The World and the Machine},
	doi = {10.1145/225014.225041},
	abstract = {As software developers we are engineers because we make useful machines. We are concerned both with the world, in which the machine serves a useful purpose, and with the machine itself. The competing demands and attractions of these two concerns must be appropriately balanced. Failure to balance them harms our work. Certainly it must take some of the blame for the gulf between researchers and practitioners in software development. To achieve proper balance we must sometimes fight against tendencies and inclinations that are deeply ingrained in our customary practices and attitudes in software development. In this paper some aspects of the relationship between the world and the machine are explored; some sources of distortion are identified; and some suggestions are put forward for maintaining a proper balance.},
	eventtitle = {1995 17th International Conference on Software Engineering},
	pages = {283--283},
	booktitle = {1995 17th International Conference on Software Engineering},
	author = {Jackson, Michael},
	date = {1995-04},
	note = {{ISSN}: 0270-5257},
	keywords = {Software engineering},
}

@thesis{sinclair_access_2013,
	title = {Access Control In and For the Real World},
	abstract = {Access control is a core component of any information-security strategy. Researchers have spent tremendous energy over the past forty years defining abstract accesscontrol models and proving various properties about them. However, surprisingly little attention has been paid to how well these models work in real socio-technical systems (i.e., real human organizations). This dissertation describes the results of two qualitative studies (involving 52 participants from four companies, drawn from the financial, software, and healthcare sectors) and observes that the current practice of access control is dysfunctional at best. It diagnoses the broken assumptions that are at the heart of this dysfunction, and offers a new definition of the access-control problem that is grounded in the requirements and limitations of the real world.},
	type = {phdthesis},
	author = {Sinclair, S.},
	date = {2013},
}

@article{sinclair_whats_2010,
	title = {What's Wrong with Access Control in the Real World?},
	volume = {8},
	issn = {1540-7993},
	url = {http://ieeexplore.ieee.org/document/5523870/},
	doi = {10.1109/MSP.2010.139},
	pages = {74--77},
	number = {4},
	journaltitle = {{IEEE} Security \& Privacy Magazine},
	shortjournal = {{IEEE} Secur. Privacy Mag.},
	author = {Sinclair, Sara and Smith, Sean W.},
	urldate = {2021-09-10},
	date = {2010-07},
	langid = {english},
}

@inproceedings{bauer_real_2009,
	location = {Boston {MA} {USA}},
	title = {Real life challenges in access-control management},
	isbn = {978-1-60558-246-7},
	url = {https://dl.acm.org/doi/10.1145/1518701.1518838},
	doi = {10.1145/1518701.1518838},
	abstract = {In this work we ask the question: what are the challenges of managing a physical or ﬁle system access-control policy for a large organization? To answer the question, we conducted a series of interviews with thirteen administrators who manage access-control policy for either a ﬁle system or a physical space. Based on these interviews we identiﬁed three sets of real-world requirements that are either ignored or inadequately addressed by technology: 1) policies are made/implemented by multiple people; 2) policy makers are distinct from policy implementers; and 3) access-control systems don’t always have the capability to implement the desired policy. We present our interview results and propose several possible solutions to address the observed issues.},
	eventtitle = {{CHI} '09: {CHI} Conference on Human Factors in Computing Systems},
	pages = {899--908},
	booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {Bauer, Lujo and Cranor, Lorrie Faith and Reeder, Robert W. and Reiter, Michael K. and Vaniea, Kami},
	urldate = {2021-09-10},
	date = {2009-04-04},
	langid = {english},
}

@article{nguyen_extensive_2015,
	title = {An extensive systematic review on the Model-Driven Development of secure systems},
	volume = {68},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584915001482},
	doi = {10.1016/j.infsof.2015.08.006},
	abstract = {Context: Model-Driven Security ({MDS}) is as a specialised Model-Driven Engineering research area for supporting the development of secure systems. Over a decade of research on {MDS} has resulted in a large number of publications. Objective: To provide a detailed analysis of the state of the art in {MDS}, a systematic literature review ({SLR} ) is essential. Method: We conducted an extensive {SLR} on {MDS}. Derived from our research questions, we designed a rigorous, extensive search and selection process to identify a set of primary {MDS} studies that is as complete as possible. Our three-pronged search process consists of automatic searching, manual searching, and snowballing. After discovering and considering more than thousand relevant papers, we identified, strictly selected, and reviewed 108 {MDS} publications. Results: The results of our {SLR} show the overall status of the key artefacts of {MDS}, and the identified primary {MDS} studies. For example, regarding security modelling artefact, we found that developing domain-specific languages plays a key role in many {MDS} approaches. The current limitations in each {MDS} artefact are pointed out and corresponding potential research directions are suggested. Moreover, we categorise the identified primary {MDS} studies into 5 significant {MDS} studies, and other emerging or less common {MDS} studies. Finally, some trend analyses of {MDS} research are given. Conclusion: Our results suggest the need for addressing multiple security concerns more systematically and simultaneously, for tool chains supporting the {MDS} development cycle, and for more empirical studies on the application of {MDS} methodologies. To the best of our knowledge, this {SLR} is the first in the field of Software Engineering that combines a snowballing strategy with database searching. This combination has delivered an extensive literature study on {MDS}.},
	pages = {62--81},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Nguyen, Phu H. and Kramer, Max and Klein, Jacques and Traon, Yves Le},
	urldate = {2021-09-13},
	date = {2015-12-01},
	langid = {english},
	keywords = {Model-Driven Engineering, {MDS}, {MDE}, Model-Driven Security, Software security engineering, Systematic review},
}

@article{gurses_eliciting_2005-1,
	title = {Eliciting Conﬁdentiality Requirements in Practice},
	pages = {17},
	author = {Gurses, Seda and Jahnke, Jens H and Obry, Christina and Onabajo, Adeniyi and Santen, Thomas and Price, Morgan},
	date = {2005},
	langid = {english},
}

@inproceedings{seifermann_unified_2021,
	title = {A Unified Model to Detect Information Flow and Access Control Violations in Software Architectures},
	isbn = {978-989-758-524-1},
	url = {https://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0010515300260037},
	doi = {10.5220/0010515300260037},
	shorttitle = {A Unified Model to Detect Information Flow and Access Control Violations in Software Architectures},
	eventtitle = {18th International Conference on Security and Cryptography},
	pages = {26--37},
	booktitle = {Proceedings of the 18th International Conference on Security and Cryptography},
	publisher = {{SCITEPRESS} - Science and Technology Publications},
	author = {Seifermann, Stephan and Heinrich, Robert and Werle, Dominik and Reussner, Ralf},
	urldate = {2021-09-14},
	date = {2021},
	langid = {english},
}

@article{ghezzi_model-based_2013,
	title = {Model-based verification of quantitative non-functional properties for software product lines},
	volume = {55},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584912001516},
	doi = {10.1016/j.infsof.2012.07.017},
	series = {Special Issue on Software Reuse and Product Lines},
	abstract = {Evaluating quality attributes of a design model in the early stages of development can significantly reduce the cost and risks of developing a low quality product. To make this possible, software designers should be able to predict quality attributes by reasoning on a model of the system under development. Although there exists a variety of quality-driven analysis techniques for software systems, only a few work address software product lines. This paper describes how probabilistic model checking techniques and tools can be used to verify non-functional properties of different configurations of a software product line. We propose a model-based approach that enables software engineers to assess their design solutions for software product lines in the early stages of development. Furthermore, we discuss how the analysis time can be surprisingly reduced by applying parametric model checking instead of classic model checking. The results show that the parametric approach is able to substantially alleviate the verification time and effort required to analyze non-functional properties of software product lines.},
	pages = {508--524},
	number = {3},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Ghezzi, Carlo and Molzam Sharifloo, Amir},
	urldate = {2021-09-14},
	date = {2013-03-01},
	langid = {english},
	keywords = {Non-functional requirements, Parametric verification, Probabilistic model checking, Quality analysis, Software product lines},
}

@thesis{boltz_architectural_2021,
	title = {Architectural Uncertainty Analysis for Access Control Scenarios in Industry 4.0},
	url = {https://publikationen.bibliothek.kit.edu/1000135847},
	abstract = {Industrie 4.0-Systeme zeichnen sich durch ihre hohe Komplexität, Konnektivität und ihren hohen Datenaustausch aus. Aufgrund dieser Eigenschaften ist es entscheidend, eine Vertraulichkeit der Daten sicher zu stellen. Ein häufig verwendetes Verfahren zum Sicherstellen von Vertraulichkeit ist das Verwenden von Zugriffskontrolle. Basierend auf modellierter Softwarearchitektur, kann eine Zugriffskontrolle bereits während der Entwurfszeit konzeptionell auf das System angewendet werden. Dies ermöglicht es, potentielle Vertraulichkeitsprobleme bereits früh zu identifizieren und bietet die Möglichkeit, die Auswirkungen von Was-wäre-wenn-Szenarien auf die Vertraulichkeit zu analysieren, bevor entsprechende Änderungen umgesetzt werden. Ungewissheiten der Systemumgebung, die sich aus Unklarheiten in den frühen Phasen der Entwicklung oder der abstrakten Sicht des Softwarearchitekturmodells ergeben, können sich jedoch direkt auf bestehende Zugriffskontrollrichtlinien auswirken und zu einer reduzierten Vertraulichkeit führen. Um dies abzuschwächen, ist es wichtig, Ungewissheiten zu identifizieren und zu behandeln. In dieser Arbeit stellen wir unseren Ansatz zum Umgang mit Ungewissheiten der Zugriffskontrolle während der Entwurfszeit vor. Wir erstellen eine Charakterisierung von Ungewissheiten in der Zugriffskontrolle auf der Architekturebene, um ein besseres Verständnis über die existierenden Arten von Ungewissheiten zu erhalten. Darauf basierend definieren wir ein Konzept des Vertrauens in die Gültigkeit von Eigenschaften der Zugriffskontrolle. Dieses Konzept bietet die Möglichkeit mit Ungewissheiten umzugehen, die bereits in Publikationen zu Zugriffskontrollmodellen beschrieben wurden. Das Konzept des Vertrauens ist eine Zusammensetzung von Umgebungsfaktoren, die die Gültigkeit von und folglich das Vertrauen in Zugriffskontrolleigenschaften beeinflussen. Um Umgebungsfaktoren zu kombinieren und so Vertrauenswerte von Zugriffskontrolleigenschaften zu erhalten, nutzen wir Fuzzy-Inferenzsysteme. Diese erhaltenen Vertrauenswerte werden von einem Analyseprozess mit in Betracht gezogen, um Probleme zu identifizieren, die aus einem Mangel an Vertrauen entstehen. Wir erweitern einen bestehenden Ansatz zur Analyse von Informationsfluss und Zugriffskontrolle zur Entwurfszeit, basierend auf Datenflussdiagrammen. Das Wissen, welches wir mit unserem Konzept des Vertrauens hinzufügen, soll Softwarearchitekten die Möglichkeit geben, die Qualität ihrer Modelle zu erhöhen und Anforderungen an die Zugriffskontrolle ihrer Systeme bereits in frühen Phasen der Softwareentwicklung, unter Berücksichtigung von Ungewissheiten zu verifizieren. Die Anwendbarkeit unseres Ansatzes evaluieren wir anhand der Verfügbarkeit der notwendigen Daten in verschiedenen Phasen der Softwareentwicklung, sowie des potenziellen Mehrwerts für bestehende Systeme. Wir messen die Genauigkeit der Analyse beim Identifizieren von Problemen und die Skalierbarkeit hinsichtlich der Ausführungszeit, wenn verschiedene Modellaspekte individuell vergrößert werden.},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Master's Thesis},
	author = {Boltz, Nicolas},
	urldate = {2021-09-20},
	date = {2021},
	langid = {german},
	doi = {10.5445/IR/1000135847},
}

@report{reiche_modeling_2021,
	title = {Modeling and Verifying Access Control for Ethereum Smart Contracts},
	url = {https://publikationen.bibliothek.kit.edu/1000129607},
	author = {Reiche, Frederik and Schiffl, Jonas and Beckert, Bernhard and Heinrich, Robert and Reussner, Ralf},
	urldate = {2021-09-21},
	date = {2021},
	langid = {german},
	doi = {10.5445/IR/1000129607},
}

@article{maeder_modeling_2020,
	title = {Modeling and Validating Role-Based Authorization Policies for a Port Communication System with {UML} and {OCL}.},
	volume = {19},
	issn = {1660-1769},
	url = {http://www.jot.fm/contents/issue_2020_03/article8.html},
	doi = {10.5381/jot.2020.19.3.a8},
	abstract = {Modern sea or inland ports rely on digital communication and systems to boost rapid turnover of trade. Stakeholders like shippers, shipping lines, container terminals and port authorities collaborate and compete using their own legacy applications. Many sea ports operate Port Community Systems ({PCS}) to orchestrate processes between the players. These software systems are potential targets of security threats that may lead to payment fraud, espionage of competitors, smuggling, theft, export control violations, up to disasters involving dangerous goods possibly effecting public mains. In our approach we apply modeling to the ﬁeld of information security. We combine and focus on Role-Based Access Control ({RBAC}) with constraints and Attribute-Based Access Control ({ABAC}) for ﬁner grained authorization constraints. In a concrete case study we model authorization policies within port communities that partly utilize dedicated {PCS}. The purpose is to increase the integrity of exchanged data and thus reduce the risks of attacks or failures. We employ the {UML}-based Speciﬁcation Environment ({USE}) and its {OCL} support to validate speciﬁed security properties for a typical container shipping scenario.},
	pages = {3:1},
	number = {3},
	journaltitle = {The Journal of Object Technology},
	shortjournal = {{JOT}},
	author = {Maeder, Christian and Sohr, Karsten and Wete Nguempnang, Rodrigue and Meyer-Larsen, Nils and Müller, Rainer},
	urldate = {2021-09-22},
	date = {2020},
	langid = {english},
}

@inproceedings{berger_automatically_2016,
	location = {Cham},
	title = {Automatically Extracting Threats from Extended Data Flow Diagrams},
	isbn = {978-3-319-30806-7},
	doi = {10.1007/978-3-319-30806-7_4},
	series = {Lecture Notes in Computer Science},
	abstract = {Architectural risk analysis is an important aspect of developing software that is free of security flaws. Knowledge on architectural flaws, however, is sparse, in particular in small or medium-sized enterprises. In this paper, we propose a practical approach to architectural risk analysis that leverages Microsoft’s threat modeling. Our technique decouples the creation of a system’s architecture from the process of detecting and collecting architectural flaws. This way, our approach allows an software architect to automatically detect vulnerabilities in software architectures by using a security knowledge base. We evaluated our approach with real-world case studies, focusing on logistics applications. The evaluation uncovered several flaws with a major impact on the security of the software.},
	pages = {56--71},
	booktitle = {Engineering Secure Software and Systems},
	publisher = {Springer International Publishing},
	author = {Berger, Bernhard J. and Sohr, Karsten and Koschke, Rainer},
	editor = {Caballero, Juan and Bodden, Eric and Athanasopoulos, Elias},
	date = {2016},
	langid = {english},
	keywords = {Architectural risk analysis, Automatic flaw detection, Threat modeling},
}

@inproceedings{ferraiolo_extensible_2016,
	location = {New York, {NY}, {USA}},
	title = {Extensible Access Control Markup Language ({XACML}) and Next Generation Access Control ({NGAC})},
	isbn = {978-1-4503-4079-3},
	url = {https://doi.org/10.1145/2875491.2875496},
	doi = {10.1145/2875491.2875496},
	series = {{ABAC} '16},
	abstract = {Extensible Access Control Markup Language ({XACML}) and Next Generation Access Control ({NGAC}) are very different attribute based access control standards with similar goals and objectives. An objective of both is to provide a standardized way for expressing and enforcing vastly diverse access control policies in support of various types of data services. The two standards differ with respect to the manner in which access control policies and attributes are specified and managed, and decisions are computed and enforced. This paper is presented as a consolidation and refinement of public draft {NIST} {SP} 800-178 [21], describing, and comparing these two standards.},
	pages = {13--24},
	booktitle = {Proceedings of the 2016 {ACM} International Workshop on Attribute Based Access Control},
	publisher = {Association for Computing Machinery},
	author = {Ferraiolo, David and Chandramouli, Ramaswamy and Kuhn, Rick and Hu, Vincent},
	urldate = {2021-10-11},
	date = {2016-03-11},
	keywords = {access control, abac, ngac, policy machine, xacml},
}

@inproceedings{anderson_security_1996,
	title = {A security policy model for clinical information systems},
	doi = {10.1109/SECPRI.1996.502667},
	abstract = {The protection of personal health information has become a live issue in a number of countries, including the {USA}, Canada, Britain and Germany. The debate has shown that there is widespread confusion about what should be protected, and why. Designers of military and banking systems can refer to Bell \& {LaPadula} (1973) and Clark \& Wilson (1987) respectively, but there is no comparable security policy model that spells out clear and concise access rules for clinical information systems. In this article, we present just such a model. It was commissioned by doctors and is driven by medical ethics; it is informed by the actual threats to privacy, and reflects current best clinical practice. Its effect is to restrict both the number of users who can access any record and the maximum number of records accessed by any user. This entails controlling information flows across rather than down and enforcing a strong notification property. We discuss its relationship with existing security policy models, and its possible use in other applications where information exposure must be localised; these range from private banking to the management of intelligence data.},
	eventtitle = {Proceedings 1996 {IEEE} Symposium on Security and Privacy},
	pages = {30--43},
	booktitle = {Proceedings 1996 {IEEE} Symposium on Security and Privacy},
	author = {Anderson, R.J.},
	date = {1996-05},
	note = {{ISSN}: 1081-6011},
	keywords = {Data security, Information security, Privacy, Protection, Laboratories, Terminology, Banking, Clinical diagnosis, Ethics, Intelligent networks},
}

@inproceedings{anton_role_2001,
	title = {The role of policy and stakeholder privacy values in requirements engineering},
	doi = {10.1109/ISRE.2001.948553},
	abstract = {Diverse uses of information technology ({IT}) in organizations affect privacy. Developers of electronic commerce, database management, security mechanisms, telecommunication and collaborative systems should be aware of these effects and acknowledge the need for early privacy planning during the requirements definition activity. Public concerns about the collection of personal information by consumer-based Web sites have led most organizations running such sites to establish and publish privacy policies. However, these policies often fail to align with prevalent societal values on one hand and the operational functioning of Web-based applications on the other. Assuming that such misalignments stem from imperfect appreciation of consequences and not an intent to deceive, we discuss concepts, tools and techniques to help requirements engineers and {IT} policy makers bring policies and system requirements into better alignment. Our objective is to encourage {RE} researchers and practitioners to adopt a more holistic view of application and system specification, in which a system or application is seen as an engine of policy enforcement and values attainment.},
	eventtitle = {Proceedings Fifth {IEEE} International Symposium on Requirements Engineering},
	pages = {138--145},
	booktitle = {Proceedings Fifth {IEEE} International Symposium on Requirements Engineering},
	author = {Anton, A.I. and Earp, J.B. and Potts, C. and Alspaugh, T.A.},
	date = {2001-08},
	keywords = {Databases, Data privacy, Systems engineering and theory, Information technology, Business, Electronic commerce, Engineering management, Technology management, Optical computing, Telecommunication computing},
}

@inproceedings{seifermann_identifying_2021,
	location = {Växjö, Sweden},
	title = {Identifying Confidentiality Violations in Architectural Design Using Palladio},
	eventtitle = {15th European Conference on Software Architecture ({ECSA} 2021)},
	pages = {1--4},
	booktitle = {Companion Proceedings of the 15th European Conference on Software Architecture ({ECSA}-C)},
	publisher = {{CEUR} Workshop Proceedings},
	author = {Seifermann, Stephan and Walter, Maximilian and Hahner, Sebastian and Heinrich, Robert and Reussner, Ralf},
	date = {2021},
}

@article{guesmia_orbac_2018,
	title = {{OrBAC} from access control model to access usage model},
	volume = {48},
	issn = {1573-7497},
	url = {https://doi.org/10.1007/s10489-017-1064-3},
	doi = {10.1007/s10489-017-1064-3},
	pages = {1996--2016},
	number = {8},
	journaltitle = {Applied Intelligence},
	shortjournal = {Appl Intell},
	author = {Guesmia, Khalida and Boustia, Narhimene},
	urldate = {2021-11-02},
	date = {2018-08-01},
	langid = {english},
}

@book{busch_architecture-based_2020,
	title = {An Architecture-based Approach for Change Impact Analysis of Software-intensive Systems},
	isbn = {978-3-7315-0974-5},
	url = {https://www.ksp.kit.edu/site/books/m/10.5445/KSP/1000098183/},
	abstract = {{\textless}p{\textgreater}A main property of software-intensive technical systems is sustainability. Sustainable systems need to change continuously. A change to a system element can result in further changes to other system elements. If these elements originate from different domains, the change can also propagate between several domains. This book presents an architecture-based approach to change propagation analysis of software-intensive technical systems that considers heterogeneous elements from different domain.{\textless}/p{\textgreater}{\textless}p{\textgreater}\textit{Umfang: {XVII}, 383 S.}{\textless}/p{\textgreater}{\textless}p{\textgreater}\textit{Preis: €49.00 {\textbar} £45.00 {\textbar} \$86.00}{\textless}/p{\textgreater}},
	publisher = {{KIT} Scientific Publishing},
	author = {Busch, Kiana},
	urldate = {2021-11-02},
	date = {2020-03-19},
	langid = {english},
	doi = {10.5445/KSP/1000098183},
	note = {Publication Title: {KIT} Scientific Publishing},
}

@inproceedings{johnson_p2amf_2013,
	location = {Berlin, Heidelberg},
	title = {P2AMF: Predictive, Probabilistic Architecture Modeling Framework},
	isbn = {978-3-642-36796-0},
	doi = {10.1007/978-3-642-36796-0_10},
	series = {Lecture Notes in Business Information Processing},
	shorttitle = {P2AMF},
	abstract = {In the design phase of business and software system development, it is desirable to predict the properties of the system-to-be. Existing prediction systems do, however, not allow the modeler to express uncertainty with respect to the design of the considered system. In this paper, we propose a formalism, the Predictive, Probabilistic Architecture Modeling Framework (P2AMF), capable of advanced and probabilistically sound reasoning about architecture models given in the form of {UML} class and object diagrams. The proposed formalism is based on the Object Constraint Language ({OCL}). To {OCL}, P2AMF adds a probabilistic inference mechanism. The paper introduces P2AMF, describes its use for system property prediction and assessment, and proposes an algorithm for probabilistic inference.},
	pages = {104--117},
	booktitle = {Enterprise Interoperability},
	publisher = {Springer},
	author = {Johnson, Pontus and Ullberg, Johan and Buschle, Markus and Franke, Ulrik and Shahzad, Khurram},
	editor = {van Sinderen, Marten and Oude Luttighuis, Paul and Folmer, Erwin and Bosems, Steven},
	date = {2013},
	langid = {english},
	keywords = {{UML}, prediction, class diagram, Object Constraint Language, object diagram, probabilistic inference, system properties},
}

@article{kruchten_41_1995,
	title = {The 4+1 View Model of architecture},
	volume = {12},
	issn = {1937-4194},
	doi = {10.1109/52.469759},
	abstract = {The 4+1 View Model organizes a description of a software architecture using five concurrent views, each of which addresses a specific set of concerns. Architects capture their design decisions in four views and use the fifth view to illustrate and validate them. The logical view describes the design's object model when an object-oriented design method is used. To design an application that is very data driven, you can use an alternative approach to develop some other form of logical view, such as an entity-relationship diagram. The process view describes the design's concurrency and synchronization aspects. The physical view describes the mapping of the software onto the hardware and reflects its distributed aspect. The development view describes the software's static organization in its development environment.{\textless}{\textgreater}},
	pages = {42--50},
	number = {6},
	journaltitle = {{IEEE} Software},
	author = {Kruchten, P.B.},
	date = {1995-11},
	note = {Conference Name: {IEEE} Software},
	keywords = {Computer architecture, Software architecture, Application software, Hardware, Design methodology, Software design, Scalability, Concurrent computing, Data engineering, Physics computing},
}

@article{trubiani_performance_2019,
	title = {Performance Issues? Hey {DevOps}, Mind the Uncertainty},
	volume = {36},
	issn = {1937-4194},
	doi = {10.1109/MS.2018.2875989},
	shorttitle = {Performance Issues?},
	abstract = {{DevOps} is a novel trend that aims to bridge the gap between software development and operation teams. This article presents an experience report that better identifies performance uncertainties through a case study and provides a step-by-step guide to practitioners for controlling system uncertainties.},
	pages = {110--117},
	number = {2},
	journaltitle = {{IEEE} Software},
	author = {Trubiani, Catia and Jamshidi, Pooyan and Cito, Jurgen and Shang, Weiyi and Jiang, Zhen Ming and Borg, Markus},
	date = {2019-03},
	note = {Conference Name: {IEEE} Software},
	keywords = {Predictive models, Uncertainty, Analytical models, Hardware, Runtime, Performance analysis, {DevOps}, Performance Analysis, Software development, Software Development},
}

@article{aleti_efficient_2018,
	title = {An Efficient Method for Uncertainty Propagation in Robust Software Performance Estimation},
	volume = {138},
	issn = {01641212},
	url = {http://arxiv.org/abs/1801.04644},
	doi = {10.1016/j.jss.2018.01.010},
	pages = {222--235},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Aleti, Aldeida and Trubiani, Catia and van Hoorn, André and Jamshidi, Pooyan},
	urldate = {2021-11-17},
	date = {2018-04},
	eprinttype = {arxiv},
	eprint = {1801.04644},
	keywords = {Computer Science - Software Engineering},
}

@article{bao_quantitative_2017,
	title = {Quantitative Performance Evaluation of Uncertainty-Aware Hybrid {AADL} Designs Using Statistical Model Checking},
	volume = {36},
	issn = {1937-4151},
	doi = {10.1109/TCAD.2017.2681076},
	abstract = {The hybrid architecture analysis and design language ({AADL}) has been proposed to model the interactions between embedded control systems and continuous physical environment. However, the worst-case performance analysis of hybrid {AADL} designs often leads to overly pessimistic estimations, and is not suitable for accurate reasoning about overall system performance, in particular when the system closely interacts with an uncertain external environment. To address this challenge, this paper proposes a statistical model checking-based framework that can perform quantitative evaluation of uncertainty-aware hybrid {AADL} designs against various performance queries. Our approach extends hybrid {AADL} to support the modeling of environment uncertainties. Furthermore, we propose a set of transformation rules that can automatically translate {AADL} designs together with designers' requirements into networks of priced timed automata and performance queries, respectively. Comprehensive experimental results on the movement authority scenario of Chinese train control system level 3 demonstrate the effectiveness of our approach.},
	pages = {1989--2002},
	number = {12},
	journaltitle = {{IEEE} Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	author = {Bao, Yongxiang and Chen, Mingsong and Zhu, Qi and Wei, Tongquan and Mallet, Frederic and Zhou, Tingliang},
	date = {2017-12},
	note = {Conference Name: {IEEE} Transactions on Computer-Aided Design of Integrated Circuits and Systems},
	keywords = {Computational modeling, uncertainty, Uncertainty, Computer architecture, Analytical models, Ports (Computers), Model checking, Hybrid architecture analysis and design language ({AADL}), quantitative performance evaluation, Statistical analysis, statistical model checking ({SMC})},
}

@article{koziolek_performance_2010,
	title = {Performance evaluation of component-based software systems: A survey},
	volume = {67},
	issn = {0166-5316},
	url = {https://www.sciencedirect.com/science/article/pii/S016653160900100X},
	doi = {10.1016/j.peva.2009.07.007},
	series = {Special Issue on Software and Performance},
	shorttitle = {Performance evaluation of component-based software systems},
	abstract = {Performance prediction and measurement approaches for component-based software systems help software architects to evaluate their systems based on component performance specifications created by component developers. Integrating classical performance models such as queueing networks, stochastic Petri nets, or stochastic process algebras, these approaches additionally exploit the benefits of component-based software engineering, such as reuse and division of work. Although researchers have proposed many approaches in this direction during the last decade, none of them has attained widespread industrial use. On this basis, we have conducted a comprehensive state-of-the-art survey of more than 20 of these approaches assessing their applicability. We classified the approaches according to the expressiveness of their component performance modelling languages. Our survey helps practitioners to select an appropriate approach and scientists to identify interesting topics for future research.},
	pages = {634--658},
	number = {8},
	journaltitle = {Performance Evaluation},
	shortjournal = {Performance Evaluation},
	author = {Koziolek, Heiko},
	urldate = {2021-11-17},
	date = {2010-08-01},
	langid = {english},
	keywords = {Classification, Measurement, Modelling, {CBSE}, Performance, Survey, Prediction, Software component},
}

@article{resconi_hierarchical_1992,
	title = {Hierarchical Uncertainty Metatheory Based Upon Modal Logic},
	volume = {21},
	issn = {0308-1079, 1563-5104},
	url = {https://doi.org/10.1080/03081079208945051},
	doi = {10.1080/03081079208945051},
	abstract = {This paper is intended to contribute to the formal study of uncertainty from u broad perspective. Its aim is to demonstrate that, in addition to prepositional calculus and probability theory, both fuzzy set theory and Dempster-Shafer evidence theory can be represented by the formal and semantic structures of modal logic. In particular, it is shown that the concept of multiple worlds in modal logic can be employed for constructing membership-grade functions of fuzzy sets, as well as belief and plausibility measures of evidence theory. It is also shown that additional theories of uncertainty, which have not been considered us yet. emerge naturally from the framework of modal logic. When looking at these various uncertainty theories emerging from modal logic from a metatheoretical perspective, a hierarchical ordering of the theories is recognized. We refer to the hierarchically ordered collection of uncertainly theories captured within the realm of modal logic as hierarchical uncertainty metatheory. Although we introduce relevant notation and key concepts of fuzzy set theory and evidence theory, we assume that the reader is familiar with the fundamentals of these theories. We do not assume knowledge of modal logic, but we overview only those of its aspects that we need for our purpose in this paper.},
	pages = {23--50},
	number = {1},
	journaltitle = {International Journal of General Systems},
	shortjournal = {International Journal of General Systems},
	author = {Resconi, Germano and Klir, George J. and Clair, Ute St.},
	urldate = {2021-11-17},
	date = {1992-06-01},
	langid = {english},
	keywords = {uncertainty, belief measure, fuzzy set, hierarchical uncertainty metatheory, Modal logic, necessity operator, plausibility measure, possibility operator},
}

@article{longtin_uncertainty_2002,
	title = {The uncertainty tree: Reducing the uncertainty of uncertainty analysis},
	volume = {73},
	issn = {0034-6748, 1089-7623},
	url = {http://aip.scitation.org/doi/10.1063/1.1505654},
	doi = {10.1063/1.1505654},
	shorttitle = {The uncertainty tree},
	pages = {3698--3700},
	number = {10},
	journaltitle = {Review of Scientific Instruments},
	shortjournal = {Review of Scientific Instruments},
	author = {Longtin, Jon P.},
	urldate = {2021-11-17},
	date = {2002-10},
	langid = {english},
}

@inproceedings{carrillo_ripple_2018,
	location = {New York, {NY}, {USA}},
	title = {Ripple effect to evaluate the impact of changes in architectural design decisions},
	isbn = {978-1-4503-6483-6},
	url = {https://doi.org/10.1145/3241403.3241446},
	doi = {10.1145/3241403.3241446},
	series = {{ECSA} '18},
	abstract = {Software architectures are affected by evolution cycles when requirements or the system change. When architectural elements are modified other parts of the design can be impacted by these changes, and be propagated to all software products. As the frequency and depth of architectural changes may affect the stability of the architecture, it becomes important to estimate how stable or unstable an architecture is during evolution cycles. Although this problem has been addressed at the class level there are no clues how the underpinning design decisions that lead to architectural changes impact on the stability of designs. Existing ripple effect algorithms aimed to estimate the effect of changes in code are rarely used in architecture and to the best of our knowledge never used to analyze the stability of design decisions. We suggest in the paper a new ripple effect technique to evaluate how a change in a design decision may affect other decisions and to assess software architects on the most stable and unstable decisions. We provide a categorization of dependency types between related decisions to improve the efficiency of our ripple effect approach during the analysis of the stability of decisions and architectures.},
	pages = {1--8},
	booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
	publisher = {Association for Computing Machinery},
	author = {Carrillo, Carlos and Capilla, Rafael},
	urldate = {2021-11-23},
	date = {2018-09-24},
	keywords = {software architecture, sustainability, design decisions, evolution, instability, ripple effect, stability},
}

@inproceedings{fernandez_methodology_2004,
	title = {A methodology for secure software design},
	abstract = {A good percentage of the software deployed in industrial/commercial applications is of poor quality and contains numerous flaws that can be exploited by attackers. There are many reasons for this and there is no doubt that we have a serious problem, every day the press reports of attacks to web sites or databases around the world, resulting in millions of dollars in direct or},
	pages = {21--24},
	booktitle = {Procs. of the 2004 Int. Conf. on Software Engineering Research and Practice ({SERP}’04},
	author = {Fernandez, Eduardo B.},
	date = {2004},
}

@article{de_capitani_di_vimercati_access_2003,
	title = {Access control: principles and solutions},
	volume = {33},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.513},
	doi = {10.1002/spe.513},
	shorttitle = {Access control},
	abstract = {Access control is the process of mediating every request to resources and data maintained by a system and determining whether the request should be granted or denied. The variety and complexity of the protection requirements that may need to be imposed makes access control a far from trivial process. Expressiveness and flexibility are top requisites for an access control system together with, and usually in conflict with, simplicity and efficiency. In this paper, we discuss the main desiderata for access control systems and illustrate the main characteristics of access control solutions in some of the most popular existing systems. Copyright © 2003 John Wiley \& Sons, Ltd.},
	pages = {397--421},
	number = {5},
	journaltitle = {Software: Practice and Experience},
	author = {De Capitani di Vimercati, Sabrina and Paraboschi, Stefano and Samarati, Pierangela},
	urldate = {2021-11-23},
	date = {2003},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.513},
	keywords = {access control, {DBMS}, Internet-based solutions, operating systems, security principles},
}

@book{schumacher_security_2013,
	title = {Security Patterns: Integrating security and systems engineering},
	publisher = {John Wiley \& Sons},
	author = {Schumacher, Markus and Fernandez-Buglioni, Eduardo and Hybertson, Duane and Buschmann, Frank and Sommerlad, Peter},
	date = {2013},
}

@inproceedings{schulz_continuous_2021,
	location = {Leipzig, Germany},
	title = {Continuous Secure Software Development and Analysis},
	eventtitle = {Symposium on Software Performance},
	pages = {1--6},
	booktitle = {Proceedings of Symposium on Software Performance 2021},
	publisher = {{CEUR} Workshop Proceedings},
	author = {Schulz, Sophie and Reiche, Frederik and Hahner, Sebastian and Schiffl, Jonas},
	date = {2021},
}

@article{seifermann_detecting_2022,
	title = {Detecting violations of access control and information flow policies in data flow diagrams},
	volume = {184},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121221002351},
	doi = {10.1016/j.jss.2021.111138},
	abstract = {The security of software-intensive systems is frequently attacked. High fines or loss in reputation are potential consequences of not maintaining confidentiality, which is an important security objective. Detecting confidentiality issues in early software designs enables cost-efficient fixes. A Data Flow Diagram ({DFD}) is a modeling notation, which focuses on essential, functional aspects of such early software designs. Existing confidentiality analyses on {DFDs} support either information flow control or access control, which are the most common confidentiality mechanisms. Combining both mechanisms can be beneficial but existing {DFD} analyses do not support this. This lack of expressiveness requires designers to switch modeling languages to consider both mechanisms, which can lead to inconsistencies. In this article, we present an extended {DFD} syntax that supports modeling both, information flow and access control, in the same language. This improves expressiveness compared to related work and avoids inconsistencies. We define the semantics of extended {DFDs} by clauses in first-order logic. A logic program made of these clauses enables the automated detection of confidentiality violations by querying it. We evaluate the expressiveness of the syntax in a case study. We attempt to model nine information flow cases and six access control cases. We successfully modeled fourteen out of these fifteen cases, which indicates good expressiveness. We evaluate the reusability of models when switching confidentiality mechanisms by comparing the cases that share the same system design, which are three pairs of cases. We successfully show improved reusability compared to the state of the art. We evaluated the accuracy of confidentiality analyses by executing them for the fourteen cases that we could model. We experienced good accuracy.},
	pages = {111138},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Seifermann, Stephan and Heinrich, Robert and Werle, Dominik and Reussner, Ralf},
	urldate = {2021-12-21},
	date = {2022-02-01},
	langid = {english},
	keywords = {Access control, Information flow, Data flow diagram},
}

@online{oasis_extensible_2013,
	title = {{eXtensible} Access Control Markup Language ({XACML}) Version 3.0},
	url = {http://docs.oasis-open.org/xacml/3.0/xacml-3.0-core-spec-os-en.html},
	author = {{OASIS}},
	urldate = {2021-12-22},
	date = {2013},
}

@inproceedings{chilton_assume-guarantee_2013,
	location = {Berlin, Heidelberg},
	title = {Assume-Guarantee Reasoning for Safe Component Behaviours},
	isbn = {978-3-642-35861-6},
	doi = {10.1007/978-3-642-35861-6_6},
	series = {Lecture Notes in Computer Science},
	abstract = {We formulate a sound and complete assume-guarantee framework for reasoning compositionally about safety properties of component behaviours. The specification of a component, which constrains the temporal ordering of input and output interactions with the environment, is expressed in terms of two prefix-closed sets of traces: an assumption and guarantee. The framework supports dynamic reasoning about components and specifications, and includes rules for parallel composition, logical conjunction corresponding to independent development, and quotient for incremental synthesis. Practical applicability of the framework is demonstrated by considering a simple printing example.},
	pages = {92--109},
	booktitle = {Formal Aspects of Component Software},
	publisher = {Springer},
	author = {Chilton, Chris and Jonsson, Bengt and Kwiatkowska, Marta},
	editor = {Păsăreanu, Corina S. and Salaün, Gwen},
	date = {2013},
	langid = {english},
	keywords = {assume-guarantee, components, compositionality, conjunction, parallel, quotient, specification theory},
}

@article{fernandez_basic_1990,
	title = {Basic Taxonomic Structures and Levels of Abstraction},
	volume = {1},
	issn = {2324-9773},
	url = {https://journals.lib.washington.edu/index.php/acro/article/view/12464},
	doi = {10.7152/acro.v1i1.12464},
	abstract = {Taxonomic knowledge structures are often used to organize information. We compare basic taxonomic structures in four areas: thesaurus construction in information retrieval, semantic data models in database management systems, semantic networks in artificial intelligence, and mental structures in cognitive psychology. We then discuss levels of abstraction, in panicular the importance of intermediate levels. In mental structures these turn out to be basic levels that are more important cognitively than higher or lower levels. We explore the role of abstraction levels in other taxonomic structures and suggest possible future research in this area.},
	pages = {59--70},
	number = {1},
	journaltitle = {Advances in Classification Research Online},
	author = {Fernandez, Marta J. and Eastman, Caroline M.},
	urldate = {2022-02-14},
	date = {1990-10-06},
	langid = {american},
}

@article{paiva_privacy_2020,
	title = {Privacy and security challenges in smart and sustainable mobility},
	volume = {2},
	issn = {2523-3971},
	url = {https://doi.org/10.1007/s42452-020-2984-9},
	doi = {10.1007/s42452-020-2984-9},
	abstract = {The current era of computing is witnessing a huge amount of data being generated with every passing moment. This massive data if nourished effectively can open new horizons for the computing world. The modern world is slowly but surely moving towards the automation age where every entity and object is being automated to perform desired tasks without the need of human interventions. This has made the lives of people more convenient and comfortable. Automation has taken over every single field of computing and even beyond. Smart mobility is one such example of automation wherein the users get real time information about the traffic conditions as well as alternate route suggestions in case of traffic jams. Transportation is considered as the backbone of every business. The automated intelligent transportation system ({ITS}) has completely transformed the way how people, goods and services are transported and is quite important for achieving sustainability. This paper provides an overview of the existing {ITS} system, concept of smart mobility and existing vulnerabilities in these systems. Their security concerns and scenarios are also analyzed. Furthermore, in this paper the importance and need for securing these intelligent systems is highlighted and future trends in {ITS} is also suggested. Although {ITS} and smart mobility technology are already providing convenient transportation and navigational facilities, there is still a huge scope to improve these facilities for the end users. The suggested future trends if integrated in an effective manner can provide exemplary means to provide state-of-the-art navigational facilities and smart mobility in a true sense.},
	pages = {1175},
	number = {7},
	journaltitle = {{SN} Applied Sciences},
	shortjournal = {{SN} Appl. Sci.},
	author = {Paiva, Sara and Ahad, Mohd Abdul and Zafar, Sherin and Tripathi, Gautami and Khalique, Aqeel and Hussain, Imran},
	urldate = {2022-03-02},
	date = {2020-06-06},
	langid = {english},
}

@inproceedings{xu_trajectory_2017,
	location = {Perth Australia},
	title = {Trajectory Recovery From Ash: User Privacy Is {NOT} Preserved in Aggregated Mobility Data},
	isbn = {978-1-4503-4913-0},
	url = {https://dl.acm.org/doi/10.1145/3038912.3052620},
	doi = {10.1145/3038912.3052620},
	shorttitle = {Trajectory Recovery From Ash},
	abstract = {Human mobility data has been ubiquitously collected through cellular networks and mobile applications, and publicly released for academic research and commercial purposes for the last decade. Since releasing individual’s mobility records usually gives rise to privacy issues, datasets owners tend to only publish aggregated mobility data, such as the number of users covered by a cellular tower at a speciﬁc timestamp, which is believed to be suﬃcient for preserving users’ privacy. However, in this paper, we argue and prove that even publishing aggregated mobility data could lead to privacy breach in individuals’ trajectories. We develop an attack system that is able to exploit the uniqueness and regularity of human mobility to recover individual’s trajectories from the aggregated mobility data without any prior knowledge. By conducting experiments on two real-world datasets collected from both mobile application and cellular network, we reveal that the attack system is able to recover users’ trajectories with accuracy about 73\%∼91\% at the scale of tens of thousands to hundreds of thousands users, which indicates severe privacy leakage in such datasets. Through the investigation on aggregated mobility data, our work recognizes a novel privacy problem in publishing statistic data, which appeals for immediate attentions from both academy and industry.},
	eventtitle = {{WWW} '17: 26th International World Wide Web Conference},
	pages = {1241--1250},
	booktitle = {Proceedings of the 26th International Conference on World Wide Web},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Xu, Fengli and Tu, Zhen and Li, Yong and Zhang, Pengyu and Fu, Xiaoming and Jin, Depeng},
	urldate = {2022-03-02},
	date = {2017-04-03},
	langid = {english},
}

@thesis{benkler_architecture-based_2022,
	title = {Architecture-based Uncertainty Impact Analysis for Confidentiality},
	pagetotal = {169},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Master's Thesis},
	author = {Benkler, Niko},
	date = {2022},
}

@inproceedings{arabo_privacy_2012,
	title = {Privacy in the Age of Mobility and Smart Devices in Smart Homes},
	doi = {10.1109/SocialCom-PASSAT.2012.108},
	abstract = {Privacy concerns arise in a wide range of context. One of such context is in smart devices used within smart environment. Adaptors of such developments are generating an ever-increasing amount of data, this is often done without their consent or been fully aware of the implications of sharing and using such devices. This paper identifies the implications and challenges of privacy to smart devices in smart homes. The paper begins with a background and motivation. Subsequently, current privacy and security issues are discussed and analysed. Framework for privacy and security in smart homes is proposed and discussed in the subsequent section, while also presenting early simulation results.},
	eventtitle = {2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing},
	pages = {819--826},
	booktitle = {2012 International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing},
	author = {Arabo, Abdullahi and Brown, Ian and El-Moussa, Fadi},
	date = {2012-09},
	keywords = {user control, privacy, Privacy, Smart homes, Androids, connected home, Malware, Mobile communication, profiling, smart device security, smart home, Smart phones},
}

@online{owasp_foundation_owasp_2021,
	title = {{OWASP} Top 10:2021},
	url = {https://owasp.org/Top10/},
	author = {{OWASP} Foundation},
	urldate = {2022-04-30},
	date = {2021},
}

@book{sasse_usable_2005,
	title = {Usable Security: Why Do We Need It? How Do We Get It?},
	publisher = {O'Reilly},
	author = {Sasse, M Angela and Flechais, Ivan},
	date = {2005},
	langid = {english},
}

@inproceedings{boltz_handling_2022,
	location = {Gran Canaria, Spain},
	title = {Handling Environmental Uncertainty in Design Time Access Control Analysis},
	doi = {10.1109/SEAA56994.2022.00067},
	eventtitle = {2022 48th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	pages = {382--389},
	booktitle = {2022 48th Euromicro Conference on Software Engineering and Advanced Applications ({SEAA})},
	publisher = {{IEEE}},
	author = {Boltz, Nicolas and Hahner, Sebastian and Walter, Maximilian and Seifermann, Stephan and Heinrich, Robert and Bures, Tomas and Hnetynka, Petr},
	date = {2022},
}

@book{szopinski_because_2019,
	title = {Because your taxonomy is worth it: Towards a framework for taxonomy evaluation},
	shorttitle = {Because your taxonomy is worth it},
	abstract = {Taxonomies constitute one fundamental type of artefact in design science, describing and classifying existing or future objects of a domain. Taxonomies support researchers and practitioners with analysing and understanding a domain, which in turn is a prerequisite for theory building. Despite the increasing interest in taxonomies (and methodological guidance for building them), there is hardly any guidance for researchers on how to rigorously evaluate taxonomies. Based on a literature analysis, this study sheds light on the question of whether, when, and how researchers currently evaluate taxonomies. We critically synthesize and comprehensively review 306 articles that are concerned with taxonomies. Surprisingly , we find that taxonomies are rarely evaluated in {IS} research, nor is there any consistency in terms of methods used for evaluations. We describe the methods used by {IS} researchers to evaluate taxonomies after taxonomy building has been completed. Being the first to systematically analyse tax-onomy evaluation, we propose a preliminary version of a framework for taxonomy evaluation which enables researchers to choose among the wide range of taxonomy evaluation methods available. Our study advances an informed and purposeful evaluation of taxonomies and contributes to bridging the gap between abstract design science evaluation strategies and concrete taxonomy evaluation methods.},
	author = {Szopinski, Daniel and Schoormann, Thorsten and Kundisch, Dennis},
	date = {2019-06-13},
}

@inproceedings{garlan_unknown_2021,
	title = {The Unknown Unknowns Are Not Totally Unknown},
	doi = {10.1109/SEAMS51251.2021.00047},
	abstract = {The question of whether “handling unanticipated changes is the ultimate challenge for self-adaptation” is impossible to evaluate without looking closely at what “unanticipated” means. In this position paper I try to bring a little clarity to this issue by arguing that the common distinction between “known unknowns” and “unknown unknowns” is too crude: for most systems there are changes that are not directly handled by “first-order” adaptation, but can, with appropriate engineering, be addressed naturally through “second-order” adaptation. I explain what I mean by this and consider ways in which such systems might be engineered.},
	eventtitle = {2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems ({SEAMS})},
	pages = {264--265},
	booktitle = {2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems ({SEAMS})},
	author = {Garlan, David},
	date = {2021-05},
	note = {{ISSN}: 2157-2321},
	keywords = {uncertainty, Software engineering, Adaptive systems, adaptive systems, unknowns},
}

@collection{pelz_mastering_2021,
	title = {Mastering Uncertainty in Mechanical Engineering},
	url = {https://library.oapen.org/handle/20.500.12657/50950},
	abstract = {This open access book reports on innovative methods, technologies and strategies for mastering uncertainty in technical systems. Despite the fact that current research on uncertainty is mainly focusing on uncertainty quantification and analysis, this book gives emphasis to innovative ways to master uncertainty in engineering design, production and product usage alike. It gathers authoritative contributions by more than 30 scientists reporting on years of research in the areas of engineering, applied mathematics and law, thus offering a timely, comprehensive and multidisciplinary account of theories and methods for quantifying data, model and structural uncertainty, and of fundamental strategies for mastering uncertainty. It covers key concepts such as robustness, flexibility and resilience in detail. All the described methods, technologies and strategies have been validated with the help of three technical systems, i.e. the Modular Active Spring-Damper System, the Active Air Spring and the 3D Servo Press, which have been in turn developed and tested during more than ten years of cooperative research. Overall, this book offers a timely, practice-oriented reference guide to graduate students, researchers and professionals dealing with uncertainty in the broad field of mechanical engineering.},
	publisher = {Springer Nature},
	editor = {Pelz, Peter F. and Groche, Peter and Pfetsch, Marc E. and Schaeffner, Maximilian},
	urldate = {2022-07-13},
	date = {2021},
	doi = {10.1007/978-3-030-78354-9},
	note = {Accepted: 2021-10-13T13:52:56Z},
	keywords = {3D Servo Press, Active Air Spring, Active/Semi-Active Systems, Adaptive Technical Systems, agriculture::{TB} Technology: general issues::{TBD} Technical design, bic Book Industry Communication::K Economics, bic Book Industry Communication::T Technology, business \& management::{KJ} Business \& management::{KJT} Operational research, engineering, finance, Fluid Dynamic Vibration Absorber, Increasing Flexibility in Manufacturing, Model Uncertainty, Open Access Book, Optimal Design of Technical Systems, Product Design Under Uncertainty, Resilient Technical Systems, Robust Design, Robust Optimization Under Uncertainty, Sonderforschungsbereich ({SFB}) 805, Stochastic Data Uncertainty, Structural Uncertainty, Visualization of Uncertainty},
}

@incollection{bernardi_living_2021,
	location = {Cham},
	title = {Living with Uncertainty in Model-Based Development},
	isbn = {978-3-030-81915-6},
	url = {https://doi.org/10.1007/978-3-030-81915-6_8},
	abstract = {Uncertainty is present in model-based developments in many different ways. In the context of composing model-based analysis tools, this chapter discusses how the combination of different models can increase or decrease the overall uncertainty. It explores how such uncertainty could be more explicitly addressed and systematically managed, with the goal of defining a conceptual framework to deal with and manage it. We proceed towards this goal both with a theoretical reasoning and a practical application through an example of designing a peer-to-peer file-sharing protocol. We distinguish two main steps: (i) software system modelling and (ii) model-based performance analysis by highlighting the challenges related to the awareness that model-based development in software engineering needs to coexist with uncertainty. This core chapter addresses Challenge 5 introduced in Chap. 3of this book (living with uncertainty).},
	pages = {159--185},
	booktitle = {Composing Model-Based Analysis Tools},
	publisher = {Springer International Publishing},
	author = {Bernardi, Simona and Famelis, Michalis and Jézéquel, Jean-Marc and Mirandola, Raffaela and Palacin, Diego Perez and Polack, Fiona A. C. and Trubiani, Catia},
	editor = {Heinrich, Robert and Durán, Francisco and Talcott, Carolyn and Zschaler, Steffen},
	urldate = {2022-07-26},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-3-030-81915-6_8},
}

@article{baniassad_discovering_2006,
	title = {Discovering early aspects},
	volume = {23},
	issn = {1937-4194},
	doi = {10.1109/MS.2006.8},
	abstract = {Aspect-oriented software development has focused on the software life cycle's implementation phase: developers identify and capture aspects mainly in code. But aspects are evident earlier in the life cycle, such as during requirements engineering and architecture design. Early aspects are concerns that crosscut an artifact's dominant decomposition or base modules derived from the dominant separation-of-concerns criterion, in the early stages of the software life cycle. In this article, we describe how to identify and capture early aspects in requirements and architecture activities and how they're carried over from one phase to another. We'll focus on requirements and architecture design activities to illustrate the points, but the same ideas apply in other phases as well, such as domain analysis or in the fine-grained design activities that lie between architecture and implementation.},
	pages = {61--70},
	number = {1},
	journaltitle = {{IEEE} Software},
	author = {Baniassad, Elisa and Clements, P.C. and Araujo, J. and Moreira, A. and Rashid, A. and Tekinerdogan, B.},
	date = {2006-01},
	note = {Conference Name: {IEEE} Software},
	keywords = {Computer architecture, Software architecture, architecture, History, Runtime, Design engineering, requirements, design, Programming profession, Banking, aspect orientation, life cycle, Scattering},
}

@article{bumiller_context-driven_2022,
	title = {A Context-Driven Modelling Framework for Dynamic Authentication Decisions},
	abstract = {Nowadays, many mechanisms exist to perform authentication, such as text passwords and biometrics. However, reasoning about their relevance (e.g., the appropriateness for security and usability) regarding the contextual situation is challenging for authentication system designers. In this paper, we present a Context-driven Modelling Framework for dynamic Authentication decisions ({COFRA}), where the context information specifies the relevance of authentication mechanisms. {COFRA} is based on a precise metamodel that reveals framework abstractions and a set of constraints that specify their meaning. Therefore, it provides a language to determine the relevant authentication mechanisms (characterized by properties that ensure their appropriateness) in a given context. The framework supports the adaptive authentication system designers in the complex trade-off analysis between context information, risks and authentication mechanisms, according to usability, deployability, security, and privacy. We validate the proposed framework through case studies and extensive exchanges with authentication and modelling experts. We show that model instances describing real-world use cases and authentication approaches proposed in the literature can be instantiated validly according to our metamodel. This validation highlights the necessity, sufficiency, and soundness of our framework.},
	pages = {9},
	author = {Bumiller, Anne and Barais, Olivier and Challita, Stéphanie and Combemale, Benoit and Aillery, Nicolas and Lan, Gael Le},
	date = {2022},
	langid = {english},
}

@inproceedings{walter_architectural_2022,
	location = {Cham},
	title = {Architectural Optimization for Confidentiality Under Structural Uncertainty},
	isbn = {978-3-031-15116-3},
	doi = {10.1007/978-3-031-15116-3_14},
	series = {Lecture Notes in Computer Science},
	pages = {309--332},
	booktitle = {Software Architecture},
	publisher = {Springer International Publishing},
	author = {Walter, Maximilian and Hahner, Sebastian and Seifermann, Stephan and Bures, Tomas and Hnetynka, Petr and Pacovsky, Jan and Heinrich, Robert},
	date = {2022},
	langid = {english},
	keywords = {Uncertainty, Access control, Software architecture, Confidentiality, Information flow, Design space exploration},
}

@inproceedings{camara_addressing_2022,
	location = {Montreal Quebec Canada},
	title = {Addressing the uncertainty interaction problem in software-intensive systems: challenges and desiderata},
	isbn = {978-1-4503-9466-6},
	url = {https://dl.acm.org/doi/10.1145/3550355.3552438},
	doi = {10.1145/3550355.3552438},
	shorttitle = {Addressing the uncertainty interaction problem in software-intensive systems},
	abstract = {Software-intensive systems are increasingly used to support tasks that are typically characterized by high degrees of uncertainty. The modeling notations employed to design, verify, and operate such systems have increasingly started to capture different types of uncertainty, so that they can be explicitly considered when systems are developed and deployed. While these modeling paradigms consider different sources of uncertainty individually, these sources are rarely independent, and their interactions affect the achievement of system goals in subtle and often unpredictable ways. This vision paper describes the problem of uncertainty interaction in software-intensive systems, illustrating it on examples from relevant application domains. We then identify key open challenges and define desiderata that future modeling notations and model-driven engineering research should consider to address these challenges.},
	eventtitle = {{MODELS} '22: {ACM}/{IEEE} 25th International Conference on Model Driven Engineering Languages and Systems},
	pages = {24--30},
	booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems},
	publisher = {{ACM}},
	author = {Cámara, Javier and Calinescu, Radu and Cheng, Betty H. C. and Garlan, David and Schmerl, Bradley and Troya, Javier and Vallecillo, Antonio},
	urldate = {2022-11-07},
	date = {2022-10-23},
	langid = {english},
}

@thesis{seifermann_architectural_2022,
	title = {Architectural Data Flow Analysis for Detecting Violations of Confidentiality Requirements},
	url = {https://doi.org/10.5445/IR/1000148748},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Dissertation},
	author = {Seifermann, Stephan},
	urldate = {2022-11-15},
	date = {2022},
	langid = {german},
}

@inproceedings{acosta_uncertainty_2022,
	location = {New York, {NY}, {USA}},
	title = {Uncertainty in coupled models of cyber-physical systems},
	isbn = {978-1-4503-9467-3},
	url = {https://doi.org/10.1145/3550356.3561539},
	doi = {10.1145/3550356.3561539},
	series = {{MODELS} '22},
	eventtitle = {25th International Conference on Model Driven Engineering Languages and Systems ({MODELS})},
	pages = {569--578},
	booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
	publisher = {{ACM}},
	author = {Acosta, Maribel and Hahner, Sebastian and Koziolek, Anne and Kühn, Thomas and Mirandola, Raffaela and Reussner, Ralf},
	date = {2022},
}

@article{hezavehi_uncertainty_2021,
	title = {Uncertainty in Self-adaptive Systems: A Research Community Perspective},
	volume = {15},
	issn = {1556-4665},
	url = {https://doi.org/10.1145/3487921},
	doi = {10.1145/3487921},
	shorttitle = {Uncertainty in Self-adaptive Systems},
	abstract = {One of the primary drivers for self-adaptation is ensuring that systems achieve their goals regardless of the uncertainties they face during operation. Nevertheless, the concept of uncertainty in self-adaptive systems is still insufficiently understood. Several taxonomies of uncertainty have been proposed, and a substantial body of work exists on methods to tame uncertainty. Yet, these taxonomies and methods do not fully convey the research community’s perception on what constitutes uncertainty in self-adaptive systems and on the key characteristics of the approaches needed to tackle uncertainty. To understand this perception and learn from it, we conducted a survey comprising two complementary stages in which we collected the views of 54 and 51 participants, respectively. In the first stage, we focused on current research and development, exploring how the concept of uncertainty is understood in the community and how uncertainty is currently handled in the engineering of self-adaptive systems. In the second stage, we focused on directions for future research to identify potential approaches to dealing with unanticipated changes and other open challenges in handling uncertainty in self-adaptive systems. The key findings of the first stage are: (a) an overview of uncertainty sources considered in self-adaptive systems, (b) an overview of existing methods used to tackle uncertainty in concrete applications, (c) insights into the impact of uncertainty on non-functional requirements, (d) insights into different opinions in the perception of uncertainty within the community and the need for standardised uncertainty-handling processes to facilitate uncertainty management in self-adaptive systems. The key findings of the second stage are: (a) the insight that over 70\% of the participants believe that self-adaptive systems can be engineered to cope with unanticipated change, (b) a set of potential approaches for dealing with unanticipated change, (c) a set of open challenges in mitigating uncertainty in self-adaptive systems, in particular in those with safety-critical requirements. From these findings, we outline an initial reference process to manage uncertainty in self-adaptive systems. We anticipate that the insights on uncertainty obtained from the community and our proposed reference process will inspire valuable future research on self-adaptive systems.},
	pages = {10:1--10:36},
	number = {4},
	journaltitle = {{ACM} Transactions on Autonomous and Adaptive Systems},
	shortjournal = {{ACM} Trans. Auton. Adapt. Syst.},
	author = {Hezavehi, Sara M. and Weyns, Danny and Avgeriou, Paris and Calinescu, Radu and Mirandola, Raffaela and Perez-Palacin, Diego},
	urldate = {2022-11-28},
	date = {2021},
	keywords = {uncertainty, Self-adaptation, survey, unanticipated change, uncertainty challenges, uncertainty methods, uncertainty models},
}

@thesis{bitschi_uncertainty-aware_2022,
	title = {Uncertainty-aware Confidentiality Analysis Using Architectural Variations},
	url = {https://doi.org/10.5445/IR/1000153079},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Bachelor's Thesis},
	author = {Bitschi, Tizian},
	urldate = {2022-11-28},
	date = {2022},
}

@thesis{priss_mobility_2022,
	title = {A Mobility Case Study Framework for Validating Uncertainty Impact Analyses regarding Confidentiality},
	url = {https://doi.org/10.5445/IR/1000153083},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Bachelor's Thesis},
	author = {Priss, Denis},
	urldate = {2022-11-28},
	date = {2022},
}

@inproceedings{walter_architectural_2022-1,
	title = {Architectural Attack Propagation Analysis for Identifying Confidentiality Issues},
	isbn = {978-1-66541-728-0},
	doi = {10.1109/ICSA53651.2022.00009},
	eventtitle = {19th International Conference on Software Architecture},
	pages = {12 S.},
	booktitle = {2022 {IEEE} 19th International Conference on Software Architecture ({ICSA})},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	author = {Walter, Maximilian and Heinrich, Robert and Reussner, Ralf},
	date = {2022},
}

@online{mehl_palladio_2022,
	title = {Palladio Addon: Uncertainty-{VariationCreation}},
	url = {https://github.com/FluidTrust/Palladio-Addons-Uncertainty-VariationCreation},
	author = {Mehl, Patrick and Walter, Maximilian},
	urldate = {2022-11-28},
	date = {2022},
}

@inproceedings{konersmann_evaluation_2022,
	location = {Honolulu, {HI}, {USA}},
	title = {Evaluation Methods and Replicability of Software Architecture Research Objects},
	doi = {10.1109/ICSA53651.2022.00023},
	eventtitle = {2022 {IEEE} 19th International Conference on Software Architecture ({ICSA})},
	pages = {157--168},
	booktitle = {2022 {IEEE} 19th International Conference on Software Architecture ({ICSA})},
	publisher = {{IEEE}},
	author = {Konersmann, Marco and Kaplan, Angelika and Kühn, Thomas and Heinrich, Robert and Koziolek, Anne and Reussner, Ralf and Jürjens, Jan and al-Doori, Mahmood and Boltz, Nicolas and Ehl, Marco and Fuchs, Dominik and Groser, Katharina and Hahner, Sebastian and Keim, Jan and Lohr, Matthias and Sağlam, Timur and Schulz, Sophie and Töberg, Jan-Philipp},
	date = {2022},
	keywords = {Software architecture, Proposals, Standards, Conferences, Bibliographies, systematic literature review, Systematics, evaluation, meta-research, Replicability, software architecture research},
}

@misc{upstream_2022_2022,
	title = {2022 Global Automotive Cybersecurity Report},
	url = {https://upstream.auto/2022report/},
	author = {{UpStream}},
	urldate = {2022-12-06},
	date = {2022},
}

@inproceedings{kaplan_introducing_2022,
	location = {New York, {NY}, {USA}},
	title = {Introducing an Evaluation Method for Taxonomies},
	isbn = {978-1-4503-9613-4},
	url = {https://doi.org/10.1145/3530019.3535305},
	doi = {10.1145/3530019.3535305},
	series = {{EASE} '22},
	pages = {311--316},
	booktitle = {Proceedings of the International Conference on Evaluation and Assessment in Software Engineering 2022},
	publisher = {{ACM}},
	author = {Kaplan, Angelika and Kühn, Thomas and Hahner, Sebastian and Benkler, Niko and Keim, Jan and Fuchß, Dominik and Corallo, Sophie and Heinrich, Robert},
	date = {2022},
}

@inproceedings{bures_attuning_2022,
	location = {Cham},
	title = {Attuning Adaptation Rules via a Rule-Specific Neural Network},
	isbn = {978-3-031-19759-8},
	doi = {10.1007/978-3-031-19759-8_14},
	series = {Lecture Notes in Computer Science},
	eventtitle = {International Symposium on Leveraging Applications of Formal Methods},
	pages = {215--230},
	booktitle = {Leveraging Applications of Formal Methods, Verification and Validation. Adaptation and Learning},
	publisher = {Springer Nature Switzerland},
	author = {Bureš, Tomáš and Hnětynka, Petr and Kruliš, Martin and Plášil, František and Khalyeyev, Danylo and Hahner, Sebastian and Seifermann, Stephan and Walter, Maximilian and Heinrich, Robert},
	editor = {Margaria, Tiziana and Steffen, Bernhard},
	date = {2022},
	langid = {english},
}

@report{carnell_information_2016,
	title = {Information Management Platform for Data Analytics and Aggregation ({IMPALA}) System Design Document},
	url = {https://ntrs.nasa.gov/citations/20160011412},
	abstract = {The System Design document tracks the design activities that are performed to guide the integration, installation, verification, and acceptance testing of the {IMPALA} Platform. The inputs to the design document are derived from the activities recorded in Tasks 1 through 6 of the Statement of Work ({SOW}), with the proposed technical solution being the completion of Phase 1-A. With the documentation of the architecture of the {IMPALA} Platform and the installation steps taken, the {SDD} will be a living document, capturing the details about capability enhancements and system improvements to the {IMPALA} Platform to provide users in development of accurate and precise analytical models. The {IMPALA} Platform infrastructure team, data architecture team, system integration team, security management team, project manager, {NASA} data scientists and users are the intended audience of this document. The {IMPALA} Platform is an assembly of commercial-off-the-shelf ({COTS}) products installed on an Apache-Hadoop platform. User interface details for the {COTS} products will be sourced from the {COTS} tools vendor documentation. The {SDD} is a focused explanation of the inputs, design steps, and projected outcomes of every design activity for the {IMPALA} Platform through installation and validation.},
	author = {Carnell, Andrew and Akinyelu, Akinyele},
	urldate = {2022-12-23},
	date = {2016-08-01},
	note = {{NTRS} Author Affiliations: {NASA} Johnson Space Center, Lockheed Martin Corp.
{NTRS} Report/Patent Number: {JSC}-{CN}-37557
{NTRS} Document {ID}: 20160011412
{NTRS} Research Center: Johnson Space Center ({JSC})},
	keywords = {Documentation And Information Science},
}

@inproceedings{rostami_architecture-based_2017,
	title = {Architecture-Based Change Impact Analysis in Information Systems and Business Processes},
	doi = {10.1109/ICSA.2017.17},
	abstract = {Business processes as well as software systems face various changes during their lifetime. As they mutually influence each other, business processes and software systems have to be modified in co-evolution. Thus, to adequately predict the change impact, it is important to consider the complex mutual dependencies of both domains. However, existing approaches are limited to analyzing the change propagation in software systems or business processes in isolation. In this paper, we present a tool-supported approach to estimate the change propagation caused by a change request in business processes or software systems based on the software architecture and the process design. We focus on the mutual dependencies regarding the change propagation between both domains. In the evaluation, we apply our approach to a community case study to demonstrate the quality of results in terms of precision, recall, and coverage.},
	eventtitle = {2017 {IEEE} International Conference on Software Architecture ({ICSA})},
	pages = {179--188},
	booktitle = {2017 {IEEE} International Conference on Software Architecture ({ICSA})},
	author = {Rostami, Kiana and Heinrich, Robert and Busch, Axel and Reussner, Ralf},
	date = {2017-04},
	keywords = {Data models, Computer architecture, Software, Software architecture, Organizations, Phase change materials},
}

@inproceedings{rostami_architecture-based_2015,
	location = {Montréal {QC} Canada},
	title = {Architecture-based Assessment and Planning of Change Requests},
	isbn = {978-1-4503-3470-9},
	url = {https://dl.acm.org/doi/10.1145/2737182.2737198},
	doi = {10.1145/2737182.2737198},
	abstract = {Software architecture reﬂects important decisions on structure, used technology and resources. Architecture decisions inﬂuence to a large extent requirements on software quality. During software evolution change requests have to be implemented in a way that the software maintains its quality, as various potential implementations of a speciﬁc change request inﬂuence the quality properties diﬀerently. Software development processes involve various organisational and technical roles. Thus, for sound decision making it is important to understand the consequences of the decisions on the various software engineering artefacts (e.g. architecture, code, test cases, build, or deployments) when analysing the impact of a change request. However, existing approaches do not use suﬃcient architecture descriptions or are limited to software development without taking management tasks into account. In this paper, we present the tool-supported approach Karlsruhe Architectural Maintainability Prediction ({KAMP}) to analyse the change propagation caused by a change request in a software system based on the architecture model. Using context information annotated on the architecture {KAMP} enables project members to assess the eﬀects of a change request on various technical and organisational artefacts and tasks during software life cycle. We evaluate {KAMP} in an empirical study, which showed that it improves scalability of analysis for information systems due to automatically generated task lists containing more complete and precise context annotations than manually created ones.},
	eventtitle = {{CompArch} '15: Federated Events on Component-Based Software Engineering and Software Architecture},
	pages = {21--30},
	booktitle = {Proceedings of the 11th International {ACM} {SIGSOFT} Conference on Quality of Software Architectures},
	publisher = {{ACM}},
	author = {Rostami, Kiana and Stammel, Johannes and Heinrich, Robert and Reussner, Ralf},
	urldate = {2023-01-16},
	date = {2015-05-04},
	langid = {english},
}

@inproceedings{canfora_data_1992,
	title = {Data flow diagrams: reverse engineering production and animation},
	doi = {10.1109/ICSM.1992.242522},
	shorttitle = {Data flow diagrams},
	abstract = {The authors propose the use of interactive animation techniques as a support to reverse engineering processes oriented to the synthesis of semantic abstractions. Starting from data flow diagrams, a formal model, called dynamic data flow diagrams ({DDFDs}), has been defined, which can be used for the production of executable models of a software system. A strategy for the {DDFD} interactive animation is also put forward. Finally, the authors describe a prototype tool for (i) the production of the {DDFD} which models an {ADA} system starting from the analysis of the code and (ii) the interactive animation of such a model according to the proposed strategy.{\textless}{\textgreater}},
	eventtitle = {Proceedings Conference on Software Maintenance 1992},
	pages = {366--375},
	booktitle = {Proceedings Conference on Software Maintenance 1992},
	author = {Canfora, G. and Sansone, L. and Visaggio, G.},
	date = {1992-11},
	keywords = {Application software, Software systems, Prototypes, Software prototyping, Documentation, Reverse engineering, Software maintenance, Animation, Flow production systems, Software reusability},
}

@book{hole_anti-fragile_2016,
	location = {Cham},
	title = {Anti-fragile {ICT} Systems},
	isbn = {978-3-319-30068-9 978-3-319-30070-2},
	url = {http://link.springer.com/10.1007/978-3-319-30070-2},
	publisher = {Springer International Publishing},
	author = {Hole, Kjell Jørgen},
	urldate = {2023-01-27},
	date = {2016},
	langid = {english},
	doi = {10.1007/978-3-319-30070-2},
}

@inproceedings{bohner_software_2002,
	title = {Software change impacts-an evolving perspective},
	doi = {10.1109/ICSM.2002.1167777},
	abstract = {As software engineering practice evolves to respond to demands for distributed applications on heterogeneous platforms, software change is increasingly influenced by middleware and components. Interoperability dependency relationships now point to more relevant impacts of software change and necessarily drive the analysis. Software changes to software systems that incorporate middleware components like Web services expose these systems and the organizations they serve to unforeseen ripple effects that frequently result in failures. Current software change impact analysis models have not adequately addressed this trend. Moreover, as software systems grow in size and complexity, the dependency webs of information extend beyond most software engineers ability to comprehend them. This paper examines preliminary research for extending current software change impact analysis to incorporate interoperability dependency relationships for addressing distributed applications and explores three dimensional (3D) visualization techniques for more effective navigation of software changes.},
	eventtitle = {International Conference on Software Maintenance, 2002. Proceedings.},
	pages = {263--272},
	booktitle = {International Conference on Software Maintenance, 2002. Proceedings.},
	author = {Bohner, S.A.},
	date = {2002-10},
	keywords = {Software performance, Application software, Software systems, Web services, Information technology, Software engineering, {XML}, Middleware, Software maintenance, Navigation},
}

@online{sap_corona-warn-app_2023,
	title = {Corona-Warn-App},
	url = {https://github.com/corona-warn-app},
	abstract = {The official {COVID}-19 exposure notification app for Germany. - Corona-Warn-App},
	titleaddon = {{GitHub}},
	author = {{SAP} and Deutsche Telekom},
	urldate = {2023-01-29},
	date = {2023},
	langid = {english},
}

@inproceedings{oquendo_coping_2019,
	title = {Coping with Uncertainty in Systems-of-Systems Architecture Modeling on the {IoT} with {SosADL}},
	doi = {10.1109/SYSOSE.2019.8753842},
	abstract = {A challenging issue in the architectural design of a System-of-Systems ({SoS}) is how to cope with the uncertainty raised by the limited knowledge of the operational environment where the {SoS} will actually be deployed as well as the constituent systems which will concretely participate in the {SoS} at run-time. It is especially the case of {SoSs} being architected on the Internet-of-Things ({IoT}). Indeed, due to the open and dynamic nature of the {IoT}, on the one hand, at design-time, most often the {SoS} architects do not know which will be the concrete {IoT} systems that will become constituents of an {SoS}, these being predominantly identified at run-time; on the other hand, the correct architecture depends not only on the constituent {IoT} systems but also, largely, on the operational environment where the {SoS} will be positioned on the {IoT}. The consequent research question is thereby how to design and describe the {SoS} architecture in a way that is flexible enough to cope with these different uncertainties. To address this challenge, this paper investigates the notion of uncertainty in {SoS} and presents how {SosADL}, a formal {SoS} Architecture Description Language ({ADL}), enables to cope with uncertainty in the architecture modeling of {SoSs}. It presents the concepts and constructs that makes possible to describe {SoS} architectures which will operate in unpredictable environments on the {IoT} based on the {SosADL} support for dealing with partial knowledge, grounded on concurrent constraints.},
	eventtitle = {2019 14th Annual Conference System of Systems Engineering ({SoSE})},
	pages = {131--136},
	booktitle = {2019 14th Annual Conference System of Systems Engineering ({SoSE})},
	author = {Oquendo, Flavio},
	date = {2019-05},
	keywords = {Uncertainty, Architecture Description Language, Concurrent Constraints, {SosADL}, System-of-Systems},
}

@article{heinrich_architecture-based_2018,
	title = {Architecture-based change impact analysis in cross-disciplinary automated production systems},
	volume = {146},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121218301717},
	doi = {10.1016/j.jss.2018.08.058},
	pages = {167--185},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Heinrich, Robert and Koch, Sandro and Cha, Suhyun and Busch, Kiana and Reussner, Ralf and Vogel-Heuser, Birgit},
	urldate = {2023-03-21},
	date = {2018-12},
	langid = {english},
}

@inproceedings{grassi_towards_2023,
	title = {Towards a Conceptual Characterization of Antifragile Systems},
	booktitle = {2023 {IEEE} 20th International Conference on Software Architecture Companion ({ICSA}-C)},
	author = {Grassi, Vincenzo and Mirandola, Raffaela and Perez-Palacin, Diego},
	date = {2023},
	langid = {english},
}

@misc{khalil_will_2023,
	title = {Will {ChatGPT} get you caught? Rethinking of Plagiarism Detection},
	url = {http://arxiv.org/abs/2302.04335},
	doi = {10.48550/arXiv.2302.04335},
	shorttitle = {Will {ChatGPT} get you caught?},
	publisher = {{arXiv}},
	author = {Khalil, Mohammad and Er, Erkan},
	urldate = {2023-04-12},
	date = {2023-02-08},
	eprinttype = {arxiv},
	eprint = {2302.04335 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{gimpel_unlocking_2023,
	title = {Unlocking the power of generative {AI} models and systems such as {GPT}-4 and {ChatGPT} for higher education},
	url = {http://opus.uni-hohenheim.de/volltexte/2023/2146/},
	author = {Gimpel, Henner and Hall, Kristina and Decker, Stefan and Eymann, Torsten and Lämmermann, Luis and Mädche, Alexander and Röglinger, Maximilian and Ruiner, Caroline and Schoch, Manfred and Schoop, Mareike and Urbach, Nils and Vandrik, Steffen},
	urldate = {2023-04-12},
	date = {2023-03-29},
}

@online{openai_introducing_2023,
	title = {Introducing {ChatGPT}},
	url = {https://openai.com/blog/chatgpt},
	author = {{OpenAI}},
	urldate = {2023-04-12},
	date = {2023},
	langid = {american},
}

@online{openai_new_2023,
	title = {New {AI} classifier for indicating {AI}-written text},
	url = {https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text},
	author = {{OpenAI}},
	urldate = {2023-04-12},
	date = {2023},
	langid = {american},
}

@inproceedings{serban_towards_2020,
	location = {Cham},
	title = {Towards Using Probabilistic Models to Design Software Systems with Inherent Uncertainty},
	isbn = {978-3-030-58923-3},
	doi = {10.1007/978-3-030-58923-3_6},
	series = {Lecture Notes in Computer Science},
	abstract = {The adoption of machine learning ({ML}) components in software systems raises new engineering challenges. In particular, the inherent uncertainty regarding functional suitability and the operation environment makes architecture evaluation and trade-off analysis difficult. We propose a software architecture evaluation method called Modeling Uncertainty During Design ({MUDD}) that explicitly models the uncertainty associated to {ML} components and evaluates how it propagates through a system. The method supports reasoning over how architectural patterns can mitigate uncertainty and enables comparison of different architectures focused on the interplay between {ML} and classical software components. While our approach is domain-agnostic and suitable for any system where uncertainty plays a central role, we demonstrate our approach using as example a perception system for autonomous driving.},
	pages = {89--97},
	booktitle = {Software Architecture},
	publisher = {Springer International Publishing},
	author = {Serban, Alex and Poll, Erik and Visser, Joost},
	editor = {Jansen, Anton and Malavolta, Ivano and Muccini, Henry and Ozkaya, Ipek and Zimmermann, Olaf},
	date = {2020},
	langid = {english},
	keywords = {Uncertainty, Software architecture, Machine learning},
}

@article{tichy_workings_2022,
	title = {Workings of science: Debunked software theories},
	volume = {2022},
	issn = {1530-2180},
	url = {https://dl.acm.org/doi/10.1145/3512338},
	doi = {10.1145/3512338},
	shorttitle = {Workings of science},
	abstract = {Falsifiability is a cornerstone of science. It states that scientific claims---propositions, hypotheses, theories---must be testable by experiment. A scientific claim is falsified if an empirical test contradicts it; if a claim withstands repeated attempts at falsification, it is accepted as fact. This article discusses three examples of falsified theories about software. They address the reliability of multi-version programs, the prediction of program bugs by means of software metrics, and the advantages of software models ({UML}). These examples demonstrate how falsifiability can eliminate incorrect theories and help reorient research and practice.},
	pages = {1--11},
	issue = {June},
	journaltitle = {Ubiquity},
	shortjournal = {Ubiquity},
	author = {Tichy, Walter},
	urldate = {2023-04-19},
	date = {2022-06},
	langid = {english},
}

@inproceedings{binkley_source_2007,
	title = {Source Code Analysis: A Road Map},
	doi = {10.1109/FOSE.2007.27},
	shorttitle = {Source Code Analysis},
	abstract = {The automated and semi-automated analysis of source code has remained a topic of intense research for more than thirty years. During this period, algorithms and techniques for source-code analysis have changed, sometimes dramatically. The abilities of the tools that implement them have also expanded to meet new and diverse challenges. This paper surveys current work on source-code analysis. It also provides a road map for future work over the next five-year period and speculates on the development of source-code analysis applications, techniques, and challenges over the next 10, 20, and 50 years.},
	eventtitle = {Future of Software Engineering ({FOSE} '07)},
	pages = {104--119},
	booktitle = {Future of Software Engineering ({FOSE} '07)},
	author = {Binkley, David},
	date = {2007-05},
	keywords = {{NIST}, Computer science, Software engineering, Productivity, Humans, Educational institutions, Data mining, Programming profession, Assembly, Software safety},
}

@article{kramer_combining_1994,
	title = {The combining {DAG}: a technique for parallel data flow analysis},
	volume = {5},
	issn = {1558-2183},
	doi = {10.1109/71.298205},
	shorttitle = {The combining {DAG}},
	abstract = {As the number of available multiprocessors increases, so does the importance of providing software support for these systems, including parallel compilers. Data flow analysis, an important component of software tools, may be computed many times during the compilation of a program, especially when compiling for a multiprocessor. Although converting a sequential data flow algorithm to a parallel algorithm can present some opportunities for computing data flow in parallel, more parallelism can be exposed by the development of new parallel data flow algorithms. We present a technique that computes rapid data flow problems in parallel and thus is applicable for commonly used classical data flow problems, including reaching definitions, reachable uses, available expressions, and very busy expressions. Unlike previous techniques, our technique exploits the inherent parallelism in the data flow computation that occurs across independent paths, within linear paths, and in paths through loops of a control flow graph. The technique first changes cyclic structures in a control flow graph to acyclic structures and then builds a combining directed acyclic graph ({DAG}) that represents the paths through the control flow graph needed to compute data flow. Data flow is then computed using two passes over the {DAG} by computing the data flow for the nodes on each level of the {DAG} in parallel. We also present experimental results comparing the performance of our algorithm with a sequential algorithm and a parallelized sequential algorithm.{\textless}{\textgreater}},
	pages = {805--813},
	number = {8},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	author = {Kramer, R. and Gupta, R. and Soffa, M.L.},
	date = {1994-08},
	note = {Conference Name: {IEEE} Transactions on Parallel and Distributed Systems},
	keywords = {Availability, Iterative methods, Concurrent computing, Data analysis, Data flow computing, Flow graphs, Iterative algorithms, Parallel algorithms, Parallel processing, Software tools},
}

@article{schneider_automatic_2023,
	title = {Automatic extraction of security-rich dataflow diagrams for microservice applications written in Java},
	volume = {202},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121223001176},
	doi = {10.1016/j.jss.2023.111722},
	abstract = {Dataflow diagrams ({DFDs}) are a valuable asset for securing applications, as they are the starting point for many security assessment techniques. Their creation, however, is often done manually, which is time-consuming and introduces problems concerning their correctness. Furthermore, as applications are continuously extended and modified in {CI}/{CD} pipelines, the {DFDs} need to be kept in sync, which is also challenging. In this paper, we present a novel, tool-supported technique to automatically extract {DFDs} from the implementation code of microservices. The technique parses source code and configuration files in search for keywords that are used as evidence for the model extraction. Our approach uses a novel technique that iteratively detects new keywords, thereby snowballing through an application’s codebase. Coupled with other detection techniques, it produces a fully-fledged {DFD} enriched with security-relevant annotations. The extracted {DFDs} further provide full traceability between model items and code snippets. We evaluate our approach and the accompanying prototype for applications written in Java on a manually curated dataset of 17 open-source applications. In our testing set of applications, we observe an overall precision of 93\% and recall of 85\%. The dataset created for the evaluation is openly released to the research community, as additional contribution of this work. © 2023 Elsevier Inc. All rights reserved.},
	pages = {111722},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Schneider, Simon and Scandariato, Riccardo},
	urldate = {2023-05-22},
	date = {2023-08},
	langid = {english},
}

@inproceedings{bambhore_tukaram_towards_2022,
	location = {Vienna Austria},
	title = {Towards a Security Benchmark for the Architectural Design of Microservice Applications},
	isbn = {978-1-4503-9670-7},
	url = {https://dl.acm.org/doi/10.1145/3538969.3543807},
	doi = {10.1145/3538969.3543807},
	abstract = {The microservice architecture presents many challenges from a security perspective, due to the large amount of services, leading to an increased attack surface and an unmanageble cognitive load for security analysts. Several benchmarks exist to guide the secure configuration of the deployment infrastructure for microservice applications, including containers (e.g., Docker), orchestration systems (e.g., Kubernetes), cloud platforms (e.g., {AWS}), and even operating systems (e.g., Linux). In this paper we approach the creation of a benchmark for the design of the microservice applications themselves. To this aim, we inventorize a number of relevant security rules for the architectural design of microservice applications and assess (in a preliminary way) how these rules could be checked automatically.},
	eventtitle = {{ARES} 2022: The 17th International Conference on Availability, Reliability and Security},
	pages = {1--7},
	booktitle = {Proceedings of the 17th International Conference on Availability, Reliability and Security},
	publisher = {{ACM}},
	author = {Bambhore Tukaram, Anusha and Schneider, Simon and Díaz Ferreyra, Nicolás E. and Simhandl, Georg and Zdun, Uwe and Scandariato, Riccardo},
	urldate = {2023-05-25},
	date = {2022-08-23},
	langid = {english},
}

@article{pittou_modelling_2023,
	title = {Modelling Uncertainty in Architectures of Parametric Component-Based Systems},
	issn = {0129-0541},
	url = {https://www.worldscientific.com/doi/abs/10.1142/S0129054123450028},
	doi = {10.1142/S0129054123450028},
	abstract = {In this paper, we propose a logic-based characterization of uncertainty in architectures of parametric component-based systems, where the parameter is the number of instances of each component type. For this, we firstly introduce an extended propositional interaction logic over De Morgan algebras and we show that its formulas can encode the uncertainty of several architectures applied in systems with a finite number of components. In turn, we introduce a first-order extended interaction logic over De Morgan algebras which is applied for modelling uncertainty in the interactions of well-known parametric architectures. Moreover, we prove that the equivalence problem for a large class of formulas of that logic is decidable in doubly exponential time by providing an effective translation to fuzzy recognizable series. For any such formula over a totally ordered De Morgan algebra, we further prove that we can compute in exponential time the set of sequences of parametric fuzzy interactions which ensure the trustworthiness of the formula according to a particular threshold.},
	pages = {1--43},
	journaltitle = {International Journal of Foundations of Computer Science},
	shortjournal = {Int. J. Found. Comput. Sci.},
	author = {Pittou, Maria and Rahonis, George},
	urldate = {2023-05-30},
	date = {2023-05-22},
	note = {Publisher: World Scientific Publishing Co.},
	keywords = {Architecture modelling, fuzzy extended interaction logics, parametric component-based systems, uncertainty of architectures},
}

@article{lorentz_deterministic_1983,
	title = {Deterministic and nondeterministic flowchart interpretations},
	volume = {27},
	issn = {0022-0000},
	url = {https://www.sciencedirect.com/science/article/pii/0022000083900508},
	doi = {10.1016/0022-0000(83)90050-8},
	abstract = {Programming languages are studied in the abstract. Algebraic theories supply the syntax for programming languages. Semantics is provided by coproduct preserving functors from the algebraic theory to some semantic category with finite coproducts. Deterministic programming languages are provided when the semantic domain is the category of pointed sets and point preserving functions. Nondeterministic programming languages occur when the semantic domain is the category of Abelian monoids. The class of all nondeterministic programming languages with a fixed syntax is shown to be a variety of algebras. All classes of deterministic programming languages that allow branching are shown to be nonvarietal. Other properties of classes of programming languages are studied using category theory.},
	pages = {400--433},
	number = {3},
	journaltitle = {Journal of Computer and System Sciences},
	shortjournal = {Journal of Computer and System Sciences},
	author = {Lorentz, Richard J. and Benson, David B.},
	urldate = {2023-05-30},
	date = {1983-12-01},
	langid = {english},
}

@inproceedings{hahner_architecture-based_2023,
	location = {Melbourne, Australia},
	title = {Architecture-Based Uncertainty Impact Analysis to Ensure Confidentiality},
	doi = {10.1109/SEAMS59076.2023.00026},
	eventtitle = {2023 {IEEE}/{ACM} 18th Symposium on Software Engineering for Adaptive and Self-Managing Systems ({SEAMS})},
	pages = {126--132},
	booktitle = {2023 {IEEE}/{ACM} 18th Symposium on Software Engineering for Adaptive and Self-Managing Systems ({SEAMS})},
	publisher = {{IEEE}/{ACM}},
	author = {Hahner, Sebastian and Heinrich, Robert and Reussner, Ralf},
	date = {2023},
	keywords = {Predictive models, Uncertainty, Software systems, Analytical models, Privacy, Confidentiality, Manuals, Runtime, Software Architecture, Software algorithms, Data Flow Analysis, Uncertainty Management},
}

@inproceedings{hahner_model-based_2023,
	title = {Model-based Confidentiality Analysis under Uncertainty},
	doi = {10.1109/ICSA-C57050.2023.00062},
	eventtitle = {2023 {IEEE} 20th International Conference on Software Architecture Companion ({ICSA}-C)},
	pages = {256--263},
	booktitle = {2023 {IEEE} 20th International Conference on Software Architecture Companion ({ICSA}-C)},
	publisher = {{IEEE}},
	author = {Hahner, Sebastian and Bitschi, Tizian and Walter, Maximilian and Bureš, Tomáš and Hnětynka, Petr and Heinrich, Robert},
	date = {2023},
	keywords = {Data models, Uncertainty, Access Control, Software architecture, Software systems, Analytical models, Confidentiality, Complexity theory, Software Architecture, Data Flow Analysis, Information filters, Model-driven Security},
}

@inproceedings{hahner_classification_2023,
	location = {Cham},
	title = {A Classification of Software-Architectural Uncertainty Regarding Confidentiality},
	isbn = {978-3-031-36840-0},
	doi = {10.1007/978-3-031-36840-0_8},
	series = {Communications in Computer and Information Science},
	pages = {139--160},
	booktitle = {E-Business and Telecommunications},
	publisher = {Springer Nature Switzerland},
	author = {Hahner, Sebastian and Seifermann, Stephan and Heinrich, Robert and Reussner, Ralf},
	date = {2023},
	langid = {english},
	keywords = {Uncertainty, Software architecture, Confidentiality},
}

@article{omg_precise_2023,
	title = {Precise Semantics for Uncertainty Modeling ({PSUM})},
	volume = {1},
	author = {{OMG}},
	date = {2023},
	langid = {english},
}

@inproceedings{schneider_microsecend_2023,
	title = {{microSecEnD}: A Dataset of Security-Enriched Dataflow Diagrams for Microservice Applications},
	doi = {10.1109/MSR59073.2023.00030},
	shorttitle = {{microSecEnD}},
	abstract = {Dataflow diagrams ({DFDs}) are useful resources in securing applications since they show a software system’s architecture and allow assessing architectural security and weaknesses. Enriching them with annotations about implemented security features further strengthens this ability. This is especially true for microservice applications, as their most pressing security concerns stem from their separation into multiple services. Researchers need data to work on these issues and enhance microservices’ architectural security. In this work, we present {microSecEnD}, a dataset of 17 manually created {DFDs} that are extensively annotated with information on implemented security features. We provide traceability for all model items. Further, a mapping to a list of 17 architectural security best-practices is provided. Finally, for each best-practice that an application violates, we present a model variant that does adhere to it.},
	eventtitle = {2023 {IEEE}/{ACM} 20th International Conference on Mining Software Repositories ({MSR})},
	pages = {125--129},
	booktitle = {2023 {IEEE}/{ACM} 20th International Conference on Mining Software Repositories ({MSR})},
	author = {Schneider, Simon and Özen, Tufan and Chen, Michael and Scandariato, Riccardo},
	date = {2023-05},
	langid = {english},
	keywords = {security, Security, Computer architecture, Software, Data mining, microservices, Annotations, dataflow diagrams, dataset, Microservice architectures, Pressing},
}

@misc{schwickerath_tool-supported_2023,
	title = {Tool-Supported Architecture-Based Data Flow Analysis for Confidentiality},
	url = {http://arxiv.org/abs/2308.01645},
	doi = {10.48550/arXiv.2308.01645},
	number = {{arXiv}:2308.01645},
	publisher = {{arXiv}},
	author = {Schwickerath, Felix and Boltz, Nicolas and Hahner, Sebastian and Walter, Maximilian and Gerking, Christopher and Heinrich, Robert},
	date = {2023},
	eprinttype = {arxiv},
	eprint = {2308.01645 [cs]},
	keywords = {Computer Science - Software Engineering, Computer Science - Cryptography and Security},
}

@article{walter_architecture-based_2023,
	title = {Architecture-based attack propagation and variation analysis for identifying confidentiality issues in Industry 4.0},
	volume = {71},
	issn = {2196-677X},
	doi = {10.1515/auto-2022-0135},
	pages = {443--452},
	number = {6},
	journaltitle = {at - Automatisierungstechnik},
	author = {Walter, Maximilian and Hahner, Sebastian and Bures, Tomas and Hnetynka, Petr and Heinrich, Robert and Reussner, Ralf},
	date = {2023},
	langid = {english},
	keywords = {software architecture, confidentiality, attack propagation},
}

@article{durugbo_data_2010,
	title = {Data uncertainty assessment and information flow analysis for product-service systems in a library case study},
	volume = {5},
	doi = {10.1504/IJSOI.2010.037002},
	abstract = {The provision of service is increasingly becoming a key driver for delivering customer value. This emphasis on service provision is promoted by approaches such as Product-Service Systems ({PSSs}) that deliver value in use based on integrated products and services. However, to achieve effective delivery of services, it is important to manage information flow and data uncertainty associated with information requirement. The paper proposes a methodology that consists of: (a) the assessment of data uncertainty through the numeral, unit, spread, assessment and pedigree approach and a pedigree matrix consisting of data uncertainties to be scored based on their influence on the system; and (b) the analysis of information flow by means of data flow diagrams that depict information exchanges and an info-dynamic engine that measures the efficiency and recommends improvements for information flows in {PSSs}. A library case study was undertaken to show how such a methodology can be applied. Copyright © 2010 Inderscience Enterprises Ltd.},
	pages = {330--350},
	journaltitle = {International Journal of Services Operations and Informatics},
	shortjournal = {International Journal of Services Operations and Informatics},
	author = {Durugbo, C.M and Erkoyuncu, John and Tiwari, Ashutosh and Alcock, Jeffrey and Roy, Rajkumar and Shehab, Essam},
	date = {2010-11-01},
}

@inproceedings{erkoyuncu_uncertainty_2009,
	title = {Uncertainty challenges in service cost estimation for product- service systems in the aerospace and defence industries},
	rights = {Copyright: Cranfield University 2009},
	isbn = {978-0-9557436-5-8},
	url = {https://dspace.lib.cranfield.ac.uk/handle/1826/3830},
	abstract = {Contracting for availability is expected to become more prevalent for product -service systems ({PSS}) in the 
aerospace and defence industries. These contracts tend to transfer responsibilities for the operational phase 
from the customer to the supplier. In parallel, with operational life spans spanning several decades, the 
ability to deal with uncertainty in cost estimation for support activities is becoming critical. This paper outlines 
challenges within this process derived from literature as well as issues that were highlighted during 
interviews with four major defence and aerospace organisations.},
	publisher = {Cranfield University Press},
	author = {Erkoyuncu, John Ahmet and Roy, Rajkumar and Shehab, Essam and Wardle, P.},
	urldate = {2023-09-11},
	date = {2009-04-01},
	langid = {english},
	note = {Accepted: 2009-10-19T10:11:59Z},
}

@inproceedings{moor_keynote_2007,
	title = {Keynote Address: .{QL} for Source Code Analysis},
	doi = {10.1109/SCAM.2007.31},
	shorttitle = {Keynote Address},
	abstract = {Many tasks in source code analysis can be viewed as evaluating queries over a relational representation of the code. Here we present an object-oriented query language, named .{QL}, and demonstrate its use for general navigation, bug finding and enforcing coding conventions. We then focus on the particular problem of specifying metrics as queries.},
	eventtitle = {Seventh {IEEE} International Working Conference on Source Code Analysis and Manipulation ({SCAM} 2007)},
	pages = {3--16},
	booktitle = {Seventh {IEEE} International Working Conference on Source Code Analysis and Manipulation ({SCAM} 2007)},
	author = {Moor, Oege de and Verbaere, Mathieu and Hajiyev, Elnar and Avgustinov, Pavel and Ekman, Torbjorn and Ongkingco, Neil and Sereni, Damien and Tibble, Julian},
	date = {2007-09},
}

@incollection{de_moor_ql_2008,
	location = {Berlin, Heidelberg},
	title = {.{QL}: Object-Oriented Queries Made Easy},
	isbn = {978-3-540-88643-3},
	url = {https://doi.org/10.1007/978-3-540-88643-3_3},
	series = {Lecture Notes in Computer Science},
	shorttitle = {.{QL}},
	abstract = {These notes are an introduction to .{QL}, an object-oriented query language for any type of structured data. We illustrate the use of .{QL} in assessing software quality, namely to find bugs, to compute metrics and to enforce coding conventions. The class mechanism of .{QL} is discussed in depth, and we demonstrate how it can be used to build libraries of reusable queries.},
	pages = {78--133},
	booktitle = {Generative and Transformational Techniques in Software Engineering {II}: International Summer School, {GTTSE} 2007, Braga, Portugal, July 2-7, 2007. Revised Papers},
	publisher = {Springer},
	author = {de Moor, Oege and Sereni, Damien and Verbaere, Mathieu and Hajiyev, Elnar and Avgustinov, Pavel and Ekman, Torbjoern and Ongkingco, Neil and Tibble, Julian},
	editor = {Lämmel, Ralf and Visser, Joost and Saraiva, Joao},
	urldate = {2023-09-11},
	date = {2008},
	langid = {english},
	doi = {10.1007/978-3-540-88643-3_3},
	keywords = {Column Type, Datalog Program, Disjunctive Normal Form, Query Language, Reference Type},
}

@article{calinescu_efficient_2018,
	title = {Efficient synthesis of robust models for stochastic systems},
	volume = {143},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121218300967},
	doi = {10.1016/j.jss.2018.05.013},
	abstract = {We describe a tool-supported method for the efficient synthesis of parametric continuous-time Markov chains ({pCTMC}) that correspond to robust designs of a system under development. The {pCTMCs} generated by our {RObust} {DEsign} Synthesis ({RODES}) method are resilient to changes in the system’s operational profile, satisfy strict reliability, performance and other quality constraints, and are Pareto-optimal or nearly Pareto-optimal with respect to a set of quality optimisation criteria. By integrating sensitivity analysis at designer-specified tolerance levels and Pareto optimality, {RODES} produces designs that are potentially slightly suboptimal in return for less sensitivity—an acceptable trade-off in engineering practice. We demonstrate the effectiveness of our method and the efficiency of its {GPU}-accelerated tool support across multiple application domains by using {RODES} to design a producer-consumer system, a replicated file system and a workstation cluster system.},
	pages = {140--158},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Calinescu, Radu and Češka, Milan and Gerasimou, Simos and Kwiatkowska, Marta and Paoletti, Nicola},
	urldate = {2023-09-25},
	date = {2018-09-01},
	keywords = {Multi-objective optimisation, Probabilistic model synthesis, Robust design, Software performance and reliability engineering},
}

@article{gerasimou_synthesis_2018,
	title = {Synthesis of probabilistic models for quality-of-service software engineering},
	volume = {25},
	issn = {1573-7535},
	url = {https://doi.org/10.1007/s10515-018-0235-8},
	doi = {10.1007/s10515-018-0235-8},
	abstract = {An increasingly used method for the engineering of software systems with strict quality-of-service ({QoS}) requirements involves the synthesis and verification of probabilistic models for many alternative architectures and instantiations of system parameters. Using manual trial-and-error or simple heuristics for this task often produces suboptimal models, while the exhaustive synthesis of all possible models is typically intractable. The {EvoChecker} search-based software engineering approach presented in our paper addresses these limitations by employing evolutionary algorithms to automate the model synthesis process and to significantly improve its outcome. {EvoChecker} can be used to synthesise the Pareto-optimal set of probabilistic models associated with the {QoS} requirements of a system under design, and to support the selection of a suitable system architecture and configuration. {EvoChecker} can also be used at runtime, to drive the efficient reconfiguration of a self-adaptive software system. We evaluate {EvoChecker} on several variants of three systems from different application domains, and show its effectiveness and applicability.},
	pages = {785--831},
	number = {4},
	journaltitle = {Automated Software Engineering},
	shortjournal = {Autom Softw Eng},
	author = {Gerasimou, Simos and Calinescu, Radu and Tamburrelli, Giordano},
	urldate = {2023-09-25},
	date = {2018-12-01},
	langid = {english},
	keywords = {Probabilistic model checking, Evolutionary algorithms, {QoS} requirements, Search-based software engineering},
}

@article{sinnema_classifying_2007,
	title = {Classifying variability modeling techniques},
	volume = {49},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584906001042},
	doi = {10.1016/j.infsof.2006.08.001},
	abstract = {Variability modeling is important for managing variability in software product families, especially during product derivation. In the past few years, several variability modeling techniques have been developed, each using its own concepts to model the variability provided by a product family. The publications regarding these techniques were written from different viewpoints, use different examples, and rely on a different technical background. This paper sheds light on the similarities and differences between six variability modeling techniques, by exemplifying the techniques with one running example, and classifying them using a framework of key characteristics for variability modeling. It furthermore discusses the relation between differences among those techniques, and the scope, size, and application domain of product families.},
	pages = {717--739},
	number = {7},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Sinnema, Marco and Deelstra, Sybren},
	urldate = {2023-09-25},
	date = {2007-07-01},
	keywords = {Classification, Software product family, Variability management, Variability modeling},
}

@article{vanherpen_design-space_2014,
	title = {Design-Space Exploration in Model Driven Engineering},
	abstract = {A designer often has to evaluate alternative designs during the development of a system. A multitude of Design-Space Exploration ({DSE}) techniques exist in the literature. Integration of these techniques into the modelling paradigm is needed when a model-driven engineering approach is used for designing systems. To a greater or lesser extent, the integration of those diﬀerent {DSE} techniques share characteristics with each other. Inspired by software design patterns, we introduce an initial pattern catalogue to categorise the embedding of diﬀerent {DSE} techniques in an {MDE} context. We demonstrate their use by a literature survey and discuss the consequences of each pattern. Finally, we demonstrate the application of our initial pattern catalogue on two examples.},
	journaltitle = {Proceedings of the First International Workshop on Combining Modelling with Search- and Example-Based Approaches ({CMSEBA} 2014)},
	author = {Vanherpen, Ken and Denil, Joachim and Meulenaere, Paul De and Vangheluwe, Hans},
	date = {2014},
	langid = {english},
}

@inproceedings{burgueno_expressing_2018,
	location = {New York, {NY}, {USA}},
	title = {Expressing Confidence in Models and in Model Transformation Elements},
	isbn = {978-1-4503-4949-9},
	url = {https://dl.acm.org/doi/10.1145/3239372.3239394},
	doi = {10.1145/3239372.3239394},
	series = {{MODELS} '18},
	abstract = {The expression and management of uncertainty, both in the information and in the operations that manipulate it, is a critical issue in those systems that work with physical environments. Measurement uncertainty can be due to several factors, such as unreliable data sources, tolerance in the measurements, or the inability to determine if a certain event has actually happened or not. In particular, this contribution focuses on the expression of one kind of uncertainty, namely the confidence on the model elements, i.e., the degree of belief that we have on their occurrence, and on how such an uncertainty can be managed and propagated through model transformations, whose rules can also be subject to uncertainty.},
	pages = {57--66},
	booktitle = {Proceedings of the 21th {ACM}/{IEEE} International Conference on Model Driven Engineering Languages and Systems},
	publisher = {Association for Computing Machinery},
	author = {Burgueño, Loli and Bertoa, Manuel F. and Moreno, Nathalie and Vallecillo, Antonio},
	urldate = {2023-09-27},
	date = {2018},
	keywords = {models, Uncertainty, model transformations, confidence},
}

@inproceedings{zhang_understanding_2016,
	location = {Cham},
	title = {Understanding Uncertainty in Cyber-Physical Systems: A Conceptual Model},
	isbn = {978-3-319-42061-5},
	doi = {10.1007/978-3-319-42061-5_16},
	series = {Lecture Notes in Computer Science},
	shorttitle = {Understanding Uncertainty in Cyber-Physical Systems},
	abstract = {Uncertainty is intrinsic in most technical systems, including Cyber-Physical Systems ({CPS}). Therefore, handling uncertainty in a graceful manner during the real operation of {CPS} is critical. Since designing, developing, and testing modern and highly sophisticated {CPS} is an expanding field, a step towards dealing with uncertainty is to identify, define, and classify uncertainties at various levels of {CPS}. This will help develop a systematic and comprehensive understanding of uncertainty. To that end, we propose a conceptual model for uncertainty specifically designed for {CPS}. Since the study of uncertainty in {CPS} development and testing is still irrelatively unexplored, this conceptual model was derived in a large part by reviewing existing work on uncertainty in other fields, including philosophy, physics, statistics, and healthcare. The conceptual model is mapped to the three logical levels of {CPS}: Application, Infrastructure, and Integration. It is captured using {UML} class diagrams, including relevant {OCL} constraints. To validate the conceptual model, we identified, classified, and specified uncertainties in two distinct industrial case studies.},
	pages = {247--264},
	booktitle = {Modelling Foundations and Applications},
	publisher = {Springer International Publishing},
	author = {Zhang, Man and Selic, Bran and Ali, Shaukat and Yue, Tao and Okariz, Oscar and Norgren, Roland},
	editor = {Wąsowski, Andrzej and Lönn, Henrik},
	date = {2016},
	langid = {english},
	keywords = {Uncertainty, Conceptual model, Cyber-Physical systems},
}

@article{tse_towards_1989,
	title = {Towards a Formal Foundation for {DeMarco} Data Flow Diagrams*},
	volume = {32},
	issn = {0010-4620},
	url = {https://doi.org/10.1093/comjnl/32.1.1},
	doi = {10.1093/comjnl/32.1.1},
	abstract = {In this paper, we describe a proposal for formalising data flow diagrams through extended Petri nets. We illustrate the usefulness of the approach by describing how it can be used to analyse the consistency of requirements specifications.},
	pages = {1--12},
	number = {1},
	journaltitle = {The Computer Journal},
	shortjournal = {The Computer Journal},
	author = {Tse, T. H. and Pong, L.},
	urldate = {2023-09-28},
	date = {1989-01-01},
}

@article{larsen_formal_1994,
	title = {A Formal Semantics of Data Flow Diagrams},
	volume = {6},
	issn = {1433-299X},
	url = {https://doi.org/10.1007/BF03259387},
	doi = {10.1007/BF03259387},
	abstract = {This paper presents a formal semantics of data flow diagrams as used in Structured Analysis, based on an abstract model for data flow transformations. The semantics consists of a collection of {VDM} functions, transforming an abstract syntax representation of a data flow diagram into an abstract syntax representation of a {VDM} specification. Since this transformation is executable, it becomes possible to provide a software analyst/designer with two ‘views’ of the system being modelled: a graphical view in terms of a data flow diagram, and a textual view in terms of a {VDM} specification. In this paper emphasis is on the motivation for the choices made in the transformation. The main aspects of the transformation itself are described using annotated {VDM} functions with some examples.},
	pages = {586--606},
	number = {6},
	journaltitle = {Formal Aspects of Computing},
	shortjournal = {Form Asp Comp},
	author = {Larsen, Peter Gorm and Plat, Nico and Toetenel, Hans},
	urldate = {2023-09-28},
	date = {1994-12-01},
	langid = {english},
	keywords = {Data flow diagrams, Formal semantics, {VDM}},
}

@article{tao_formal_1991,
	title = {Formal definition and verification of data flow diagrams},
	volume = {16},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/0164121291900296},
	doi = {10.1016/0164-1212(91)90029-6},
	abstract = {Data flow diagrams ({DFD}) are widely used to specify large complex software systems. A {DFD} is visual and informal, hence, easy to learn and use. However, its informality makes it difficult to conduct formal verification of the consistency and completeness of a {DFD} specification. The objective of this article is to provide a formal basis for the {DFD}. A {DFD} is defined as a diagraph together with a binary relation, called the precedence relation. The nodes of the digraph represent the processes, data stores, and external entities, and the directed edges represent the data flows. The precedence relation for a {DFD} is an abstraction of the functional semantics and specifies the “is-used-to-produce” relationships among the data flows. Based on this definition, the notion of consistency in process decomposition is defined. The child {DFD} that results from decomposition is consistent with the parent process if the child {DFD} preserves the precedence relation for the parent process and does not introduce additional precedence relationships between the input and output flows of the parent process. This consistency criterion is shown to be stronger than those found in the literature. Moreover, a number of completeness criteria are discussed and formalized. The results of this paper can be easily incorporated into some existing {CASE} tools.},
	pages = {29--36},
	number = {1},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Tao, Yonglei and Kung, Chenho},
	urldate = {2023-09-28},
	date = {1991-09-01},
}

@book{weyns_introduction_2020,
	location = {Hoboken},
	title = {An introduction to self-adaptive systems: A contemporary software engineering perspective},
	isbn = {978-1-119-57494-1},
	url = {https://doi.org/10.1002/9781119574910},
	publisher = {John Wiley \& Sons},
	author = {Weyns, Danny},
	date = {2020},
}

@inproceedings{bersani_conceptual_2023,
	location = {Hannover, Germany},
	title = {A Conceptual Framework for Explainability Requirements in Software-Intensive Systems},
	url = {https://ieeexplore.ieee.org/document/10260808/},
	doi = {10.1109/REW57809.2023.00059},
	abstract = {Software-intensive systems include enterprise systems, {IoT} systems, cyber-physical systems, and industrial control systems where software plays a vital role. In such systems, the software is increasingly responsible for autonomous decisionmaking. However, trust can be hindered by the black-box nature of these systems, whose autonomous decisions may be confusing or even dangerous for humans. Thus, explainability emerges as a crucial non-functional property to achieve transparency and increase the understanding of the systems’ behavior, fostering their acceptance in our society.},
	eventtitle = {2023 {IEEE} 31st International Requirements Engineering Conference Workshops ({REW})},
	pages = {309--315},
	booktitle = {2023 {IEEE} 31st International Requirements Engineering Conference Workshops ({REW})},
	publisher = {{IEEE}},
	author = {Bersani, Marcello M. and Camilli, Matteo and Lestingi, Livia and Mirandola, Raffaela and Rossi, Matteo and Scandurra, Patrizia},
	urldate = {2023-10-19},
	date = {2023-09},
	langid = {english},
}

@incollection{bersani_architecting_2023,
	location = {Cham},
	title = {Architecting Explainable Service Robots},
	volume = {14212},
	url = {https://link.springer.com/10.1007/978-3-031-42592-9_11},
	abstract = {Service robots entailing a tight collaboration with humans are increasingly widespread in critical domains, such as healthcare and domestic assistance. However, the so-called Human-Machine-Teaming paradigm can be hindered by the black-box nature of service robots, whose autonomous decisions may be confusing or even dangerous for humans. Thus, the explainability for these systems emerges as a crucial property for their acceptance in our society. This paper introduces the concept of explainable service robots and proposes a software architecture to support the engineering of the self-explainability requirements in these collaborating systems by combining formal analysis and interpretable machine learning. We evaluate the proposed architecture using an illustrative example in healthcare. Results show that our proposal supports the explainability of multi-agent Human-Machine-Teaming missions featuring an inﬁnite (dense) space of human-machine uncertain factors, such as diverse physical and physiological characteristics of the agents involved in the teamwork.},
	pages = {153--169},
	booktitle = {Software Architecture},
	publisher = {Springer Nature Switzerland},
	author = {Bersani, Marcello M. and Camilli, Matteo and Lestingi, Livia and Mirandola, Raffaela and Rossi, Matteo and Scandurra, Patrizia},
	urldate = {2023-10-19},
	date = {2023},
	langid = {english},
}

@article{weyns_towards_2023,
	title = {Towards a Research Agenda for Understanding and Managing Uncertainty in Self-Adaptive Systems},
	volume = {48},
	issn = {0163-5948},
	doi = {10.1145/3617946.3617951},
	pages = {20--36},
	number = {4},
	journaltitle = {{ACM} {SIGSOFT} Software Engineering Notes},
	author = {Weyns, Danny and Calinescu, Radu and Mirandola, Raffaela and Tei, Kenji and Acosta, Maribel and Bennaceur, Amel and Boltz, Nicolas and Bures, Tomas and Camara, Javier and Diaconescu, Ada and Engels, Gregor and Gerasimou, Simos and Gerostathopoulos, Ilias and Getir Yaman, Sinem and Grassi, Vincenzo and Hahner, Sebastian and Letier, Emmanuel and Litoiu, Marin and Marsso, Lina and Musil, Angelika and Musil, Juergen and Nunes Rodrigues, Genaina and Perez-Palacin, Diego and Quin, Federico and Scandurra, Patrizia and Vallecillo, Antonio and Zisman, Andrea},
	urldate = {2023-11-02},
	date = {2023},
}

@article{bernsmed_adopting_2022,
	title = {Adopting threat modelling in agile software development projects},
	volume = {183},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121221001874},
	doi = {10.1016/j.jss.2021.111090},
	abstract = {The goal of secure software engineering is to create software that keeps performing as intended, even when exposed to attacks. Threat modelling is considered to be a key activity to reach this goal, but has turned out to be challenging to implement in agile teams. This paper presents results from four different studies, in which we have investigated how agile teams do threat modelling today. Study A is based on observations and document analysis from five teams in a single organisation, Study B is based on interviews with eight individuals from four different organisations, Study C is based on a questionnaire survey of 45 students at two different universities, and Study D is based on interviews with seven teams in a single organisation, supplemented with document analysis. Our results include findings, challenges and current good practice related to the use of Data Flow Diagrams, {STRIDE} and the Microsoft Threat Modelling Tool. We also cross-check our findings with previous relevant work, and provide recommendations for making the threat modelling activities more useful to agile teams.},
	pages = {111090},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Bernsmed, Karin and Cruzes, Daniela Soares and Jaatun, Martin Gilje and Iovan, Monica},
	urldate = {2023-11-09},
	date = {2022-01-01},
	keywords = {Software, Agile, Data Flow Diagrams, {MS}-{TMT}, {STRIDE}, Threat modelling},
}

@inproceedings{alshareef_precise_2022,
	location = {New York, {NY}, {USA}},
	title = {Precise Analysis of Purpose Limitation in Data Flow Diagrams},
	isbn = {978-1-4503-9670-7},
	url = {https://dl.acm.org/doi/10.1145/3538969.3539010},
	doi = {10.1145/3538969.3539010},
	series = {{ARES} '22},
	abstract = {Data Flow Diagrams ({DFDs}) are primarily used for modelling functional properties of a system. In recent work, it was shown that {DFDs} can be used to also model non-functional properties, such as security and privacy properties, if they are annotated with appropriate security- and privacy-related information. An important privacy principle one may wish to model in this way is purpose limitation. But previous work on privacy-aware {DFDs} ({PA}-{DFDs}) considers purpose limitation only superficially, without explaining how the purpose of {DFD} activators and flows ought to be specified, checked or inferred. In this paper, we define a rigorous formal framework for (1) annotating {DFDs} with purpose labels and privacy signatures, (2) checking the consistency of labels and signatures, and (3) inferring labels from signatures. We implement our theoretical framework in a proof-of concept tool consisting of a domain-specific language ({DSL}) for specifying privacy signatures and algorithms for checking and inferring purpose labels from such signatures. Finally, we evaluate our framework and tool through a case study based on a {DFD} from the privacy literature.},
	pages = {1--11},
	booktitle = {Proceedings of the 17th International Conference on Availability, Reliability and Security},
	publisher = {Association for Computing Machinery},
	author = {Alshareef, Hanaa and Tuma, Katja and Stucki, Sandro and Schneider, Gerardo and Scandariato, Riccardo},
	urldate = {2023-11-10},
	date = {2022-08-23},
	keywords = {data flow diagram, Privacy by design, purpose limitation},
}

@inproceedings{leavens_formal_1999,
	location = {New York, {NY}, {USA}},
	title = {Formal semantics for {SA} style data flow diagram specification languages},
	isbn = {978-1-58113-086-7},
	url = {https://dl.acm.org/doi/10.1145/298151.298433},
	doi = {10.1145/298151.298433},
	series = {{SAC} '99},
	pages = {526--532},
	booktitle = {Proceedings of the 1999 {ACM} symposium on Applied computing},
	publisher = {Association for Computing Machinery},
	author = {Leavens, Gary T. and Wahls, Tim and Baker, Albert L.},
	urldate = {2023-11-10},
	date = {1999-02-28},
	keywords = {refinement, data flow diagram, concurrency, semantics of formal specification languages, structured analysis},
}

@inproceedings{liu_formal_1991,
	title = {A formal approach to the semantic specification of data flow diagrams},
	url = {https://ieeexplore.ieee.org/document/170179},
	doi = {10.1109/CMPSAC.1991.170179},
	abstract = {Dataflow diagrams ({DFDs}) are modeled as networks of concurrent processes. With the use of the temporal logic language {XYZ}/E, the formal basis of the semantic specification of {DFD} can be ensured, and the system properties such as safety and liveness can be easily characterized. A verification methodology is proposed which is based on the formal semantics of {DFD}. The implementation of the tools which can support the formal specification, verification, and simulation of {DFD} are also briefly described.{\textless}{\textgreater}},
	eventtitle = {[1991] Proceedings The Fifteenth Annual International Computer Software \& Applications Conference},
	pages = {237--242},
	booktitle = {[1991] Proceedings The Fifteenth Annual International Computer Software \& Applications Conference},
	author = {Liu, T. and Tang, C.S. and Zhang, R.},
	urldate = {2023-11-10},
	date = {1991-09},
}

@article{france_semantically_1992,
	title = {Semantically extended dataflow diagrams: a formal specification tool},
	volume = {18},
	issn = {1939-3520},
	url = {https://ieeexplore.ieee.org/document/129221},
	doi = {10.1109/32.129221},
	shorttitle = {Semantically extended dataflow diagrams},
	abstract = {A method for associating a dataflow diagram ({DFD}) with a formal specification is described. The intention is to enhance the use of the {DFD} as a formal specification tool, thus gaining a tool that can be used to document application functionality in an understandable manner and, at the same time, be capable of producing a formal specification that can be used to rigorously investigate the semantic properties of the application. It is shown how the formal specifications characterizing semantic models of {DFDs} can be used to investigate desired application properties of verify semantic decompositions of data transforms.{\textless}{\textgreater}},
	pages = {329--346},
	number = {4},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {France, R.B.},
	urldate = {2023-11-10},
	date = {1992-04},
	note = {Conference Name: {IEEE} Transactions on Software Engineering},
}

@article{adler_algebra_1988,
	title = {An algebra for data flow diagram process decomposition},
	volume = {14},
	issn = {1939-3520},
	url = {https://ieeexplore.ieee.org/document/4636},
	doi = {10.1109/32.4636},
	abstract = {Data flow diagram process decomposition, as applied in the analysis phase of software engineering, is a top-down method that takes a process, and its input and output data flows, and logically implements the process as a network of smaller processes. The decomposition is generally performed in an ad hoc manner by an analyst applying heuristics, expertise, and knowledge to the problem. An algebra that formalizes process decomposition is presented using the De Marco representation scheme. In this algebra, the analyst relates the disjoint input and output sets of a single process by specifying the elements of an input/output connectivity matrix. A directed acyclic graph is constructed from the matrix and is the decomposition of the process. The graph basis, grammar matrix, and graph interpretations, and the operators of the algebra are discussed. A decomposition procedure for applying the algebra, prototype, and production tools and outlook are also discussed.{\textless}{\textgreater}},
	pages = {169--183},
	number = {2},
	journaltitle = {{IEEE} Transactions on Software Engineering},
	author = {Adler, M.},
	urldate = {2023-11-10},
	date = {1988-02},
	note = {Conference Name: {IEEE} Transactions on Software Engineering},
}

@book{heinrich_composing_2021,
	location = {Cham},
	title = {Composing Model-Based Analysis Tools},
	url = {https://link.springer.com/10.1007/978-3-030-81915-6},
	publisher = {Springer International Publishing},
	author = {Heinrich, Robert and Durán, Francisco and Talcott, Carolyn and Zschaler, Steffen},
	urldate = {2023-11-13},
	date = {2021},
	langid = {english},
	keywords = {Formal Methods, Requirements Engineering, Metamodelling, Model-Based Analysis, Model-Based Software Engineering, Modelling Languages, Software Composition},
}

@inproceedings{basin_is_2023,
	location = {New York, {NY}, {USA}},
	title = {Is Modeling Access Control Worth It?},
	isbn = {9798400700507},
	url = {https://dl.acm.org/doi/10.1145/3576915.3623196},
	doi = {10.1145/3576915.3623196},
	series = {{CCS} '23},
	abstract = {Implementing access control policies is an error-prone task that can have severe consequences for the security of software applications. Model-driven approaches have been proposed in the literature and associated tools have been developed with the goal of reducing the complexity of this task and helping developers to produce secure software efficiently. Nevertheless, there is a lack of empirical data supporting the advantages of model-driven security approaches over code-centric approaches, which are the de-facto industry standard for software development. In this work, we compare the result of implementing the same functional and security requirements by multiple developer groups in the context of a security engineering graduate course. We thereby obtain evidence on the security and efficiency of a tool-based model-driven approach to security from the literature compared to a direct implementation in a well-known, modern web-development framework. For example, the projects using model-driven development pass up to 50\% more security tests on average with less development effort. Also, we observe that models are twice as concise as manual implementations, which improves system maintainability.},
	pages = {2830--2844},
	booktitle = {Proceedings of the 2023 {ACM} {SIGSAC} Conference on Computer and Communications Security},
	publisher = {Association for Computing Machinery},
	author = {Basin, David and Guarnizo, Juan and Krstic, Srđan and Nguyen, Hoang and Ochoa, Martín},
	urldate = {2023-11-27},
	date = {2023-11-21},
	keywords = {access control, security engineering, modeling languages},
}

@inproceedings{walter_architecture-based_2023-1,
	location = {Cham},
	title = {Architecture-Based Attack Path Analysis for Identifying Potential Security Incidents},
	isbn = {978-3-031-42592-9},
	doi = {10.1007/978-3-031-42592-9_3},
	series = {Lecture Notes in Computer Science},
	abstract = {Analyzing attacks and potential attack paths can help to identify and avoid potential security incidents. Manually estimating an attack path to a targeted software element can be complex since a software system consists of multiple vulnerable elements, such as components, hardware resources, or network elements. In addition, the elements are protected by access control. Software architecture describes the structural elements of the system, which may form elements of the attack path. However, estimating attack paths is complex since different attack paths can lead to a targeted element. Additionally, not all attack paths might be relevant since attack paths can have different properties based on the attacker’s capabilities and knowledge. We developed an approach that enables architects to identify relevant attack paths based on the software architecture. We created a metamodel for filtering options and added support for describing attack paths in an architectural description language. Based on this metamodel, we developed an analysis that automatically estimates attack paths using the software architecture. This can help architects to identify relevant attack paths to a targeted component and increase the system’s overall security. We evaluated our approach on five different scenarios. Our evaluation goals are to investigate our analysis’s accuracy and scalability. The results suggest a high accuracy and good runtime behavior for smaller architectures.},
	pages = {37--53},
	booktitle = {Software Architecture},
	publisher = {Springer Nature Switzerland},
	author = {Walter, Maximilian and Heinrich, Robert and Reussner, Ralf},
	editor = {Tekinerdogan, Bedir and Trubiani, Catia and Tibermacine, Chouki and Scandurra, Patrizia and Cuesta, Carlos E.},
	date = {2023},
	langid = {english},
	keywords = {Software Architecture, Attack Path, Attack Propagation},
}

@book{jcgm_1002008_evaluation_2008,
	title = {Evaluation of measurement data—Guide to the expression of uncertainty in measurement ({GUM})},
	publisher = {{ISO} Joint Com. for Guides in Metrology},
	author = {{JCGM 100:2008}},
	date = {2008},
}

@book{de_finetti_theory_2017,
	title = {Theory of Probability: A critical introductory treatment},
	isbn = {978-1-119-28637-0},
	publisher = {John Wiley \& Sons},
	author = {de Finetti, Bruno},
	date = {2017},
	doi = {10.1002/9781119286387},
}

@book{russell_artificial_2010,
	edition = {3},
	title = {Artificial Intelligence, A Modern Approach},
	publisher = {Prentice Hall},
	author = {Russell, Stuart J. and Norvig, Peter},
	date = {2010},
}

@book{zimmermann_fuzzy_2001,
	title = {Fuzzy Set Theory – and Its Applications},
	publisher = {Springer Science+Business Media},
	author = {Zimmermann, Hans-Jürgen},
	date = {2001},
}

@book{shafer_mathematical_1976,
	title = {A Mathematical Theory of Evidence},
	publisher = {Princeton University Press},
	author = {Shafer, Glenn},
	date = {1976},
}

@book{josang_subjective_2016,
	title = {Subjective Logic – A Formalism for Reasoning Under Uncertainty},
	isbn = {978-3-319-42335-7},
	url = {https://link.springer.com/book/10.1007/978-3-319-42337-1},
	series = {Artificial Intelligence: Foundations, Theory, and Algorithms},
	publisher = {Springer},
	author = {Jøsang, Audun},
	date = {2016},
	doi = {10.1007/978-3-319-42337-1},
}

@inproceedings{vanherpen_design-space_2014-1,
	title = {Design-Space Exploration in {MDE}: An Initial Pattern Catalogue},
	volume = {1340},
	url = {http://ceur-ws.org/Vol-1340/paper6.pdf},
	series = {{CEUR} Workshop Proceedings},
	pages = {42--51},
	booktitle = {Proc. of {CMSEBA}@{MODELS}'14},
	publisher = {{CEUR}-{WS}.org},
	author = {Vanherpen, Ken and Denil, Joachim and Meulenaere, Paul De and Vangheluwe, Hans},
	date = {2014},
}

@article{burgueno_dealing_2023,
	title = {Dealing with belief uncertainty in domain models},
	volume = {32},
	doi = {10.1145/3542947},
	pages = {1--34},
	number = {2},
	journaltitle = {{ACM} Transactions on Software Engineering and Methodology},
	author = {Burgueño, Lola and Muñoz, Paula and Clarisó, Robert and Cabot, Jordi and Gérard, Sébastien and Vallecillo, Antonio},
	date = {2023},
}

@article{munoz_extending_2020,
	title = {Extending {OCL} with Subjective Logic},
	volume = {19},
	issn = {1660-1769},
	doi = {10.5381/jot.2020.19.3.a1},
	pages = {3:1--15},
	number = {3},
	journaltitle = {Journal of Object Technology},
	author = {Muñoz, Paula and Burgueño, Loli and Ortiz, Victor and Vallecillo, Antonio},
	date = {2020-10},
}

@book{object_management_group_unified_2015,
	title = {Unified Modeling Language ({UML}) Specification. Version 2.5},
	author = {{Object Management Group}},
	date = {2015-03},
}

@book{object_management_group_precise_2023,
	title = {Precise Semantics for Uncertainty Modeling ({PSUM}), Version 1.0 Beta 1},
	author = {{Object Management Group}},
	date = {2023-03},
}

@book{object_management_group_software_2008,
	title = {Software \& Systems Process Engineering Metamodel ({SPEM}) Specification. Version 2.0},
	author = {{Object Management Group}},
	date = {2008-04},
}

@book{object_management_group_business_2014,
	title = {Business Process Model and Notation ({BPMN}) Specification. Version 2.0},
	author = {{Object Management Group}},
	date = {2014-01},
}

@book{isoiec_15909-12019_systems_2019,
	title = {Systems and software engineering – High-level Petri nets – Part 1: Concepts, definitions and graphical notation},
	publisher = {{ISO}/{IEC}},
	author = {{ISO/IEC 15909-1:2019}},
	date = {2019},
}

@book{object_management_group_uml_2011,
	title = {{UML} Profile for {MARTE}: Modeling and Analysis of Real-Time Embedded Systems. Version 1.1},
	author = {{Object Management Group}},
	date = {2011-06},
}

@book{object_management_group_omg_2023,
	title = {{OMG} Systems Modeling Language ({SysML}), version 2.0},
	author = {{Object Management Group}},
	date = {2023-06},
}

@incollection{demarco_structure_1979,
	title = {Structure analysis and system specification},
	pages = {255--288},
	booktitle = {Pioneers and Their Contributions to Software Engineering},
	publisher = {Springer},
	author = {{DeMarco}, Tom},
	date = {1979},
}

@book{ghanem_handbook_2017,
	title = {Handbook of uncertainty quantification},
	volume = {6},
	publisher = {Springer},
	author = {Ghanem, Roger and Higdon, David and Owhadi, Houman and {others}},
	date = {2017},
}

@inproceedings{de_lemos_software_2013,
	title = {Software engineering for self-adaptive systems: A second research roadmap},
	pages = {1--32},
	booktitle = {Software Engineering for Self-Adaptive Systems {II}: International Seminar, Dagstuhl Castle, Germany, October 24-29, 2010 Revised Selected and Invited Papers},
	publisher = {Springer},
	author = {De Lemos, Rogério and Giese, Holger and Müller, Hausi A and Shaw, Mary and Andersson, Jesper and Litoiu, Marin and Schmerl, Bradley and Tamura, Gabriel and Villegas, Norha M and Vogel, Thomas and {others}},
	date = {2013},
}

@article{garlan_rainbow_2004,
	title = {Rainbow: Architecture-Based Self-Adaptation with Reusable Infrastructure},
	volume = {37},
	doi = {10.1109/MC.2004.175},
	pages = {46--54},
	number = {10},
	journaltitle = {Computer},
	author = {Garlan, David and Cheng, Shang-Wen and Huang, An-Cheng and Schmerl, Bradley R. and Steenkiste, Peter},
	date = {2004},
}

@inproceedings{calinescu_designing_2017,
	title = {Designing Robust Software Systems through Parametric Markov Chain Synthesis},
	doi = {10.1109/ICSA.2017.16},
	pages = {131--140},
	booktitle = {Proc. of {ICSE}'17},
	publisher = {{IEEE} Computer Society},
	author = {Calinescu, Radu and Ceska, Milan and Gerasimou, Simos and Kwiatkowska, Marta and Paoletti, Nicola},
	date = {2017},
}

@book{bause_stochastic_2002,
	title = {Stochastic petri nets},
	volume = {1},
	publisher = {Vieweg Wiesbaden},
	author = {Bause, Falko and Kritzinger, Pieter S},
	date = {2002},
}

@article{camara_uncertainty_2022,
	title = {The uncertainty interaction problem in self-adaptive systems},
	volume = {21},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-022-01037-6},
	doi = {10.1007/s10270-022-01037-6},
	abstract = {The problem of mitigating uncertainty in self-adaptation has driven much of the research proposed in the area of software engineering for self-adaptive systems in the last decade. Although many solutions have already been proposed, most of them tend to tackle specific types, sources, and dimensions of uncertainty (e.g., in goals, resources, adaptation functions) in isolation. A special concern are the aspects associated with uncertainty modeling in an integrated fashion. Different uncertainties are rarely independent and often compound, affecting the satisfaction of goals and other system properties in subtle and often unpredictable ways. Hence, there is still limited understanding about the specific ways in which uncertainties from various sources interact and ultimately affect the properties of self-adaptive, software-intensive systems. In this {SoSym} expert voice, we introduce the Uncertainty Interaction Problem as a way to better qualify the scope of the challenges with respect to representing different types of uncertainty while capturing their interaction in models employed to reason about self-adaptation. We contribute a characterization of the problem and discuss its relevance in the context of case studies taken from two representative application domains. We posit that the Uncertainty Interaction Problem should drive future research in software engineering for autonomous and self-adaptive systems, and therefore, contribute to evolving uncertainty modeling towards holistic approaches that would enable the construction of more resilient self-adaptive systems.},
	pages = {1277--1294},
	number = {4},
	journaltitle = {Software and Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Cámara, Javier and Troya, Javier and Vallecillo, Antonio and Bencomo, Nelly and Calinescu, Radu and Cheng, Betty H. C. and Garlan, David and Schmerl, Bradley},
	urldate = {2023-12-15},
	date = {2022-08-01},
	langid = {english},
	keywords = {Uncertainty, Self-adaptation, Modeling, Assurances},
}

@inproceedings{abdelmoez_error_2004,
	title = {Error propagation in software architectures},
	url = {https://ieeexplore.ieee.org/abstract/document/1357923?casa_token=uDQYQrmJUucAAAAA:M5jmF-rLx9J7HixnceMSkLQXiRCNn-3Wax4FD7aj_RUcjOCi4SjLCP1m4Uypa6LnZyjDQzaA},
	doi = {10.1109/METRIC.2004.1357923},
	abstract = {The study of software architectures is emerging as an important discipline in software engineering, due to its emphasis on large scale composition of software products, and its support for emerging software engineering paradigms such as product line engineering, component based software engineering, and software evolution. Architectural attributes differ from code-level software attributes in that they focus on the level of components and connectors, and that they are meaningful for an architecture. In this paper, we focus on a specific architectural attribute, which is the error propagation probability throughout the architecture, i.e. the probability that an error that arises in one component propagates to other components. We introduce, analyze, and validate formulas for estimating these probabilities using architectural level information.},
	eventtitle = {10th International Symposium on Software Metrics, 2004. Proceedings.},
	pages = {384--393},
	booktitle = {10th International Symposium on Software Metrics, 2004. Proceedings.},
	author = {Abdelmoez, W. and Nassar, D.M. and Shereshevsky, M. and Gradetsky, N. and Gunnalan, R. and Ammar, H.H. and Yu, B. and Mili, A.},
	urldate = {2023-12-15},
	date = {2004-09},
	note = {{ISSN}: 1530-1435},
}

@inproceedings{bencomo_world_2014,
	location = {New York, {NY}, {USA}},
	title = {A world full of surprises: bayesian theory of surprise to quantify degrees of uncertainty},
	isbn = {978-1-4503-2768-8},
	url = {https://doi.org/10.1145/2591062.2591118},
	doi = {10.1145/2591062.2591118},
	series = {{ICSE} Companion 2014},
	shorttitle = {A world full of surprises},
	abstract = {In the specific area of Software Engineering ({SE}) for self-adaptive systems ({SASs}) there is a growing research awareness about the synergy between {SE} and Artificial Intelligence ({AI}). However, just few significant results have been published so far. In this paper, we propose a novel and formal Bayesian definition of surprise as the basis for quantitative analysis to measure degrees of uncertainty and deviations of self-adaptive systems from normal behavior. A surprise measures how observed data affects the models or assumptions of the world during runtime. The key idea is that a "surprising'' event can be defined as one that causes a large divergence between the belief distributions prior to and posterior to the event occurring. In such a case the system may decide either to adapt accordingly or to flag that an abnormal situation is happening. In this paper, we discuss possible applications of Bayesian theory of surprise for the case of self-adaptive systems using Bayesian dynamic decision networks.},
	pages = {460--463},
	booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Bencomo, Nelly and Belaggoun, Amel},
	urldate = {2023-12-15},
	date = {2014},
	keywords = {uncertainty, self-adaptation, bayesian networks, bayesian surprise},
}

@article{bertoa_incorporating_2020,
	title = {Incorporating measurement uncertainty into {OCL}/{UML} primitive datatypes},
	volume = {19},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-019-00741-0},
	doi = {10.1007/s10270-019-00741-0},
	abstract = {The correct representation of the relevant properties of a system is an essential requirement for the effective use and wide adoption of model-based practices in industry. Uncertainty is one of the inherent properties of any measurement or estimation that is obtained in any physical setting; as such, it must be considered when modeling software systems deal with real data. Although a few modeling languages enable the representation of measurement uncertainty, these aspects are not normally incorporated into their type systems. Therefore, operating with uncertain values and propagating their uncertainty become cumbersome processes, which hinder their realization in real environments. This paper proposes an extension of {OCL}/{UML} primitive datatypes that enables the representation of the uncertainty that comes from physical measurements or user estimates into the models, together with an algebra of operations that are defined for the values of these types.},
	pages = {1163--1189},
	number = {5},
	journaltitle = {Software and Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Bertoa, Manuel F. and Burgueño, Loli and Moreno, Nathalie and Vallecillo, Antonio},
	urldate = {2023-12-15},
	date = {2020-09-01},
	langid = {english},
	keywords = {{OCL}, {UML}, Measurement uncertainty, Primitive datatypes},
}

@inproceedings{camara_haiq_2020,
	location = {New York, {NY}, {USA}},
	title = {{HaiQ}: Synthesis of Software Design Spaces with Structural and Probabilistic Guarantees},
	isbn = {978-1-4503-7071-4},
	url = {https://doi.org/10.1145/3372020.3391562},
	doi = {10.1145/3372020.3391562},
	series = {{FormaliSE} '20},
	shorttitle = {{HaiQ}},
	abstract = {Formal methods used to validate software designs, like Alloy, {OCL}, and B, are powerful tools to analyze complex structures (e.g., architectures, object-relational mappings) captured as sets of relational constraints. However, their applicability is limited when software is subject to uncertainty (derived, e.g., from lack of control over third-party components, interaction with physical elements). In contrast, quantitative verification has emerged as a powerful way of providing quantitative guarantees about the performance, cost, and reliability of systems operating under uncertainty. However, quantitative verification methods do not retain thefl exibility of relational modeling in describing structures, forcing engineers to trade structural exploration for analytic capabilities that concern probabilistic and other quantitative guarantees. This paper contributes a method ({HaiQ}) that enhances structural modeling/synthesis with quantitative guarantees in the style provided by quantitative verification. It includes a language for describing structure and (stochastic) behavior of systems, and a temporal logic that allows checking probability and reward-based properties over sets of feasible design alternatives implicitly described by the relational constraints in a {HaiQ} model. We report the results of applying a prototype tool in two domains, on which we show the feasibility of synthesizing structural designs that optimize probabilistic and other quantitative guarantees.},
	pages = {22--33},
	booktitle = {Proceedings of the 8th International Conference on Formal Methods in Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Cámara, Javier},
	urldate = {2023-12-15},
	date = {2020},
	keywords = {Uncertainty, Alloy, guarantees, {HaiQ}, M-{PCTL}, {PRISM}, probabilistic model checking, quantitative verification, relational modeling},
}

@article{garcia-fernandez_modeling_2010,
	title = {Modeling Strategic Decisions Using Activity Diagrams to Consider the Contribution of Dynamic Planning in the Profitability of Projects Under Uncertainty},
	volume = {57},
	issn = {1558-0040},
	url = {https://ieeexplore.ieee.org/document/5353701},
	doi = {10.1109/TEM.2009.2033048},
	abstract = {In this paper, a framework to consider the contribution of decision making and dynamic planning in the profitability of a project under uncertainty is proposed. Unified modeling language ({UML}) activity diagrams are constructed for different strategies of an ongoing engineering project whose final profitability is highly influenced by a set of uncertain variables, such as demand, costs and prices, or unexpected events. Some of these strategies can be, for instance, expanding, contracting, switching, abandoning, waiting, transferring, etc. A method to derive a simple mathematical model for carrying out a project from any {UML} activity diagram describing the strategy is also presented. This mathematical model can be easily implemented in a simulation environment, where the random nature of the different uncertain variables of the project, the relationships between them, and its final profitability can be considered. An example of the application of the proposed model is shown. This example also illustrates how to model the uncertainty in demand by means of a stochastic Bass process. We suggest that the proposed methodology be used by itself or as a complementary tool to the existing methods of capital budgeting by solving some of the deficiencies found in them. For instance: 1) net present value or return on investment is static in nature and cannot cope with uncertainty; 2) real options valuation may be an obscure technique and in many cases does not allow an operational strategy to be derived for guiding the project in real life; and 3) decision analysis occurs within the problem of the “flaw of averages,” by using expected values of different uncertain variables to calculate the profitability of a project instead of their complete probability distribution.},
	pages = {463--476},
	number = {3},
	journaltitle = {{IEEE} Transactions on Engineering Management},
	author = {García-Fernández, Luis Enrique and Garijo, Mercedes},
	urldate = {2023-12-15},
	date = {2010-08},
	note = {Conference Name: {IEEE} Transactions on Engineering Management},
}

@inproceedings{ghezzi_managing_2013,
	title = {Managing non-functional uncertainty via model-driven adaptivity},
	url = {https://ieeexplore.ieee.org/document/6606549},
	doi = {10.1109/ICSE.2013.6606549},
	abstract = {Modern software systems are often characterized by uncertainty and changes in the environment in which they are embedded. Hence, they must be designed as adaptive systems. We propose a framework that supports adaptation to non-functional manifestations of uncertainty. Our framework allows engineers to derive, from an initial model of the system, a finite state automaton augmented with probabilities. The system is then executed by an interpreter that navigates the automaton and invokes the component implementations associated to the states it traverses. The interpreter adapts the execution by choosing among alternative possible paths of the automaton in order to maximize the system's ability to meet its non-functional requirements. To demonstrate the adaptation capabilities of the proposed approach we implemented an adaptive application inspired by an existing worldwide distributed mobile application and we discussed several adaptation scenarios.},
	eventtitle = {2013 35th International Conference on Software Engineering ({ICSE})},
	pages = {33--42},
	booktitle = {2013 35th International Conference on Software Engineering ({ICSE})},
	author = {Ghezzi, Carlo and Pinto, Leandro Sales and Spoletini, Paola and Tamburrelli, Giordano},
	urldate = {2023-12-15},
	date = {2013-05},
	note = {{ISSN}: 1558-1225},
}

@inproceedings{kwiatkowska_assume-guarantee_2010,
	location = {Berlin, Heidelberg},
	title = {Assume-Guarantee Verification for Probabilistic Systems},
	isbn = {978-3-642-12002-2},
	doi = {10.1007/978-3-642-12002-2_3},
	series = {Lecture Notes in Computer Science},
	abstract = {We present a compositional verification technique for systems that exhibit both probabilistic and nondeterministic behaviour. We adopt an assume-guarantee approach to verification, where both the assumptions made about system components and the guarantees that they provide are regular safety properties, represented by finite automata. Unlike previous proposals for assume-guarantee reasoning about probabilistic systems, our approach does not require that components interact in a fully synchronous fashion. In addition, the compositional verification method is efficient and fully automated, based on a reduction to the problem of multi-objective probabilistic model checking. We present asymmetric and circular assume-guarantee rules, and show how they can be adapted to form quantitative queries, yielding lower and upper bounds on the actual probabilities that a property is satisfied. Our techniques have been implemented and applied to several large case studies, including instances where conventional probabilistic verification is infeasible.},
	pages = {23--37},
	booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
	publisher = {Springer},
	author = {Kwiatkowska, Marta and Norman, Gethin and Parker, David and Qu, Hongyang},
	editor = {Esparza, Javier and Majumdar, Rupak},
	date = {2010},
	langid = {english},
}

@inproceedings{pavese_probabilistic_2009,
	location = {New York, {NY}, {USA}},
	title = {Probabilistic environments in the quantitative analysis of (non-probabilistic) behaviour models},
	isbn = {978-1-60558-001-2},
	url = {https://dl.acm.org/doi/10.1145/1595696.1595760},
	doi = {10.1145/1595696.1595760},
	series = {{ESEC}/{FSE} '09},
	abstract = {System specifications have long been expressed through automata-based languages, enabling verification techniques such as model checking. These verification techniques can assess whether a property holds or not, given a system specification. Quantitative model checking can provide additional information on the probability of these properties holding. We are interested in quantitatively analysing the probability of errors in non-probabilistic system models by composing them with probabilistic models of the environment. Although many probabilistic automata-based formalisms and composition operators exist, these are not adequate for such a setting. In this work we present a formalism inspired on interface automata and a suitable composition operator for these automata that enables validation of environment models in isolation and sound analysis of its composition with the non-probabilistic model of the system-under-analysis.},
	pages = {335--344},
	booktitle = {Proceedings of the 7th joint meeting of the European software engineering conference and the {ACM} {SIGSOFT} symposium on The foundations of software engineering},
	publisher = {Association for Computing Machinery},
	author = {Pavese, Esteban and Braberman, Víctor and Uchitel, Sebastian},
	urldate = {2023-12-15},
	date = {2009-08-24},
	keywords = {probability, model checking, behaviour models, interface automata},
}

@article{samin_decision-making_2022,
	title = {Decision-making under uncertainty: be aware of your priorities},
	volume = {21},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-021-00956-0},
	doi = {10.1007/s10270-021-00956-0},
	shorttitle = {Decision-making under uncertainty},
	abstract = {Self-adaptive systems ({SASs}) are increasingly leveraging autonomy in their decision-making to manage uncertainty in their operating environments. A key problem with {SASs} is ensuring their requirements remain satisfied as they adapt. The trade-off analysis of the non-functional requirements ({NFRs}) is key to establish balance among them. Further, when performing the trade-offs it is necessary to know the importance of each {NFR} to be able to resolve conflicts among them. Such trade-off analyses are often built upon optimisation methods, including decision analysis and utility theory. A problem with these techniques is that they use a single-scalar utility value to represent the overall combined priority for all the {NFRs}. However, this combined scalar priority value may hide information about the impacts of the environmental contexts on the individual {NFRs}’ priorities, which may change over time. Hence, there is a need for support for runtime, autonomous reasoning about the separate priority values for each {NFR}, while using the knowledge acquired based on evidence collected. In this paper, we propose Pri-{AwaRE}, a self-adaptive architecture that makes use of Multi-Reward Partially Observable Markov Decision Process ({MR}-{POMDP}) to perform decision-making for {SASs} while offering awareness of {NFRs}’ priorities. {MR}-{POMDP} is used as a priority-aware runtime specification model to support runtime reasoning and autonomous tuning of the distinct priority values of {NFRs} using a vector-valued reward function. We also evaluate the usefulness of our Pri-{AwaRE} approach by applying it to two substantial example applications from the networking and {IoT} domains.},
	pages = {2213--2242},
	number = {6},
	journaltitle = {Software and Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Samin, Huma and Bencomo, Nelly and Sawyer, Peter},
	urldate = {2023-12-15},
	date = {2022-12-01},
	langid = {english},
	keywords = {Decision-making, Non-functional requirements, Priorities, Self-Adaptive systems},
}

@article{troya_uncertainty_2021,
	title = {Uncertainty representation in software models: a survey},
	volume = {20},
	issn = {1619-1374},
	url = {https://doi.org/10.1007/s10270-020-00842-1},
	doi = {10.1007/s10270-020-00842-1},
	shorttitle = {Uncertainty representation in software models},
	abstract = {This paper provides a comprehensive overview and analysis of research work on how uncertainty is currently represented in software models. The survey presents the definitions and current research status of different proposals for addressing uncertainty modeling and introduces a classification framework that allows to compare and classify existing proposals, analyze their current status and identify new trends. In addition, we discuss possible future research directions, opportunities and challenges.},
	pages = {1183--1213},
	number = {4},
	journaltitle = {Software and Systems Modeling},
	shortjournal = {Softw Syst Model},
	author = {Troya, Javier and Moreno, Nathalie and Bertoa, Manuel F. and Vallecillo, Antonio},
	urldate = {2023-12-15},
	date = {2021-08-01},
	langid = {english},
	keywords = {Uncertainty, {UML}, Modeling languages, Software models, Systematic literature review},
}

@thesis{hahner_inkrementelle_2016,
	title = {Inkrementelle Aktualisierungstechniken für Modelle und ihre Datenbankrepräsentation},
	url = {https://publikationen.bibliothek.kit.edu/1000140048},
	pagetotal = {60},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Bachelor's Thesis},
	author = {Hahner, Sebastian},
	date = {2016},
	doi = {10.5445/IR/1000140048},
}

@inproceedings{saglam_token-based_2022,
	location = {New York, {NY}, {USA}},
	title = {Token-based plagiarism detection for metamodels},
	isbn = {978-1-4503-9467-3},
	url = {https://doi.org/10.1145/3550356.3556508},
	doi = {10.1145/3550356.3556508},
	series = {{MODELS} '22},
	eventtitle = {25th International Conference on Model Driven Engineering Languages and Systems ({MODELS})},
	pages = {138--141},
	booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
	publisher = {{ACM}},
	author = {Sağlam, Timur and Hahner, Sebastian and Wittler, Jan Willem and Kühn, Thomas},
	date = {2022},
	keywords = {education, {JPlag}, metamodel similarity, metamodeling, obfuscation attacks, plagiarism detection, token-based plagiarism detection},
}

@incollection{heinrich_dynamic_2023,
	location = {Berlin, Heidelberg},
	title = {Dynamic Access Control in Industry 4.0 Systems},
	isbn = {978-3-662-65004-2},
	url = {https://doi.org/10.1007/978-3-662-65004-2_6},
	pages = {143--170},
	booktitle = {Digital Transformation: Core Technologies and Emerging Topics from a Computer Science Perspective},
	publisher = {Springer},
	author = {Heinrich, Robert and Seifermann, Stephan and Walter, Maximilian and Hahner, Sebastian and Reussner, Ralf and Bureš, Tomáš and Hnětynka, Petr and Pacovský, Jan},
	editor = {Vogel-Heuser, Birgit and Wimmer, Manuel},
	date = {2023},
	langid = {english},
	doi = {10.1007/978-3-662-65004-2_6},
}

@inproceedings{saglam_how_2023,
	location = {Västerås, Sweden},
	title = {How Students Plagiarize Modeling Assignments},
	doi = {10.1109/MODELS-C59198.2023.00032},
	eventtitle = {2023 {ACM}/{IEEE} International Conference on Model Driven Engineering Languages and Systems Companion ({MODELS}-C)},
	pages = {98--101},
	booktitle = {2023 {ACM}/{IEEE} International Conference on Model Driven Engineering Languages and Systems Companion ({MODELS}-C)},
	publisher = {{ACM}/{IEEE}},
	author = {Sağlam, Timur and Schmid, Larissa and Hahner, Sebastian and Burger, Erik},
	date = {2023},
}

@article{bures_generating_2023,
	title = {Generating adaptation rule-specific neural networks},
	volume = {25},
	issn = {1433-2787},
	doi = {10.1007/s10009-023-00725-y},
	pages = {733--746},
	number = {5},
	journaltitle = {International Journal on Software Tools for Technology Transfer},
	author = {Bureš, Tomáš and Hnětynka, Petr and Kruliš, Martin and Plášil, František and Khalyeyev, Danylo and Hahner, Sebastian and Seifermann, Stephan and Walter, Maximilian and Heinrich, Robert},
	urldate = {2024-01-03},
	date = {2023},
	langid = {english},
	keywords = {Self-adaptive systems, Adaptation rules, Machine learning, Neural networks},
}

@inproceedings{grua_self-adaptation_2019,
	title = {Self-Adaptation in Mobile Apps: a Systematic Literature Study},
	url = {https://ieeexplore.ieee.org/document/8787041},
	doi = {10.1109/SEAMS.2019.00016},
	shorttitle = {Self-Adaptation in Mobile Apps},
	abstract = {With their increase, smartphones have become more integral components of our lives but due to their mobile nature it is not possible to develop a mobile application the same way another software system would be built. In order to always provide the full service, a mobile application needs to be able to detect and deal with changes of context it may be presented with. A suitable method to achieve this goal is self-adaptation. However, as of today it is difficult to have a clear view of existing research on self-adaptation in the context of mobile applications. In this paper, we apply the systematic literature review methodology on selected peer-reviewed papers focusing on self-adaptability in the context of mobile applications. Out of 607 potentially relevant studies, we select 44 primary studies via carefully-defined exclusion and inclusion criteria. We use known modelling dimensions for self-adaptive software systems as our classification framework, which we apply to all selected primary studies. From the synthesized data we obtained, we produce an overview of the state of the art. The results of this study give a solid foundation to plan for future research and practice on engineering self-adaptive mobile applications.},
	eventtitle = {2019 {IEEE}/{ACM} 14th International Symposium on Software Engineering for Adaptive and Self-Managing Systems ({SEAMS})},
	pages = {51--62},
	booktitle = {2019 {IEEE}/{ACM} 14th International Symposium on Software Engineering for Adaptive and Self-Managing Systems ({SEAMS})},
	author = {Grua, Eoin Martino and Malavolta, Ivano and Lago, Patricia},
	urldate = {2024-01-12},
	date = {2019-05},
	note = {{ISSN}: 2157-2321},
}

@inproceedings{yamaguchi_modeling_2014,
	title = {Modeling and Discovering Vulnerabilities with Code Property Graphs},
	url = {https://ieeexplore.ieee.org/document/6956589},
	doi = {10.1109/SP.2014.44},
	abstract = {The vast majority of security breaches encountered today are a direct result of insecure code. Consequently, the protection of computer systems critically depends on the rigorous identification of vulnerabilities in software, a tedious and error-prone process requiring significant expertise. Unfortunately, a single flaw suffices to undermine the security of a system and thus the sheer amount of code to audit plays into the attacker's cards. In this paper, we present a method to effectively mine large amounts of source code for vulnerabilities. To this end, we introduce a novel representation of source code called a code property graph that merges concepts of classic program analysis, namely abstract syntax trees, control flow graphs and program dependence graphs, into a joint data structure. This comprehensive representation enables us to elegantly model templates for common vulnerabilities with graph traversals that, for instance, can identify buffer overflows, integer overflows, format string vulnerabilities, or memory disclosures. We implement our approach using a popular graph database and demonstrate its efficacy by identifying 18 previously unknown vulnerabilities in the source code of the Linux kernel.},
	eventtitle = {2014 {IEEE} Symposium on Security and Privacy},
	pages = {590--604},
	booktitle = {2014 {IEEE} Symposium on Security and Privacy},
	author = {Yamaguchi, Fabian and Golde, Nico and Arp, Daniel and Rieck, Konrad},
	urldate = {2024-02-05},
	date = {2014-05},
	note = {{ISSN}: 2375-1207},
	keywords = {Security, Databases, Abstracts, Syntactics, Static Analysis, Graph Databases, Joints, Kernel, Vulnerabilities},
}

@inproceedings{hahner_architecture-based_2024,
	location = {Linz, Austria},
	title = {Architecture-based Propagation Analyses Regarding Security},
	isbn = {978-3-88579-737-1},
	url = {https://dl.gi.de/handle/20.500.12116/43582},
	doi = {10.18420/sw2024_38},
	eventtitle = {Software Engineering 2024 ({SE} 2024)},
	pages = {121--122},
	booktitle = {Software Engineering 2024},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Hahner, Sebastian and Walter, Maximilian and Heinrich, Robert and Reussner, Ralf},
	urldate = {2024-02-25},
	date = {2024},
	langid = {english},
}

@inproceedings{sofaer_rogueone_2024,
	title = {{RogueOne}: Detecting Rogue Updates  via Differential Data-flow Analysis Using Trust Domains},
	doi = {10.1145/3597503.3639199},
	abstract = {Rogue updates, an important type of software supply-chain attack in which attackers conceal malicious code inside updates to benign software, are a growing problem due to their stealth and effectiveness. We design and implement {RogueOne}, a system for detecting rogue updates to {JavaScript} packages. {RogueOne} uses a novel differential data-flow analysis to capture how an update changes a package’s interactions with external {APIs}. Using an efficient form of abstract interpretation that can exclude unchanged code in a package, it constructs an object data-flow relationship graph ({ODRG}) that tracks data-flows among objects. {RogueOne} then maps objects to trust domains, a novel abstraction which summarizes trust relationships in a package. Objects are assigned a trust domain based on whether they originate in the target package, a dependency, or in a system {API}. {RogueOne} uses the {ODRG} to build a set of data-flows across trust domains. It compares data-flow sets across package versions to detect untrustworthy new interactions with external {APIs}. We evaluated {RogueOne} on hundreds of npm packages, demonstrating its effectiveness at detecting rogue updates and distinguishing them from benign ones. {RogueOne} achieves high accuracy and can be more than seven times as effective in detecting rogue updates and avoiding false positives compared to other systems built to detect malicious packages.},
	eventtitle = {{ICSE} ’24},
	booktitle = {{ICSE} ’24},
	author = {Sofaer, Raphael J and David, Yaniv and Kang, Mingqing and Yu, Jianjia and Cao, Yinzhi and Yang, Junfeng and Nieh, Jason},
	date = {2024},
	langid = {english},
}

@thesis{walter_context-based_2023,
	title = {Context-based Access Control and Attack Modelling and Analysis},
	type = {Dissertation},
	author = {Walter, Maximilian},
	date = {2023},
	langid = {german},
}

@inproceedings{cheng_evaluating_2009,
	title = {Evaluating the effectiveness of the Rainbow self-adaptive system},
	url = {https://ieeexplore.ieee.org/abstract/document/5069082},
	doi = {10.1109/SEAMS.2009.5069082},
	abstract = {Rainbow is a framework for engineering a system with run-time, self-adaptive capabilities to monitor, detect, decide, and act on opportunities for system improvement. We applied Rainbow to a system, Znn.com, and evaluated its effectiveness to self-adapt on three levels: its effectiveness to maintain quality attribute in the face of changing conditions, run-time overheads of adaptation, and the engineering effort to use it to add self-adaptive capabilities to Znn.com. We make Znn.com and the associated evaluation tools available to the community so that other researchers can use it to evaluate their own systems and the community can compare different systems. In this paper, we report on our evaluation experience, reflect on some principles for benchmarking self-adaptive systems, and discuss the suitability of our evaluation tools for this purpose.},
	eventtitle = {2009 {ICSE} Workshop on Software Engineering for Adaptive and Self-Managing Systems},
	pages = {132--141},
	booktitle = {2009 {ICSE} Workshop on Software Engineering for Adaptive and Self-Managing Systems},
	author = {Cheng, Shang-Wen and Garlan, David and Schmerl, Bradley},
	urldate = {2024-04-03},
	date = {2009-05},
	keywords = {Control systems, Quality of service, Monitoring, Systems engineering and theory, Face detection, Maintenance engineering, Automatic control, Runtime, Humans, Utility theory},
}

@article{zhao_early_2024,
	title = {Early Career Software Developers - Are You Sinking or Swimming?},
	abstract = {Background: Newbies in their early stage of software engineering careers suffer from unfitting task assignments, unclear job expectations, and insufficient communication with managers frequently, which leads to personal frustration, unsatisfactory team performance, and low employee retention. Goals: The goal of this research is to investigate new software developers’ "sink or swim" early career experience from the following four dimensions: job assignment, newbie-manager pairing, job satisfaction, and thoughts and suggestions. Methodology: To achieve our research goal, we conducted an empirical study by distributing an online questionnaire that includes both qualitative and quantitative questions. Results: There are several factors contributing to a "sink or swim" early career experience, such as unclear about what to do, who to report to, lack of communication, and vague expectations, posing negative impacts on both individuals and the organization. In addition, we also propose a new community smell in our paper - Newbie Sink or Swim, based on our investigation. Conclusions: The early stage is critical to software developers’ careers. A failing start phase has detrimental effects on software developers and development teams. Our study empirically examines software developers’ early careers from various aspects, providing deeper insights into how to build a more supportive and productive working environment for entry-level developers in the software community.},
	author = {Zhao, Xin and University, Seattle and Tsuboi, Narissa and University, Seattle},
	date = {2024},
	langid = {english},
}

@inproceedings{he_high_2024,
	location = {Lisbon Portugal},
	title = {High Expectations: An Observational Study of Programming and Cannabis Intoxication},
	isbn = {9798400702174},
	url = {https://dl.acm.org/doi/10.1145/3597503.3639145},
	doi = {10.1145/3597503.3639145},
	shorttitle = {High Expectations},
	abstract = {Anecdotal evidence of cannabis use by professional programmers abounds. Recent studies have found that some professionals regularly use cannabis while programming, even for work-related tasks. However, accounts of the impacts of cannabis on programming vary widely and are often contradictory. For example, some programmers claim that it impairs their ability to generate correct solutions, while others claim it enhances creativity and focus. There remains a need for an empirical understanding of the true impacts of cannabis on programming. This paper presents the first controlled observational study of cannabis’s effects on programming ability. Based on a within-subjects design with over 70 participants, we find that, at ecologically valid dosages, cannabis significantly impairs programming performance. Programs implemented while high contain more bugs and take longer to write (𝑝 {\textless} 0.05) — a small to medium effect (0.22 ≤ 𝑑 ≤ 0.44). We also did not find any evidence that high programmers generate more divergent solutions. However, programmers can accurately assess differences in their programming performance (𝑟 = 0.59), even when under the influence of cannabis. We hope that this research will facilitate evidence-based policies and help developers make informed decisions regarding cannabis use while programming.},
	eventtitle = {{ICSE} '24: {IEEE}/{ACM} 46th International Conference on Software Engineering},
	pages = {1--12},
	booktitle = {Proceedings of the {IEEE}/{ACM} 46th International Conference on Software Engineering},
	publisher = {{ACM}},
	author = {He, Wenxin and Parikh, Manasvi and Weimer, Westley and Endres, Madeline},
	urldate = {2024-04-18},
	date = {2024-04-12},
	langid = {english},
}

@inproceedings{steenhoek_dataflow_2024,
	location = {Lisbon Portugal},
	title = {Dataflow Analysis-Inspired Deep Learning for Efficient Vulnerability Detection},
	isbn = {9798400702174},
	url = {https://dl.acm.org/doi/10.1145/3597503.3623345},
	doi = {10.1145/3597503.3623345},
	abstract = {Deep learning-based vulnerability detection has shown great performance and, in some studies, outperformed static analysis tools. However, the highest-performing approaches use token-based transformer models, which are not the most efficient to capture code semantics required for vulnerability detection. Classical program analysis techniques such as dataflow analysis can detect many types of bugs based on their root causes. In this paper, we propose to combine such causal-based vulnerability detection algorithms with deep learning, aiming to achieve more efficient and effective vulnerability detection. Specifically, we designed {DeepDFA}, a dataflow analysisinspired graph learning framework and an embedding technique that enables graph learning to simulate dataflow computation. We show that {DeepDFA} is both performant and efficient. {DeepDFA} outperformed all non-transformer baselines. It was trained in 9 minutes, 75x faster than the highest-performing baseline model. When using only 50+ vulnerable and several hundreds of total examples as training data, the model retained the same performance as 100\% of the dataset. {DeepDFA} also generalized to real-world vulnerabilities in {DbgBench}; it detected 8.7 out of 17 vulnerabilities on average across folds and was able to distinguish between patched and buggy versions, while the highest-performing baseline models did not detect any vulnerabilities. By combining {DeepDFA} with a large language model, we surpassed the state-of-the-art vulnerability detection performance on the Big-Vul dataset with 96.46 F1 score, 97.82 precision, and 95.14 recall. Our replication package is located at https://doi.org/10.6084/m9.figshare.21225413.},
	eventtitle = {{ICSE} '24: 46th {IEEE}/{ACM} International Conference on Software Engineering},
	pages = {1--13},
	booktitle = {Proceedings of the 46th {IEEE}/{ACM} International Conference on Software Engineering},
	publisher = {{ACM}},
	author = {Steenhoek, Benjamin and Gao, Hongyang and Le, Wei},
	urldate = {2024-04-18},
	date = {2024-02-06},
	langid = {english},
}

@article{liebel_challenges_2024,
	title = {Challenges, Strengths, and Strategies of Software Engineers with {ADHD}: A Case Study},
	abstract = {Neurodiversity describes brain function variation in individuals, including Attention deficit hyperactivity disorder ({ADHD}) and Autism spectrum disorder. Neurodivergent individuals both experience challenges and exhibit strengths in the workplace. As an important disorder included under the neurodiversity term, an estimated 5.0\% to 7.1\% of the world population have {ADHD}. However, existing studies involving {ADHD} in the workplace are of general nature and do not focus on software engineering ({SE}) activities. To address this gap, we performed an exploratory qualitative case study on the experiences of people with {ADHD} working in {SE}. We find that people with {ADHD} struggle with several important {SErelated} activities, e.g., task organisation and estimation, attention to work, relation to others. Furthermore, they experience issues with physical and mental health. In terms of strengths, they exhibit, e.g., increased creative skills, perform well when solving puzzles, and have the capability to think ahead. Our findings align with clinical {ADHD} research, having important implications to {SE} practice.},
	author = {Liebel, Grischa and University, Reykjavik},
	date = {2024},
	langid = {english},
}

@inproceedings{jackson_co-creation_2024,
	location = {Lisbon Portugal},
	title = {Co-Creation in Fully Remote Software Teams},
	isbn = {9798400702174},
	url = {https://dl.acm.org/doi/10.1145/3597503.3623297},
	doi = {10.1145/3597503.3623297},
	abstract = {In this paper, we use the lens of co-creation—a concept originally coined and applied in the fields of management and design that denotes how groups of people collaboratively create something of meaning through an orchestration of people, activities, and tools—to study how fully remote software teams co-create digital artifacts that can be considered as a form of documentation. We report on the results of a qualitative, interview-based study with 25 software professionals working in remote teams. Our primary findings are the definition of four models of co-creation, examples of sequencing these models into work chains to produce artifacts, factors that influence how developers match tasks to models and chains, and insights into tool support for co-creation. Together, our findings illustrate how co-creation is an intentional activity that has a significant role in how remote software teams’ choose to structure their collaborative activities.},
	eventtitle = {{ICSE} '24: 46th {IEEE}/{ACM} International Conference on Software Engineering},
	pages = {1--12},
	booktitle = {Proceedings of the 46th {IEEE}/{ACM} International Conference on Software Engineering},
	publisher = {{ACM}},
	author = {Jackson, Victoria and Prikladnicki, Rafael and Van Der Hoek, Andre},
	urldate = {2024-04-18},
	date = {2024-02-06},
	langid = {english},
}

@article{alguliyev_cyber-physical_2018,
	title = {Cyber-physical systems and their security issues},
	volume = {100},
	issn = {0166-3615},
	url = {https://www.sciencedirect.com/science/article/pii/S0166361517304244},
	doi = {10.1016/j.compind.2018.04.017},
	abstract = {The creation of cyber-physical systems posed new challenges for people. Ensuring the information security of cyber-physical systems is one of the most complex problems in a wide range of defenses against cyber-attacks. The aim of this paper is to analyse and classify existing research papers on the security of cyber-physical systems. Philosophical issues of cyber-physical systems are raised. Their influence on the aspects of people's lives is investigated. The principle of cyber-physical system operation is described. The main difficulties and solutions in the estimation of the consequences of cyber-attacks, attacks modeling and detection and the development of security architecture are noted. The main types of attacks and threats against cyber-physical systems are analysed. A tree of attacks on cyber-physical systems is proposed. The future research directions are shown.},
	pages = {212--223},
	journaltitle = {Computers in Industry},
	shortjournal = {Computers in Industry},
	author = {Alguliyev, Rasim and Imamverdiyev, Yadigar and Sukhostat, Lyudmila},
	urldate = {2024-04-24},
	date = {2018-09-01},
	keywords = {Cyber-physical system, Cyber-physical system attacks, Cyber-physical system security, Cyber-physical system security threats, Philosophical issues, Tree of attacks},
}

@online{github_githubcom_2024,
	title = {{GitHub}.com Documentation},
	url = {https://docs.github.com/},
	titleaddon = {{GitHub} Docs},
	author = {{GitHub}},
	urldate = {2024-04-29},
	date = {2024},
}

@article{goh_link_2007,
	title = {Link decay in leading information science journals},
	volume = {58},
	issn = {1532-2890},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.20513},
	doi = {10.1002/asi.20513},
	abstract = {Web citations have become common in scholarly publications as the amount of online literature increases. Yet, such links are not persistent and many decay over time, causing accessibility problems for readers. The present study investigates the link decay phenomenon in three leading information science journals. Articles spanning a period of 7 years (1997–2003) were downloaded, and their links were extracted. From these, a measure of link decay, the half-life, was computed to be approximately 5 years, which compares favorably against other disciplines (1.4–4.8 years). The study also investigated types of link accessibility errors encountered as well as examined characteristics of links that may be associated with decay. It was found that approximately 31\% of all citations were not accessible during the time of testing, and the majority of errors were due to missing content ({HTTP} Error Code 404). Citations from the edu domain were also found to have the highest failure rates of 36\% when compared with other popular top-level domains. Results indicate that link decay is a problem that cannot be ignored, and implications for journal authors and readers are discussed.},
	pages = {15--24},
	number = {1},
	journaltitle = {Journal of the American Society for Information Science and Technology},
	author = {Goh, Dion Hoe-Lian and Ng, Peng Kin},
	urldate = {2024-04-29},
	date = {2007},
	langid = {english},
}

@article{enaya_case_2024,
	title = {A case study on the development of the German Corona-Warn-App},
	volume = {213},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121224000633},
	doi = {10.1016/j.jss.2024.112020},
	abstract = {The {COVID}-19 pandemic has drastically changed daily life and required fast responses to new situations, such as restricted public life. A major means to limit infections have been contact-tracing apps that inform an individual about a potential infection, helping to initiate countermeasures faster. While different tracing apps have been compared technologically, we are not aware of studies providing insights into their development processes during the pandemic emergency situation. To address this gap, we report an exploratory case study on how the German open-source Corona-Warn-App has been developed at {SAP} {SE}—and how other organizations (e.g., Deutsche Telekom {AG}), researchers, and individual developers contributed. We elicited data on the process, practices, and challenges by interviewing six developers at {SAP} {SE}, analyzing documentation, and discussing our data with an expert on the app’s development. Overall, we provide insights into how the development process of the Corona-Warn-App differed from other projects at {SAP} {SE} (e.g., testing), discuss the causes (i.e., public interest causing researchers to perform tests), and study the consequences (i.e., emergency tickets by researchers). Our findings can guide organizations when developing software in similar emergency situations (e.g., pandemics) in which reliable software needs to be developed within a short period of time.},
	pages = {112020},
	journaltitle = {Journal of Systems and Software},
	shortjournal = {Journal of Systems and Software},
	author = {Enaya, Mohamad Fawaz and Klingbeil, Thomas and Krüger, Jacob and Broneske, David and Feinbube, Frank and Saake, Gunter},
	urldate = {2024-05-14},
	date = {2024-07-01},
	keywords = {Empirical study, Contact tracing app, {COVID}-19, Pandemic, Software development process},
}

@inproceedings{lupafya_framework_2022,
	title = {A Framework for Considering Uncertainty in Software Systems},
	url = {https://ieeexplore.ieee.org/document/9842720},
	doi = {10.1109/COMPSAC54236.2022.00241},
	abstract = {There are many aspects involved in the development and operation of a software system, including system artefacts, activities, and infrastructure. Most of these aspects are vulnerable to uncertainty, which can result in risks to system quality and performance. Thus it is important to identify, represent and manage uncertainty in software systems. We hypothesise that using an underlying conceptual framework for characterising uncertainty can facilitate these activities. This paper demonstrates the use of an extensible framework, which defines a foundation for the systematic and explicit consideration of uncertainty in software systems. A software architecture case study is used to illustrate and evaluate the framework. A discussion of potential uses for the framework and future research is also provided.},
	eventtitle = {2022 {IEEE} 46th Annual Computers, Software, and Applications Conference ({COMPSAC})},
	pages = {1519--1524},
	booktitle = {2022 {IEEE} 46th Annual Computers, Software, and Applications Conference ({COMPSAC})},
	author = {Lupafya, Chawanangwa and Balasubramaniam, Dharini},
	urldate = {2024-05-16},
	date = {2022-06},
	keywords = {Uncertainty, Computer architecture, Software architecture, Software systems, Software Architecture, Systematics, Framework, Uncertainty in Software},
}

@incollection{von_neumann_theory_1944,
	title = {Theory of Games and Economic Behavior},
	booktitle = {Theory of Games and Economic Behavior},
	author = {von Neumann, John and Morgenstern, Oskar},
	date = {1944},
	langid = {english},
	keywords = {Uncertainty, Measurement, Economics, Mathematics, Prediction, Set theory, Linear programming, Addition, Analogy, Axiom, Behavioral economics, Big O notation, Bilateral monopoly, Characteristic function (probability theory), Coefficient, Combination, Competition, Computation, Consideration, Contradiction, Determination, Disadvantage, Economic problem, Economist, Elaboration, Enumeration, Exchange economy, Existential quantification, Expected value, Game Theory, Geometry, Hypothesis, Illustration, Indifference curve, Intransitivity, Leonid Hurwicz, Marginal utility, Matching Pennies, Mathematical analysis, Mathematical economics, Mathematical problem, Mathematical proof, Mathematician, Maxima and minima, Monopolistic competition, Notation, Oligopoly, Oskar Morgenstern, Partially ordered set, Participant, Payment, Permutation, Preference (economics), Probability, Probability theory, Quantity, Requirement, Result, Saddle point, Social science, Special case, Strategy (game theory), Subset, Suggestion, Summation, Theorem, Theory, Theory of Games and Economic Behavior, Variable (mathematics), Zero-Sum Game},
}

@online{weisbaum_trust_2018,
	title = {Trust in Facebook has dropped by 66 percent since the Cambridge Analytica scandal},
	url = {https://www.nbcnews.com/business/consumer/trust-facebook-has-dropped-51-percent-cambridge-analytica-scandal-n867011},
	author = {Weisbaum, Herb},
	urldate = {2023-01-19},
	date = {2018},
}

@inproceedings{goseva-popstojanova_assessing_2003,
	title = {Assessing uncertainty in reliability of component-based software systems},
	doi = {10.1109/ISSRE.2003.1251052},
	eventtitle = {14th International Symposium on Software Reliability Engineering, 2003. {ISSRE} 2003.},
	pages = {307--320},
	booktitle = {{ISSRE}},
	author = {Goseva-Popstojanova, K. and Kamavaram, S.},
	date = {2003-11},
	keywords = {Uncertainty, Computer architecture, Application software, Software systems, Computer science, Bayesian methods, Performance analysis, Software reliability, Moment methods, Parameter estimation},
}

@misc{starke_arc42_2024,
	title = {arc42 Quality Model},
	url = {https://quality.arc42.org/},
	author = {Starke, Gernot},
	date = {2024},
}

@book{funtowicz_uncertainty_1990,
	title = {Uncertainty and quality in science for policy},
	volume = {15},
	publisher = {Springer Science \& Business Media},
	author = {Funtowicz, Silvio O and Ravetz, Jerome R},
	date = {1990},
}

@article{iverson_knowledge_2002,
	title = {Knowledge Management in Communities of Practice: Being True to the Communicative Character of Knowledge},
	volume = {16},
	url = {https://doi.org/10.1177/089331802237239},
	doi = {10.1177/089331802237239},
	pages = {259--266},
	number = {2},
	journaltitle = {Management Communication Quarterly},
	author = {Iverson, Joel O. and Mcphee, Robert D.},
	date = {2002},
}

@inproceedings{layzell_supporting_2000,
	title = {Supporting collaboration in distributed software engineering teams},
	doi = {10.1109/APSEC.2000.896681},
	pages = {38--45},
	booktitle = {Proceedings Seventh Asia-Pacific Software Engeering Conference. {APSEC} 2000},
	author = {Layzell, P. and Brereton, O.P. and French, A.},
	date = {2000},
	keywords = {Computer industry, Project management, Software engineering, Economics, Context, Collaborative software, Communication effectiveness, Communication industry, Globalization, Personnel},
}

@article{belliger_knowledge_2018,
	title = {Knowledge Management in Digital Change: New Findings and Practical Cases},
	author = {Belliger, A and Krieger, {DJ} and North, K and Maier, R and Haas, O},
	date = {2018},
	note = {Publisher: Springer International Publishing, Cham},
}

@article{sterz_intelligente_2022,
	title = {Intelligente Verkehrssysteme – {IT}-Sicherheit in offenen Infrastrukturen},
	number = {6},
	journaltitle = {Recht der Datenverarbeitung},
	author = {Sterz, Leonie and Werner, Christoph and Raabe, Oliver},
	date = {2022},
}

@inproceedings{kusumasari_collaboration_2011,
	title = {Collaboration model of software development},
	doi = {10.1109/ICEEI.2011.6021769},
	pages = {1--6},
	booktitle = {Proceedings of the 2011 International Conference on Electrical Engineering and Informatics},
	author = {Kusumasari, Tien Fabrianti and Supriana, Iping and Surendro, Kridanto and Sastramihardja, Husni},
	date = {2011},
	keywords = {software development, collaboration, Face, Programming, Software quality, Software measurement, Software tools, Collaboration, collaboration method, collaboration model, software process},
}

@book{van_scoy_software_1992,
	title = {Software development risk: opportunity, not problem},
	publisher = {Carnegie Mellon University, Software Engineering Institute Pittsburgh, Pa.},
	author = {Van Scoy, Roger L},
	date = {1992},
}

@article{venkatraman_communities_2018,
	title = {Communities of Practice Approach for Knowledge Management Systems},
	volume = {6},
	issn = {2079-8954},
	url = {https://www.mdpi.com/2079-8954/6/4/36},
	doi = {10.3390/systems6040036},
	number = {4},
	journaltitle = {Systems},
	author = {Venkatraman, Sitalakshmi and Venkatraman, Ramanathan},
	date = {2018},
}

@article{verdon_risk_2004,
	title = {Risk analysis in software design},
	volume = {2},
	doi = {10.1109/MSP.2004.55},
	pages = {79--84},
	number = {4},
	journaltitle = {{IEEE} Security \& Privacy},
	author = {Verdon, D. and {McGraw}, G.},
	date = {2004},
	keywords = {Risk analysis, Computer security, Data security, Costs, software development, Hardware, Cryptography, Software design, Probability, abuse cases, Acceleration, Life testing, misuse cases, software design},
}

@inproceedings{zimmermann_reusable_2007,
	title = {Reusable architectural decision models for enterprise application development},
	pages = {15--32},
	booktitle = {Software Architectures, Components, and Applications: Third International Conference on Quality of Software Architectures, {QoSA} 2007, Medford, {MA}, {USA}, July 11-23, 2007, Revised Selected Papers 3},
	publisher = {Springer},
	author = {Zimmermann, Olaf and Gschwind, Thomas and Küster, Jochen and Leymann, Frank and Schuster, Nelly},
	date = {2007},
}

@misc{bundeskriminalamt_cybercrime_2021,
	title = {Cybercrime Bundeslagebild},
	url = {https://www.bka.de/SharedDocs/Downloads/DE/Publikationen/JahresberichteUndLagebilder/Cybercrime/cybercrimeBundeslagebild2021.html?nn=28110},
	author = {{Bundeskriminalamt}},
	urldate = {2023-05-30},
	date = {2021-05-09},
}

@article{brooke_usability_1996,
	title = {Usability evaluation in industry},
	author = {Brooke, John and Jordan, Patrick W and Thomas, Bruce and Weerdmeester, Bernard A and {McClelland}, {IL}},
	date = {1996},
	note = {Publisher: Taylor \& Francis, London, {UK}},
}

@article{lewis_system_2018,
	title = {The system usability scale: past, present, and future},
	volume = {34},
	doi = {10.1080/10447318.2018.1455307},
	pages = {577--590},
	number = {7},
	journaltitle = {International Journal of Human–Computer Interaction},
	author = {Lewis, James R},
	date = {2018},
	note = {Publisher: Taylor \& Francis},
}

@inproceedings{colesky_system_2018,
	title = {A System of Privacy Patterns for Informing Users: Creating a Pattern System},
	doi = {10.1145/3282308.3282325},
	series = {{EuroPLoP} '18},
	booktitle = {Proceedings of the 23rd European Conference on Pattern Languages of Programs},
	author = {Colesky, Michael and Caiza, Julio C.},
	date = {2018},
}

@inproceedings{colesky_system_2018-1,
	title = {A system of privacy patterns for user control},
	doi = {10.1145/3167132.3167257},
	series = {{SAC} '18},
	pages = {1150--1156},
	booktitle = {Proceedings of the 33rd Annual {ACM} Symposium on Applied Computing},
	author = {Colesky, Michael and {others}},
	date = {2018},
}

@inproceedings{hahner_arcn_2024,
	title = {{ARC}³N: A Collaborative Uncertainty Catalog to Address the Awareness Problem of Model-Based Confidentiality Analysis},
	doi = {10.1145/3652620.3688556},
	eventtitle = {{ACM}/{IEEE} 27th International Conference on Model Driven Engineering Languages and Systems},
	booktitle = {{ACM}/{IEEE} 27th International Conference on Model Driven Engineering Languages and Systems ({MODELS} Companion '24)},
	publisher = {{ACM}},
	author = {Hahner, Sebastian and Niehues, Nils and Boltz, Nicolas and Fuksa, Mario and Heinrich, Robert},
	date = {2024},
	langid = {english},
}

@collection{rausch_common_2008,
	location = {Berlin, Heidelberg},
	title = {The Common Component Modeling Example: Comparing Software Component Models},
	volume = {5153},
	url = {http://link.springer.com/10.1007/978-3-540-85289-6},
	series = {Lecture Notes in Computer Science},
	shorttitle = {The Common Component Modeling Example},
	publisher = {Springer Berlin Heidelberg},
	editor = {Rausch, Andreas and Reussner, Ralf and Mirandola, Raffaela and Plášil, František},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2024-06-11},
	date = {2008},
	langid = {english},
}

@article{kephart_vision_2003,
	title = {The vision of autonomic computing},
	volume = {36},
	issn = {1558-0814},
	url = {https://ieeexplore.ieee.org/document/1160055},
	doi = {10.1109/MC.2003.1160055},
	abstract = {A 2001 {IBM} manifesto observed that a looming software complexity crisis -caused by applications and environments that number into the tens of millions of lines of code - threatened to halt progress in computing. The manifesto noted the almost impossible difficulty of managing current and planned computing systems, which require integrating several heterogeneous environments into corporate-wide computing systems that extend into the Internet. Autonomic computing, perhaps the most attractive approach to solving this problem, creates systems that can manage themselves when given high-level objectives from administrators. Systems manage themselves according to an administrator's goals. New components integrate as effortlessly as a new cell establishes itself in the human body. These ideas are not science fiction, but elements of the grand challenge to create self-managing computing systems.},
	pages = {41--50},
	number = {1},
	journaltitle = {Computer},
	author = {Kephart, J.O. and Chess, D.M.},
	urldate = {2024-06-17},
	date = {2003},
	note = {Conference Name: Computer},
	keywords = {Computer industry, Internet, Technological innovation, Environmental management, Pervasive computing, Humans, Biology computing, Computer vision, Crisis management, {LAN} interconnection},
}

@book{dijkstra_notes_1970,
	edition = {Second edition},
	title = {Notes on structured programming},
	series = {T.H. - Report 70-{WSK}-03},
	author = {Dijkstra, Edsger W.},
	date = {1970},
}

@book{object_management_group_precise_2024,
	title = {Precise Semantics for Uncertainty Modeling ({PSUM})},
	volume = {1},
	url = {https://www.omg.org/spec/PSUM/1.0/Beta2/PDF},
	author = {Object Management Group},
	date = {2024},
	langid = {english},
}

@inproceedings{boltz_model-based_2022,
	title = {A Model-Based Framework for Simplified Collaboration of Legal and Software Experts in Data Protection Assessments},
	isbn = {978-3-88579-720-3},
	url = {https://dl.gi.de/handle/20.500.12116/39544},
	abstract = {The protection of personal data has become an increasingly important issue. Legal norms focused on data protection, such as the {GDPR}, provide legally binding requirements for systems that process personal data. Article 25 of the {GDPR} refers to the obligation to Data Protection by Design and Default. This can be achieved by conducting {DPLA} of the system in the early stages of development and implementing data protection concepts where necessary. This ties in with Article 35, which refers to an obligation to conduct {DPLA} before the actual processing of data. To aid in conducting continuous {DPLA} during the design time of software systems, we propose a model-based collaboration framework. This framework not only aids in providing consistent views of the software system for legal experts and software architects but also simplifies communication between both parties. We discuss the overall goals and benefits of such a framework and go into detail about the processes that interact as part of the framework. We also try to align legal concepts with the processes and describe the continuous iterative development using the collaboration framework.},
	eventtitle = {{INFORMATIK} 2022},
	pages = {521--532},
	publisher = {Gesellschaft für Informatik, Bonn},
	author = {Boltz, Nicolas and Sterz, Leonie and Gerking, Christopher and Raabe, Oliver},
	urldate = {2024-07-02},
	date = {2022},
	langid = {english},
}

@online{reussner_palladio_2024,
	title = {The Palladio Approach},
	url = {https://www.palladio-simulator.com/},
	titleaddon = {Modeling and Simulating Software Architectures},
	author = {Reussner, Ralf},
	urldate = {2024-07-11},
	date = {2024},
	langid = {english},
}

@book{martin_clean_2017,
	location = {Boston, {MA}},
	title = {Clean Architecture: A Craftsman's Guide to Software Structure and Design},
	series = {Robert C. Martin Series},
	publisher = {Prentice Hall},
	author = {Martin, Robert C.},
	date = {2017},
	keywords = {01841 103 book safari software architecture development},
}

@thesis{stengel_verfeinerung_2021,
	title = {Verfeinerung von Zugriffskontrollrichtlinien unter Berücksichtigung von Ungewissheit in der Entwurfszeit},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Master's Thesis},
	author = {Stengel, Daniel},
	date = {2021},
}

@book{knuth_art_1997,
	location = {{USA}},
	title = {The art of computer programming, volume 1 (3rd ed.): fundamental algorithms},
	isbn = {0-201-89683-4},
	publisher = {Addison Wesley Longman Publishing Co., Inc.},
	author = {Knuth, Donald E.},
	date = {1997},
}

@book{diestel_graph_2017,
	location = {Berlin, Heidelberg},
	title = {Graph Theory},
	volume = {173},
	url = {https://link.springer.com/10.1007/978-3-662-53622-3},
	series = {Graduate Texts in Mathematics},
	publisher = {Springer Berlin Heidelberg},
	author = {Diestel, Reinhard},
	urldate = {2024-07-17},
	date = {2017},
	langid = {english},
	doi = {10.1007/978-3-662-53622-3},
}

@inproceedings{camara_software_2020,
	location = {New York, {NY}, {USA}},
	title = {Software architecture and task plan co-adaptation for mobile service robots},
	isbn = {978-1-4503-7962-5},
	url = {https://doi.org/10.1145/3387939.3391591},
	doi = {10.1145/3387939.3391591},
	series = {{SEAMS} '20},
	abstract = {Self-adaptive systems increasingly need to reason about and adapt both structural and behavioral system aspects, such as in mobile service robots, which must reason about missions that they need to achieve and the architecture of the software executing them. Deciding how to best adapt these systems to run time changes is challenging because it entails considering mutual dependencies between the software architecture that the system is running and the outcome of plans for completing tasks, while also considering multiple trade-offs and uncertainties. Considering all these aspects in planning for adaptation often yields large solution spaces which cannot be adequately explored at run time. We address this challenge by proposing a planning approach able to consider the impact of mutual dependencies between software architecture and task planning on the satisfaction of mission goals. The approach is able to reason quantitatively about the outcome of adaptation decisions handling both the reconfiguration of the system's architecture and adaptation of task plans under uncertainty and in a rich trade-off space. Our results show: (i) feasibility of run-time decision-making for self-adaptation in an otherwise intractable solution space by dividing-and-conquering adaptation into architecture reconfiguration and task planning sub-problems, and (ii) improved quality of adaptation decisions with respect to decision making that does not consider dependencies between architecture and task planning.},
	pages = {125--136},
	booktitle = {Proceedings of the {IEEE}/{ACM} 15th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
	publisher = {Association for Computing Machinery},
	author = {Cámara, Javier and Schmerl, Bradley and Garlan, David},
	urldate = {2024-07-18},
	date = {2020-09-18},
}

@book{klir_fuzzy_1995,
	title = {Fuzzy sets and fuzzy logic},
	volume = {4},
	publisher = {Prentice hall New Jersey},
	author = {Klir, George and Yuan, Bo},
	date = {1995},
}

@inproceedings{taghavi_survey_2023,
	title = {A Survey of Analysis Composition Operators in the Context of Palladio},
	url = {https://dl.gi.de/handle/20.500.12116/43245},
	abstract = {Model-Based Analysis is an approach in Model-Driven Engineering that uses models to systematically analyze a system for structure, behavior, or quality characteristics. Due to the complexity and interdependence of modern systems, individual analysis approaches need to be combined to meet a specific purpose and achieve complete analysis. This paper provides an overview of current analysis composition operators in the context of Palladio, along with examples of how they are used. The objective is to define some criteria that aid in the judicious selection of the most fitting operator for distinct scenarios.},
	eventtitle = {Softwaretechnik-Trends Band 43, Heft 4},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Taghavi, Bahareh and Weber, Sebastian},
	urldate = {2024-07-24},
	date = {2023},
	langid = {english},
}

@inproceedings{busch_modelling_2016,
	title = {Modelling the Structure of Reusable Solutions for Architecture-Based Quality Evaluation},
	url = {https://ieeexplore.ieee.org/abstract/document/7830732},
	doi = {10.1109/CloudCom.2016.0091},
	abstract = {When designing cloud applications many decisions must be made like the selection of the right set of software components. Often, there are several third-party implementations on the market from which software architects have the choice between several solutions that are functionally very similar. Even though they are comparable in functionality, the solutions differ in their quality attributes, and in their software architecture. This diversity hinders automated decision support in model-driven engineering approaches, since current state-of-the-art approaches for automated quality estimation often rely on similar architectures to compare several solutions. In this paper, we address this problem by contributing with a metamodel that unifies the architecture of several functional similar solutions, and describes the different solutions' architectural degrees of freedom. Such a model can be used later to extend the process of reuse from reusing libraries to reusing the corresponding models of these libraries with the lasting benefit of automated decision support at design-time that supports decisions when deploying applications into the cloud. Finally, we apply our approach on two intrusion detection systems.},
	eventtitle = {2016 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	pages = {521--526},
	booktitle = {2016 {IEEE} International Conference on Cloud Computing Technology and Science ({CloudCom})},
	author = {Busch, Axel and Schneider, Yves and Koziolek, Anne and Rostami, Kiana and Kienzle, Jörg},
	urldate = {2024-07-26},
	date = {2016-12},
	keywords = {Computer architecture, Software, Unified modeling language, Analytical models, Biological system modeling, Reuse, Phase change materials, Cloud, Architecture, Model, Concern, Decision support, Media, Quality, Solutions, Structure},
}

@article{roblek_complex_2016,
	title = {A Complex View of Industry 4.0},
	volume = {6},
	issn = {2158-2440},
	url = {https://doi.org/10.1177/2158244016653987},
	doi = {10.1177/2158244016653987},
	abstract = {This article is focused on the importance and influence of Industry 4.0 and consequently the Internet-connected technologies for the creation of value added for organizations and society. The contribution of the article is mainly conceptual. With the development of the Internet, the Internet of things that is central to the new industrial revolution has led to “Industry 4.0.” The aim of this article is to synthesize the known theory and practices of Industry 4.0, and to investigate the changes that will result from Industry 4.0 and with the development of the Internet of things.},
	pages = {2158244016653987},
	number = {2},
	journaltitle = {Sage Open},
	author = {Roblek, Vasja and Meško, Maja and Krapež, Alojz},
	urldate = {2024-07-30},
	date = {2016-04-01},
	langid = {english},
	note = {Publisher: {SAGE} Publications},
}

@inproceedings{kjaergaard_indoor_2010,
	location = {Berlin, Heidelberg},
	title = {Indoor Positioning Using {GPS} Revisited},
	isbn = {978-3-642-12654-3},
	doi = {10.1007/978-3-642-12654-3_3},
	abstract = {It has been considered a fact that {GPS} performs too poorly inside buildings to provide usable indoor positioning. We analyze results of a measurement campaign to improve on the understanding of indoor {GPS} reception characteristics. The results show that using state-of-the-art receivers {GPS} availability is good in many buildings with standard material walls and roofs. The measured root mean squared 2D positioning error was below five meters in wooden buildings and below ten meters in most of the investigated brick and concrete buildings. Lower accuracies, where observed, can be linked to either low signal-to-noise ratios, multipath phenomena or bad satellite constellation geometry. We have also measured the indoor performance of embedded {GPS} receivers in mobile phones which provided lower availability and accuracy than state-of-the-art ones. Finally, we consider how the {GPS} performance within a given building is dependent on local properties like close-by building elements and materials, number of walls, number of overlaying stories and surrounding buildings.},
	pages = {38--56},
	booktitle = {Pervasive Computing},
	publisher = {Springer},
	author = {Kjærgaard, Mikkel Baun and Blunck, Henrik and Godsk, Torben and Toftkjær, Thomas and Christensen, Dan Lund and Grønbæk, Kaj},
	editor = {Floréen, Patrik and Krüger, Antonio and Spasojevic, Mirjana},
	date = {2010},
	langid = {english},
	keywords = {Building Element, Cold Start, Global Navigation Satellite System, Shopping Mall},
}

@inproceedings{hengartner_distributed_2007,
	title = {Distributed, Uncertainty-Aware Access Control for Pervasive Computing},
	url = {https://ieeexplore.ieee.org/abstract/document/4144833},
	doi = {10.1109/PERCOMW.2007.39},
	abstract = {Access control to sensitive resources in pervasive computing needs to take uncertainty into account. Previous research has developed uncertainty-aware access-control models for environments that are managed by a centralized administrator. We demonstrate that environments managed in a distributed way require a more powerful model. Furthermore, we point out additional challenges that need to be considered when deploying uncertainty-aware access control, namely, identifying and authenticating both people and their intended actions, associating uncertainty with time, providing monotonicity, and defending against Sybil attacks. We present an access-control model that addresses these challenges and discuss a sample implementation},
	eventtitle = {Fifth Annual {IEEE} International Conference on Pervasive Computing and Communications Workshops ({PerComW}'07)},
	pages = {241--246},
	booktitle = {Fifth Annual {IEEE} International Conference on Pervasive Computing and Communications Workshops ({PerComW}'07)},
	author = {Hengartner, Urs and Zhong, Ge},
	urldate = {2024-07-30},
	date = {2007-03},
	keywords = {Uncertainty, Access control, Authentication, security of data, Computer science, Cellular phones, centralized administrator, Context-aware services, Energy management, Environmental management, pervasive computing, Pervasive computing, Sybil attacks, ubiquitous computing, uncertain systems, uncertainty-aware access control},
}

@report{kramer_model-driven_2017,
	title = {Model-Driven Specification and Analysis of Confidentiality in Component-Based Systems},
	url = {https://doi.org/10.5445/IR/1000076957},
	abstract = {Many software systems have to be designed and developed in a way that guarantees that specific information remains confidential with respect to considered adversaries. Such guarantees depend on the internal information flow inside individual components and the system architecture, e.g., the deployment on hardware nodes and properties of their communication links. Therefore, we propose a novel architecture-driven approach for specifying and analyzing the confidentiality of information processed by component-based systems. It includes an architectural analysis that is able to infer leaks of confidential information from abstract architecture models, adversary models, and confidentiality specifications. Our approach supports re-usability of components and specification parts across systems as well as specifications with custom labels, e.g., accessibility of hardware and service interfaces. Additionally, our information flow specifications for components are compositional and supported by tools for non-interference verification on source code level. In two case studies, we show how our specification approach is applied and how the architectural analysis is able to detect information leaks of a system in an early design phase.},
	author = {Kramer, Max E. and Hecker, Martin and Greiner, Simon and Bao, Kaibin and Yurchenko, Kateryna},
	urldate = {2024-08-07},
	date = {2017},
	langid = {german},
}

@inproceedings{walter_tool-based_2023,
	location = {Cham},
	title = {Tool-Based Attack Graph Estimation and Scenario Analysis for Software Architectures},
	isbn = {978-3-031-36889-9},
	doi = {10.1007/978-3-031-36889-9_5},
	abstract = {With the increase of connected systems and the ongoing digitalization of various aspects of our life, the security demands for software increase. Software architects should design a secure and resistant system. One solution can be the identification of attack paths or the usage of an access control policy analysis. However, due to the system complexity identifying an attack path or analyzing access control policies is hard. Current attack path calculation approaches, often only focus on the network topology and do not consider the more fine-grained information a software architecture can provide, such as the components or deployment. In addition, the impact of access control policies for a given scenario is unclear. We developed an open-source attack propagation tool, which can calculate an attack graph based on the software architecture. This tool could help software architects to identify potential critical attack paths. Additionally, we extended the used access control metamodel to support a scenario-based access control analysis.},
	pages = {45--61},
	booktitle = {Software Architecture. {ECSA} 2022 Tracks and Workshops},
	publisher = {Springer International Publishing},
	author = {Walter, Maximilian and Reussner, Ralf},
	editor = {Batista, Thais and Bures, Tomas and Raibulet, Claudia and Muccini, Henry},
	date = {2023},
	langid = {english},
	keywords = {Security, Software Architecture, Attack Propagation},
}

@incollection{leinweber_leveraging_2023,
	location = {Wiesbaden},
	title = {Leveraging Distributed Ledger Technology for Decentralized Mobility-as-a-Service Ticket Systems},
	isbn = {978-3-658-39438-7},
	url = {https://doi.org/10.1007/978-3-658-39438-7_32},
	abstract = {Mobility-as-A-Service ({MaaS}) is a concept for combining different transport modes, including diverse mobility services, while facilitating their use through customer centricity (e.g., pay-as-you-go tariffs, unified interfaces). {MaaS} platforms offer access to different mobility services of various providers via {MaaS} ticket systems. {IT} governance of current ticket systems is largely assigned to central organizations that guide decisions on the ticket system design, modalities, and the participation of mobility providers. Mobility providers depend on decisions of system providers, which can cause discrimination of competitors in {MaaS} ticket systems and limit flexibility for customers. By distributing decision rights to multiple mobility providers, {IT} governance for {MaaS} ticket systems can be decentralized so that dependencies on single providers are reduced.},
	pages = {547--567},
	booktitle = {Towards the New Normal in Mobility: Technische und betriebswirtschaftliche Aspekte},
	publisher = {Springer Fachmedien},
	author = {Leinweber, Marc and Kannengießer, Niclas and Hartenstein, Hannes and Sunyaev, Ali},
	editor = {Proff, Heike},
	urldate = {2024-08-07},
	date = {2023},
	langid = {german},
	doi = {10.1007/978-3-658-39438-7_32},
	keywords = {Blockchain, Decentralized Systems, Distributed Ledger Technology ({DLT}), Mobility-as-a-Service ({MaaS}), Trusted Execution Environments ({TEEs})},
}

@article{prechelt_finding_2002,
	title = {Finding plagiarisms among a set of programs with {JPlag}},
	volume = {8},
	number = {11},
	journaltitle = {Journal of Universal Computer Science},
	author = {Prechelt, Lutz and Malpohl, Guido and Philippsen, Michael and {others}},
	date = {2002},
}

@inproceedings{baumgartner_mind_2020,
	title = {Mind the {GAP}: Security \& Privacy Risks of Contact Tracing Apps},
	url = {https://ieeexplore.ieee.org/abstract/document/9342982},
	doi = {10.1109/TrustCom50675.2020.00069},
	shorttitle = {Mind the {GAP}},
	abstract = {Google and Apple have jointly provided an {API} for exposure notification in order to implement decentralized contract tracing apps using Bluetooth Low Energy, the so-called “Google/Apple Proposal”, which we abbreviate by “{GAP}”. We demonstrate that in real-world scenarios the current {GAP} design is vulnerable to (i) profiling and possibly de-anonymizing infected persons, and (ii) relay-based wormhole attacks that basically can generate fake contacts with the potential of affecting the accuracy of an app-based contact tracing system. For both types of attack, we have built tools that can easily be used on mobile phones or Raspberry Pis (e.g., Bluetooth sniffers). The goal of our work is to perform a reality check towards possibly providing empirical real-world evidence for these two privacy and security risks. We hope that our findings provide valuable input for developing secure and privacy-preserving digital contact tracing systems.},
	eventtitle = {2020 {IEEE} 19th International Conference on Trust, Security and Privacy in Computing and Communications ({TrustCom})},
	pages = {458--467},
	booktitle = {2020 {IEEE} 19th International Conference on Trust, Security and Privacy in Computing and Communications ({TrustCom})},
	author = {Baumgärtner, Lars and Dmitrienko, Alexandra and Freisleben, Bernd and Gruler, Alexander and Höchst, Jonas and Kühlberg, Joshua and Mezini, Mira and Mitev, Richard and Miettinen, Markus and Muhamedagic, Anel and Nguyen, Thien Duc and Penning, Alvar and Pustelnik, Dermot and Roos, Filipp and Sadeghi, Ahmad-Reza and Schwarz, Michael and Uhl, Christian},
	urldate = {2024-08-13},
	date = {2020-12},
	keywords = {Security, Internet, Privacy, Mobile handsets, Tools, Bluetooth, contact tracing apps, exposure notification {API}, Faces},
}

@online{saglam_jplag_2024,
	title = {{JPlag}: State-of-the-Art Software Plagiarism \& Collusion Detection},
	url = {https://github.com/jplag/jplag},
	author = {Sağlam, Timur and Hahner, Sebastian and Fuchß, Dominik and Schmid, Larissa},
	urldate = {2024-08-14},
	date = {2024},
}

@inproceedings{ananieva_conceptual_2020,
	location = {New York, {NY}, {USA}},
	title = {A conceptual model for unifying variability in space and time},
	isbn = {978-1-4503-7569-6},
	url = {https://dl.acm.org/doi/10.1145/3382025.3414955},
	doi = {10.1145/3382025.3414955},
	series = {{SPLC} '20},
	abstract = {Software engineering faces the challenge of developing and maintaining systems that are highly variable in space (concurrent variations of the system at a single point in time) and time (sequential variations of the system due to its evolution). Recent research aims to address this need by managing variability in space and time simultaneously. However, such research often relies on nonuniform terminologies and a varying understanding of concepts, as it originates from different communities: software product-line engineering and software configuration management. These issues complicate the communication and comprehension of the concepts involved, impeding the development of techniques to unify variability in space and time. To tackle this problem, we performed an iterative, expert-driven analysis of existing tools to derive the first conceptual model that integrates and unifies terminologies and concepts of both dimensions of variability. In this paper, we present the unification process of concepts for variability in space and time, and the resulting conceptual model itself. We show that the conceptual model achieves high coverage and that its concepts are of appropriate granularity with respect to the tools for managing variability in space, time, or both that we considered. The conceptual model provides a well-defined, uniform terminology that empowers researchers and developers to compare their work, clarifies communication, and prevents redundant developments.},
	pages = {1--12},
	booktitle = {Proceedings of the 24th {ACM} Conference on Systems and Software Product Line: Volume A - Volume A},
	publisher = {Association for Computing Machinery},
	author = {Ananieva, Sofia and Greiner, Sandra and Kühn, Thomas and Krüger, Jacob and Linsbauer, Lukas and Grüner, Sten and Kehrer, Timo and Klare, Heiko and Koziolek, Anne and Lönn, Henrik and Krieter, Sebastian and Seidl, Christoph and Ramesh, S. and Reussner, Ralf and Westfechtel, Bernhard},
	urldate = {2024-08-20},
	date = {2020},
}

@article{bedford_evaluating_2013,
	title = {Evaluating classification schema and classification decisions},
	volume = {39},
	issn = {1550-8366},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bult.2013.1720390206},
	doi = {10.1002/bult.2013.1720390206},
	abstract = {Editor's Summary Direction on the construction and application of classification schemes such as taxonomies is readily available, but relatively little has been offered on evaluating the schemes themselves and their use to categorize content. A classification scheme can be judged for how well it meets its purpose and complies with standards, and a strong evaluative framework is reflected in S.R. Ranganathan's principles of classification. The degree of certainty of classification decisions depends on objective understanding of the object to be classified, the scope and details of the class and the coverage and organization of the overall classification scheme. The more complete the information about each class, the more reliable the goodness- of-fit for an object to a class is likely to be, whether chosen by human or machine classifiers. This information comes through definitions, examples, prior use and semantic relationships. The risk of misclassification can be reduced by analyzing the goodness-of-fit of objects to classes and the patterns of missed or erroneous selections.},
	pages = {13--21},
	number = {2},
	journaltitle = {Bulletin of the American Society for Information Science and Technology},
	author = {Bedford, Denise},
	urldate = {2024-08-20},
	date = {2013},
	langid = {english},
}

@book{van_rijsbergen_information_1979,
	location = {London},
	edition = {2},
	title = {Information Retrieval},
	publisher = {Butterworths},
	author = {van Rijsbergen, C. J.},
	date = {1979},
}

@thesis{gehrig_enabling_2023,
	title = {Enabling the Collaborative Collection of Uncertainty Sources Regarding Confidentiality},
	url = {https://doi.org/10.5445/IR/1000164576},
	pagetotal = {56},
	institution = {Karlsruher Institut für Technologie ({KIT})},
	type = {Bachelor's Thesis},
	author = {Gehrig, Gabriel},
	date = {2023},
}

@inproceedings{boltz_modeling_2024,
	location = {Cham},
	title = {Modeling and Analyzing Zero Trust Architectures Regarding Performance and Security},
	isbn = {978-3-031-70797-1},
	doi = {10.1007/978-3-031-70797-1_17},
	abstract = {Zero Trust is considered a powerful strategy for securing systems by emphasizing distrust of all resource access requests. There are different approaches to integrating {ZTAs} into a system, differing in their components, assembly, and allocation. Early evaluation and selection of the right approach can reduce the costs of resources. In this paper, we propose a novel zero trust architecture ({ZTA}) metamodel based on literature and industry applications. We introduce our proposed metamodel elements and provide a model instance using the Palladio Component Model ({PCM}). We describe the requirements for enabling two existing approaches to performance simulation and security data flow analysis on the architectural level and outline how we realize them in our {PCM}-based implementation. Our evaluation demonstrates the applicability of our {ZTA} metamodel. It can represent real-world {ZTA} approaches in various domains, enabling the simulation of performance impact and analysis of the correct implementation of zero trust principles at the architectural level.},
	pages = {253--269},
	booktitle = {Software Architecture},
	publisher = {Springer Nature Switzerland},
	author = {Boltz, Nicolas and Schmid, Larissa and Taghavi, Bahareh and Gerking, Christopher and Heinrich, Robert},
	editor = {Galster, Matthias and Scandurra, Patrizia and Mikkonen, Tommi and Oliveira Antonino, Pablo and Nakagawa, Elisa Yumi and Navarro, Elena},
	date = {2024},
	langid = {english},
}

@incollection{bauer_encryption_2005,
	location = {Boston, {MA}},
	title = {Encryption},
	isbn = {978-0-387-23483-0},
	url = {https://doi.org/10.1007/0-387-23483-7_141},
	pages = {202--202},
	booktitle = {Encyclopedia of Cryptography and Security},
	publisher = {Springer {US}},
	author = {Bauer, Friedrich L.},
	editor = {van Tilborg, Henk C. A.},
	urldate = {2024-09-09},
	date = {2005},
	langid = {english},
	doi = {10.1007/0-387-23483-7_141},
}

@book{stahl_model-driven_2006,
	location = {Hoboken, {NJ}, {USA}},
	title = {Model-Driven Software Development: Technology, Engineering, Management},
	isbn = {0-470-02570-0},
	publisher = {John Wiley \& Sons, Inc.},
	author = {Stahl, Thomas and Voelter, Markus and Czarnecki, Krzysztof},
	date = {2006},
}

@book{steinberg_emf_2008,
	title = {{EMF}: Eclipse Modeling Framework},
	publisher = {Pearson Education},
	author = {Steinberg, Dave and Budinsky, Frank and Merks, Ed and Paternostro, Marcelo},
	date = {2008},
}

@misc{omg_about_2016,
	title = {About the Meta Object Facility Specification Version 2.5.1},
	url = {https://www.omg.org/spec/MOF},
	author = {{OMG}},
	urldate = {2024-09-10},
	date = {2016},
}

@report{international_organization_for_standardization_isoiecieee_2022,
	title = {{ISO}/{IEC}/{IEEE} 42010:2022 Software, systems and enterprise - Architecture description},
	type = {Standard},
	author = {{International Organization for Standardization}},
	date = {2022},
}

@thesis{pilipchuk_architectural_2021,
	title = {Architectural Alignment of Access Control Requirements Extracted from Business Processes},
	url = {https://doi.org/10.5445/IR/1000140856},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Dissertation},
	author = {Pilipchuk, Roman},
	date = {2021},
	langid = {german},
}

@book{bang-jensen_digraphs_2009,
	location = {London},
	title = {Digraphs},
	url = {http://link.springer.com/10.1007/978-1-84800-998-1},
	series = {Springer Monographs in Mathematics},
	publisher = {Springer London},
	author = {Bang-Jensen, Jørgen and Gutin, Gregory Z.},
	urldate = {2024-09-10},
	date = {2009},
	langid = {english},
}

@inproceedings{aleti_archeopterix_2009,
	title = {{ArcheOpterix}: An extendable tool for architecture optimization of {AADL} models},
	url = {https://ieeexplore.ieee.org/abstract/document/5069138},
	doi = {10.1109/MOMPES.2009.5069138},
	shorttitle = {{ArcheOpterix}},
	abstract = {For embedded systems quality requirements are equally if not even more important than functional requirements. The foundation for the fulfillment of these quality requirements has to be set in the architecture design phase. However, finding a suitable architecture design is a difficult task for software and system architects. Some of the reasons for this are an ever-increasing complexity of today's systems, strict design constraints and conflicting quality requirements. To simplify the task, this paper presents an extendable Eclipse-based tool, called {ArcheOpterix}, which provides a framework to implement evaluation techniques and optimization heuristics for {AADL} specifications. Currently, evolutionary strategies have been implemented to identify optimized deployment architectures with respect to multiple quality objectives and design constraints. Experiments with a set of initial deployment architectures provide evidence that the tool can successfully find architecture specifications with better quality.},
	eventtitle = {2009 {ICSE} Workshop on Model-Based Methodologies for Pervasive and Embedded Software},
	pages = {61--71},
	booktitle = {2009 {ICSE} Workshop on Model-Based Methodologies for Pervasive and Embedded Software},
	author = {Aleti, Aldeida and Bjornander, Stefan and Grunske, Lars and Meedeniya, Indika},
	urldate = {2024-09-17},
	date = {2009-05},
	keywords = {Computer architecture, Costs, Software systems, Automotive engineering, Software quality, Algorithm design and analysis, Software safety, {AADL}, {ArcheOpterix}, Architecture and Deployment Architecture Optimization, Design optimization, Embedded system, Evolutionary Algorithms, Multi-Objective and Pareto Optimization, Pareto optimization},
}

@article{snelting_checking_2014,
	title = {Checking probabilistic noninterference using {JOANA}},
	volume = {56},
	pages = {280--287},
	number = {6},
	journaltitle = {it - Information Technology},
	author = {Snelting, Gregor and Giffhorn, Dennis and Graf, Jürgen and Hammer, Christian and Hecker, Martin and Mohr, Martin and Wasserrab, Daniel},
	date = {2014},
}

@book{ahrendt_deductive_2016,
	title = {Deductive software verification–the key book},
	publisher = {Springer},
	author = {Ahrendt, Wolfgang and Beckert, Bernhard and Bubel, Richard and Hähnle, Reiner and Schmitt, Peter H and Ulbrich, Mattias},
	date = {2016},
	doi = {10.1007/978-3-319-49812-6},
}

@inproceedings{shull_what_2002,
	title = {What we have learned about fighting defects},
	pages = {249--258},
	booktitle = {{METRICS}},
	author = {Shull, F. and Basili, V. and Boehm, B. and Brown, A.W. and Costa, P. and Lindvall, M. and Port, D. and Rus, I. and Tesoriero, R. and Zelkowitz, M.},
	date = {2002},
}

@inproceedings{cuppens_modelling_2003,
	title = {Modelling contexts in the Or-{BAC} model},
	url = {https://ieeexplore.ieee.org/abstract/document/1254346},
	doi = {10.1109/CSAC.2003.1254346},
	abstract = {As computer infrastructures become more complex, security models must provide means to handle more flexible and dynamic requirements. In the organization based access control (Or-{BAC}) model, it is possible to express such requirements using the notion of context. In Or-{BAC}, each privilege (permission or obligation or prohibition) only applies in a given context. A context is viewed as an extra condition that must be satisfied to activate a given privilege. We present a taxonomy of different types of context and investigate the data the information system must manage in order to deal with these different contexts. We then explain how to model them in the Or-{BAC} model.},
	eventtitle = {19th Annual Computer Security Applications Conference, 2003. Proceedings.},
	pages = {416--425},
	booktitle = {19th Annual Computer Security Applications Conference, 2003. Proceedings.},
	author = {Cuppens, F. and Miege, A.},
	urldate = {2024-09-17},
	date = {2003-12},
	keywords = {Taxonomy, Access control, Computer architecture, Computer security, Application software, Permission, Resource management, Management information systems, Context modeling, Information management},
}

@thesis{liu_design_2021,
	title = {Design Space Evaluation for Confidentiality under Architectural Uncertainty},
	url = {https://doi.org/10.5445/IR/1000139590},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Bachelor's Thesis},
	author = {Liu, Oliver},
	date = {2021},
	langid = {english},
}

@incollection{weyns_patterns_2013,
	location = {Berlin, Heidelberg},
	title = {On Patterns for Decentralized Control in Self-Adaptive Systems},
	isbn = {978-3-642-35813-5},
	url = {https://doi.org/10.1007/978-3-642-35813-5_4},
	abstract = {Self-adaptation is typically realized using a control loop. One prominent approach for organizing a control loop in self-adaptive systems is by means of four components that are responsible for the primary functions of self-adaptation: Monitor, Analyze, Plan, and Execute, together forming a {MAPE} loop. When systems are large, complex, and heterogeneous, a single {MAPE} loop may not be sufficient for managing all adaptation in a system, so multiple {MAPE} loops may be introduced. In self-adaptive systems with multiple {MAPE} loops, decisions about how to decentralize each of the {MAPE} functions must be made. These decisions involve how and whether the corresponding functions from multiple loops are to be coordinated (e.g., planning components coordinating to prepare a plan for an adaptation). To foster comprehension of self-adaptive systems with multiple {MAPE} loops and support reuse of known solutions, it is crucial that we document common design approaches for engineers. As such systematic knowledge is currently lacking, it is timely to reflect on these systems to: (a) consolidate the knowledge in this area, and (b) to develop a systematic approach for describing different types of control in self-adaptive systems. We contribute with a simple notation for describing interacting {MAPE} loops, which we believe helps in achieving (b), and we use this notation to describe a number of existing patterns of interacting {MAPE} loops, to begin to fulfill (a). From our study, we outline numerous remaining research challenges in this area.},
	pages = {76--107},
	booktitle = {Software Engineering for Self-Adaptive Systems {II}: International Seminar, Dagstuhl Castle, Germany, October 24-29, 2010 Revised Selected and Invited Papers},
	publisher = {Springer},
	author = {Weyns, Danny and Schmerl, Bradley and Grassi, Vincenzo and Malek, Sam and Mirandola, Raffaela and Prehofer, Christian and Wuttke, Jochen and Andersson, Jesper and Giese, Holger and Göschka, Karl M.},
	editor = {de Lemos, Rogério and Giese, Holger and Müller, Hausi A. and Shaw, Mary},
	urldate = {2024-09-17},
	date = {2013},
	langid = {english},
	keywords = {Control Loop, {MAPE} Component, {MAPE} Loop, {MAPE} Pattern, Service Level Agreement},
}

@incollection{andersson_modeling_2009,
	location = {Berlin, Heidelberg},
	title = {Modeling Dimensions of Self-Adaptive Software Systems},
	isbn = {978-3-642-02161-9},
	url = {https://doi.org/10.1007/978-3-642-02161-9_2},
	abstract = {It is commonly agreed that a self-adaptive software system is one that can modify itself at run-time due to changes in the system, its requirements, or the environment in which it is deployed. A cursory review of the software engineering literature attests to the wide spectrum of software systems that are described as self-adaptive. The way self-adaptation is conceived depends on various aspects, such as the users’ requirements, the particular properties of a system, and the characteristics of the environment. In this paper, we propose a classification of modeling dimensions for self-adaptive software systems. Each modeling dimension describes a particular facet of the system that is relevant to self-adaptation. The modeling dimensions provide the engineers with a common set of vocabulary for specifying the self-adaptive properties under consideration and select suitable solutions. We illustrate how the modeling dimensions apply to several application scenarios.},
	pages = {27--47},
	booktitle = {Software Engineering for Self-Adaptive Systems},
	publisher = {Springer},
	author = {Andersson, Jesper and de Lemos, Rogério and Malek, Sam and Weyns, Danny},
	editor = {Cheng, Betty H. C. and de Lemos, Rogério and Giese, Holger and Inverardi, Paola and Magee, Jeff},
	urldate = {2024-09-17},
	date = {2009},
	langid = {english},
	doi = {10.1007/978-3-642-02161-9_2},
	keywords = {Modeling, Dynamic Adaptation, Self-*, Self-Adaptive},
}

@incollection{andersson_software_2013,
	location = {Berlin, Heidelberg},
	title = {Software Engineering Processes for Self-Adaptive Systems},
	isbn = {978-3-642-35813-5},
	url = {https://doi.org/10.1007/978-3-642-35813-5_3},
	abstract = {In this paper, we discuss how for self-adaptive systems some activities that traditionally occur at development-time are moved to run-time. Responsibilities for these activities shift from software engineers to the system itself, causing the traditional boundary between development-time and run-time to blur. As a consequence, we argue how the traditional software engineering process needs to be reconceptualized to distinguish both development-time and run-time activities, and to support designers in taking decisions on how to properly engineer such systems.},
	pages = {51--75},
	booktitle = {Software Engineering for Self-Adaptive Systems {II}: International Seminar, Dagstuhl Castle, Germany, October 24-29, 2010 Revised Selected and Invited Papers},
	publisher = {Springer},
	author = {Andersson, Jesper and Baresi, Luciano and Bencomo, Nelly and de Lemos, Rogério and Gorla, Alessandra and Inverardi, Paola and Vogel, Thomas},
	editor = {de Lemos, Rogério and Giese, Holger and Müller, Hausi A. and Shaw, Mary},
	urldate = {2024-09-17},
	date = {2013},
	langid = {english},
	doi = {10.1007/978-3-642-35813-5_3},
	keywords = {Adaptation Logic, {IEEE} Computer Society, Software Engineer, Software Process, Work Product},
}

@inproceedings{abbas_modeling_2012,
	location = {New York, {NY}, {USA}},
	title = {Modeling variability in product lines using domain quality attribute scenarios},
	isbn = {978-1-4503-1568-5},
	url = {https://dl.acm.org/doi/10.1145/2361999.2362028},
	doi = {10.1145/2361999.2362028},
	series = {{WICSA}/{ECSA} '12},
	abstract = {The concept of variability is fundamental in software product lines and a successful implementation of a product line largely depends on how well domain requirements and their variability are specified, managed, and realized. While developing an educational software product line, we identified a lack of support to specify variability in quality concerns. To address this problem we propose an approach to model variability in quality concerns, which is an extension of quality attribute scenarios. In particular, we propose domain quality attribute scenarios, which extend standard quality attribute scenarios with additional information to support specification of variability and deriving product specific scenarios. We demonstrate the approach with scenarios for robustness and upgradability requirements in the educational software product line.},
	pages = {135--142},
	booktitle = {Proceedings of the {WICSA}/{ECSA} 2012 Companion Volume},
	publisher = {Association for Computing Machinery},
	author = {Abbas, Nadeem and Andersson, Jesper and Weyns, Danny},
	urldate = {2024-09-17},
	date = {2012-08-20},
}

@inproceedings{oster_pairwise_2011,
	location = {New York, {NY}, {USA}},
	title = {Pairwise feature-interaction testing for {SPLs}: potentials and limitations},
	isbn = {978-1-4503-0789-5},
	url = {https://dl.acm.org/doi/10.1145/2019136.2019143},
	doi = {10.1145/2019136.2019143},
	series = {{SPLC} '11},
	shorttitle = {Pairwise feature-interaction testing for {SPLs}},
	abstract = {A fundamental problem of testing Software Product Lines ({SPLs}) is that variability enables the production of a large number of instances and it is difficult to construct and run test cases even for {SPLs} with a small number of variable features. Interacting features is a foundation of a fault model for {SPLs}, where faults are likely to be revealed at execution points where features exchange information with other features or influence one another. Therefore, a test adequacy criterion is to cover as many interactions among different features as possible, thus increasing the probability of finding bugs. Our approach combines a combinatorial designs algorithm for pairwise feature generation with model-based testing to reduce the size of the {SPL} required for comprehensive coverage of interacting features. We implemented our approach and applied it to an {SPL} from the automotive domain provided by one of our industrial partners. The results suggest that with our approach higher coverage of feature interactions is achieved at a fraction of cost when compared with a baseline approach of testing all feature interactions.},
	pages = {1--8},
	booktitle = {Proceedings of the 15th International Software Product Line Conference, Volume 2},
	publisher = {Association for Computing Machinery},
	author = {Oster, Sebastian and Zink, Marius and Lochau, Malte and Grechanik, Mark},
	urldate = {2024-09-17},
	date = {2011-08-21},
}

@inproceedings{patel_feature_2013,
	title = {Feature interaction testing of variability intensive systems},
	url = {https://ieeexplore.ieee.org/abstract/document/6608666},
	doi = {10.1109/PLEASE.2013.6608666},
	abstract = {Testing variability intensive systems is a formidable task due to the combinatorial explosion of feature interactions that result from all variations. We developed and validated an approach of combinatorial test generation using Multi-Perspective Feature Models ({MPFM}). {MPFMs} are a set of feature models created to achieve Separation of Concerns within the model. This approach improves test coverage of variability. Results from an experiment on a real-life case show that up to 37\% of the test effort could be reduced and up to 79\% defects from the live system could be detected. We discuss the learning from this experiment and further research potential in testing variability intensive systems.},
	eventtitle = {2013 4th International Workshop on Product {LinE} Approaches in Software Engineering ({PLEASE})},
	pages = {53--56},
	booktitle = {2013 4th International Workshop on Product {LinE} Approaches in Software Engineering ({PLEASE})},
	author = {Patel, Sachin and Gupta, Priya and Shah, Vipul},
	urldate = {2024-09-17},
	date = {2013-05},
	keywords = {Software, Unified modeling language, Analytical models, Manuals, Solid modeling, Testing, combinatorial testing, feature interaction testing, feature models, Portals, product line testing, separation of concerns, variability modeling},
}

@article{lochau_model-based_2012,
	title = {Model-based pairwise testing for feature interaction coverage in software product line engineering},
	volume = {20},
	issn = {1573-1367},
	url = {https://doi.org/10.1007/s11219-011-9165-4},
	doi = {10.1007/s11219-011-9165-4},
	abstract = {Testing software product lines ({SPLs}) is very challenging due to a high degree of variability leading to an enormous number of possible products. The vast majority of today’s testing approaches for {SPLs} validate products individually using different kinds of reuse techniques for testing. Because of their reusability and adaptability capabilities, model-based approaches are suitable to describe variability and are therefore frequently used for implementation and testing purposes of {SPLs}. Due to the enormous number of possible products, individual product testing becomes more and more infeasible. Pairwise testing offers one possibility to test a subset of all possible products. However, according to the best of our knowledge, there is no contribution discussing and rating this approach in the {SPL} context. In this contribution, we provide a mapping between feature models describing the common and variable parts of an {SPL} and a reusable test model in the form of statecharts. Thereby, we interrelate feature model-based coverage criteria and test model-based coverage criteria such as control and data flow coverage and are therefore able to discuss the potentials and limitations of pairwise testing. We pay particular attention to test requirements for feature interactions constituting a major challenge in {SPL} engineering. We give a concise definition of feature dependencies and feature interactions from a testing point of view, and we discuss adequacy criteria for {SPL} coverage under pairwise feature interaction testing and give a generalization to the T-wise case. The concept and implementation of our approach are evaluated by means of a case study from the automotive domain.},
	pages = {567--604},
	number = {3},
	journaltitle = {Software Quality Journal},
	shortjournal = {Software Qual J},
	author = {Lochau, Malte and Oster, Sebastian and Goltz, Ursula and Schürr, Andy},
	urldate = {2024-09-17},
	date = {2012-09-01},
	langid = {english},
	keywords = {Software product lines, Combinatorial testing, Feature interaction, Model-based engineering and testing, Test generation and coverage},
}

@inproceedings{migliorini_architectural_2024,
	location = {Cham},
	title = {Architectural Views: The State of Practice in Open-Source Software Projects},
	isbn = {978-3-031-70797-1},
	doi = {10.1007/978-3-031-70797-1_27},
	shorttitle = {Architectural Views},
	abstract = {Context: Architectural views serve as fundamental artefacts for designing and communicating software architectures. In the context of collaborative software development, producing sound architectural documentation, where architectural views play a central role, is a crucial aspect for effective teamwork. Despite their importance, the use of architectural views in open-source projects to date remains only marginally explored.},
	pages = {396--415},
	booktitle = {Software Architecture},
	publisher = {Springer Nature Switzerland},
	author = {Migliorini, Sofia and Verdecchia, Roberto and Malavolta, Ivano and Lago, Patricia and Vicario, Enrico},
	editor = {Galster, Matthias and Scandurra, Patrizia and Mikkonen, Tommi and Oliveira Antonino, Pablo and Nakagawa, Elisa Yumi and Navarro, Elena},
	date = {2024},
	langid = {english},
	keywords = {Architectural Documentation, Architectural Views, Open Source Software, Repository Mining},
}

@inproceedings{harrison_nature_2024,
	location = {Cham},
	title = {The Nature of Questions that Arise During Software Architecture Design},
	isbn = {978-3-031-70797-1},
	doi = {10.1007/978-3-031-70797-1_3},
	abstract = {During the process of software architectural design, numerous questions arise which must be answered. These questions may be about requirements on the proposed system (the problem space) or about how the system should be designed and developed (the solution space). As questions arise they may be answered immediately, deferred until later, or provisionally answered with an assumption about the answer. The objective of this work was to explore the nature of questions that arise during architecture. We explored the types of questions, how they are organized, how they are tracked, and how and when they are answered. We started by surveying highly experienced architects about their practices with respect to architectural questions. We also performed a controlled experiment with master students about organizing architectural questions that clarified and substantiated the survey data. We learned that architectural questions include slightly more questions about the problem space than the solution space, as well as a minority of questions related to the managing of the project. We found that architects often use ad hoc methods to organize and track them, although they typically organize them along more than one dimension. We learned also that, about a third of the time, architects make assumptions about the answers to architectural questions in order to make progress on the architecture. This suggests that some projects may have risks of incorrect design or later costly rework due to inadequate tracking or incorrectly answered architectural questions.},
	pages = {37--52},
	booktitle = {Software Architecture},
	publisher = {Springer Nature Switzerland},
	author = {Harrison, Neil B. and Aguiar, Ademar},
	editor = {Galster, Matthias and Scandurra, Patrizia and Mikkonen, Tommi and Oliveira Antonino, Pablo and Nakagawa, Elisa Yumi and Navarro, Elena},
	date = {2024},
	langid = {english},
	keywords = {Software Architecture, Requirements, Quality Attributes},
}

@article{tchernykh_towards_2019,
	title = {Towards understanding uncertainty in cloud computing with risks of confidentiality, integrity, and availability},
	volume = {36},
	issn = {1877-7503},
	url = {https://www.sciencedirect.com/science/article/pii/S1877750316303878},
	doi = {10.1016/j.jocs.2016.11.011},
	abstract = {An extensive research has led to a general understanding of uncertainty issues in different fields ranging from computational biology to decision making in economics. However, a study of uncertainty on large scale computing systems and cloud computing systems is limited. Most of works examine uncertainty phenomena in users’ perceptions of the qualities, intentions and actions of cloud providers. In this paper, we discuss the role of uncertainty in the resource and service provisioning, privacy, etc. especially, in the presence of the risks of confidentiality, integrity, and availability. We review sources of uncertainty, and fundamental approaches for scheduling under uncertainty. We also discuss potentials of these approaches, and address methods for mitigating the risks of confidentiality, integrity, and availability associated with the loss of information, denial of access for a long time, and information leakage.},
	pages = {100581},
	journaltitle = {Journal of Computational Science},
	shortjournal = {Journal of Computational Science},
	author = {Tchernykh, Andrei and Schwiegelsohn, Uwe and Talbi, El-ghazali and Babenko, Mikhail},
	urldate = {2024-09-19},
	date = {2019-09-01},
	keywords = {Uncertainty, Privacy, Cloud computing, Reliability, Optimization, Resource provisioning, Scheduling},
}

@article{jorswieck_broadcasting_2015,
	title = {Broadcasting Into the Uncertainty: Authentication and Confidentiality by Physical-Layer Processing},
	volume = {103},
	issn = {1558-2256},
	url = {https://ieeexplore.ieee.org/abstract/document/7270404},
	doi = {10.1109/JPROC.2015.2469602},
	shorttitle = {Broadcasting Into the Uncertainty},
	abstract = {The wireless medium offers many opportunities for broadcast communications. However, it also opens the possibility for attackers to eavesdrop the broadcast data or to pretend to be another node or device. These two attacks define the protection goals, namely, confidentiality and authenticity. Traditionally, both are solved by cryptographic approaches exploiting knowledge available in the surrounding infrastructure. The novel communication paradigms for the Internet of Things or cyber–physical systems do not scale with the standard cryptographic approach. Instead it is possible to exploit properties of the underlying physical channel to provide countermeasures against eavesdropping and impersonation attacks. Thereby, the random fading channel induces uncertainty which is detrimental but at the same time also helpful. In this paper, we review and describe a generalized model for physical-layer-based confidential data transmission and wireless authentication. A key role is played by the channel uncertainty and available design dimensions such as time, frequency, and space. We show that wireless authentication and secret-key generation can work in multicarrier and multiple-antenna systems and explain how even outdated channel state information can help to increase the available secure degrees of freedom. This survey focuses on the system design of wireless physical-layer confidentiality and authenticity under channel uncertainty. The insights could lead to a design of practical systems which are preparing the ground for confidentiality and authenticity already on the physical layer of the communication protocol stack.},
	pages = {1702--1724},
	number = {10},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Jorswieck, Eduard and Tomasin, Stefano and Sezgin, Aydin},
	urldate = {2024-09-19},
	date = {2015-10},
	note = {Conference Name: Proceedings of the {IEEE}},
	keywords = {Uncertainty, Security, Authentication, broadcast channel, Broadcasting, Channel estimation, channel state information ({CSI}), channel uncertainty, Communication system security, delayed {CSI}, multicarrier transmission, multiple-antenna systems, Physical layer, physical-layer security, secret-key agreement, Telecommunication services, wireless authentication, Wireless communication, wiretap channel},
}

@incollection{longpre_how_2007,
	location = {Berlin, Heidelberg},
	title = {How to Efficiently Process Uncertainty within a Cyberinfrastructure without Sacrificing Privacy and Confidentiality},
	isbn = {978-3-540-71078-3},
	url = {https://doi.org/10.1007/978-3-540-71078-3_6},
	pages = {155--173},
	booktitle = {Computational Intelligence in Information Assurance and Security},
	publisher = {Springer},
	author = {Longpré, Luc and Kreinovich, Vladik},
	editor = {Nedjah, Nadia and Abraham, Ajith and Mourelle, Luiza de Macedo},
	urldate = {2024-09-19},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-3-540-71078-3_6},
}

@inproceedings{puska_confidentiality-aware_2018,
	title = {Confidentiality-Aware Decision on Handoffs under Uncertainty on Heterogeneous Wireless Networks},
	url = {https://ieeexplore.ieee.org/abstract/document/8538677},
	doi = {10.1109/ISCC.2018.8538677},
	abstract = {The handoff process in heterogeneous wireless networks ({HetNets}) focuses on the maintenance of mobile users connectivity, seeking to keep them continuously connected to the best available network. By supporting a better user connectivity on {HetNets}, handoff decision methods should take into account in the choice procedure both {QoS} and security issues jointly with performance. Unfortunately, such methods have slightly addressed security by ignoring its properties, and such fragility can lead to risky set up for user's data confidentiality transmission. Particularly, handoff decision methods ignore the existing uncertainty in {HetNets}. But, uncertain information is common when handling wireless networks transition. Therefore, this work presents a method to support confidentiality-aware decision making in the mobile device handoff process by adapting the expected-utility theory. Simulation results show how this method brings advantages to the user connectivity providing both less risky choices and low handoff cost.},
	eventtitle = {2018 {IEEE} Symposium on Computers and Communications ({ISCC})},
	pages = {00884--00889},
	booktitle = {2018 {IEEE} Symposium on Computers and Communications ({ISCC})},
	author = {Puska, Alisson and Nogueira, Michele and Santos, Aldri},
	urldate = {2024-09-19},
	date = {2018-06},
	keywords = {Uncertainty, Security, Decision making, Mobile handsets, Adaptation models, Performance evaluation, Wireless networks},
}

@inproceedings{morali_it_2008,
	title = {{IT} confidentiality risk assessment for an architecture-based approach},
	url = {https://ieeexplore.ieee.org/abstract/document/4540072},
	doi = {10.1109/BDIM.2008.4540072},
	abstract = {Information systems require awareness of risks and a good understanding of vulnerabilities and their exploitations. In this paper, we propose a novel approach for the systematic assessment and analysis of confidentiality risks caused by disclosure of operational and functional information. The approach is based on a model integrating information assets and the {IT} infrastructure that they rely on for distributed systems. {IT} infrastructures enable one to analyse risk propagation possibilities and calculate the impact of confidentiality incidents. Furthermore, our approach is a mean to bridge the technical and businessoriented views of information systems, since the importance of information assets, which is leading the technical decisions, is set by the business.},
	eventtitle = {2008 3rd {IEEE}/{IFIP} International Workshop on Business-driven {IT} Management},
	pages = {31--40},
	booktitle = {2008 3rd {IEEE}/{IFIP} International Workshop on Business-driven {IT} Management},
	author = {Morali, Ayse and Zambon, Emmanuele and Etalle, Sandro and Overbeek, P.L.},
	urldate = {2024-09-19},
	date = {2008-04},
	keywords = {risk analysis, Databases, Risk analysis, software architecture, Information security, architecture-based approach, Bridges, Computer hacking, Credit cards, functional information, Information analysis, Internet, {ISO} standards, {IT} confidentiality risk assessment, {IT} infrastructures, Risk management, Solids, systems analysis},
}

@inproceedings{busari_radar_2017,
	title = {{RADAR}: A Lightweight Tool for Requirements and Architecture Decision Analysis},
	url = {https://ieeexplore.ieee.org/abstract/document/7985693},
	doi = {10.1109/ICSE.2017.57},
	shorttitle = {{RADAR}},
	abstract = {Uncertainty and conflicting stakeholders' objectives make many requirements and architecture decisions particularly hard. Quantitative probabilistic models allow software architects to analyse such decisions using stochastic simulation and multi-objective optimisation, but the difficulty of elaborating the models is an obstacle to the wider adoption of such techniques. To reduce this obstacle, this paper presents a novel modelling language and analysis tool, called {RADAR}, intended to facilitate requirements and architecture decision analysis. The language has relations to quantitative {AND}/{OR} goal models used in requirements engineering and to feature models used in software product lines. However, it simplifies such models to a minimum set of language constructs essential for decision analysis. The paper presents {RADAR}'s modelling language, automated support for decision analysis, and evaluates its application to four real-world examples.},
	eventtitle = {2017 {IEEE}/{ACM} 39th International Conference on Software Engineering ({ICSE})},
	pages = {552--562},
	booktitle = {2017 {IEEE}/{ACM} 39th International Conference on Software Engineering ({ICSE})},
	author = {Busari, Saheed A. and Letier, Emmanuel},
	urldate = {2024-09-20},
	date = {2017-05},
	keywords = {Mathematical model, Computer architecture, Software, Analytical models, Software Architecture, Optimization, Requirements Engineering, Decision analysis, Decision Analysis, Expected Value of Information, Goal Modelling, Monte-Carlo Simulation, Multi-Objective Optimisation, Radar, Search-Based Software Engineering},
}

@online{github_codeql_2021,
	title = {{CodeQL}},
	url = {https://codeql.github.com/},
	author = {{GitHub}},
	urldate = {2024-09-21},
	date = {2021},
}

@online{european_data_protection_board_hamburg_2020,
	title = {Hamburg Commissioner Fines H\&M 35.3 Million Euro for Data Protection Violations in Service Centre {\textbar} European Data Protection Board},
	url = {https://www.edpb.europa.eu/news/national-news/2020/hamburg-commissioner-fines-hm-353-million-euro-data-protection-violations_en},
	author = {European Data Protection Board},
	urldate = {2024-09-23},
	date = {2020},
}

@online{morris_massive_2021,
	title = {Massive data leak exposes 700 million {LinkedIn} users’ information},
	url = {https://fortune.com/2021/06/30/linkedin-data-theft-700-million-users-personal-information-cybersecurity/},
	titleaddon = {Fortune},
	author = {Morris, Chris},
	urldate = {2024-09-23},
	date = {2021},
	langid = {english},
}

@online{haselton_yahoo_2017,
	title = {Yahoo just said every single account was affected by 2013 attack - 3 billion in all},
	url = {https://www.cnbc.com/2017/10/03/yahoo-every-single-account-3-billion-people-affected-in-2013-attack.html},
	abstract = {Yahoo said every single account was affected by an attack that took place in 2013.},
	titleaddon = {{CNBC}},
	author = {Haselton, Todd},
	urldate = {2024-09-23},
	date = {2017},
	langid = {english},
	note = {Section: Technology},
}

@article{gatzlaff_effect_2010,
	title = {The Effect of Data Breaches on Shareholder Wealth},
	volume = {13},
	issn = {1540-6296},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6296.2010.01178.x},
	doi = {10.1111/j.1540-6296.2010.01178.x},
	abstract = {Many companies face the risk of a data breach exposing stored personal information of customers and employees. The frequency of such incidents has been increasing over time and can result in significant costs for the affected firm. This article examines the stock market's assessment of the cost of data breaches at publicly traded companies in which personal information such as customer and/or employee data are exposed. Using event study methodology on a sample of 77 events between the beginning of 2004 and the end of 2006, we find that the overall effect of a data breach on shareholder wealth is negative and statistically significant. Based on a cross-sectional analysis of the cumulative abnormal returns, we find a negative association between market reaction and firms that are less forthcoming about the details of the breach. We also find that firms with higher market-to-book ratios experience greater negative abnormal returns associated with a data breach. Further, we find that firm size and subsidiary status mitigate the negative effect of a data breach on the firm's stock price and that the negative market reaction to a data breach is more significant in the most recent time periods of the sample.},
	pages = {61--83},
	number = {1},
	journaltitle = {Risk Management and Insurance Review},
	author = {Gatzlaff, Kevin M. and {McCullough}, Kathleen A.},
	urldate = {2024-09-23},
	date = {2010},
	langid = {english},
}

@article{cheng_enterprise_2017,
	title = {Enterprise data breach: causes, challenges, prevention, and future directions},
	volume = {7},
	issn = {1942-4795},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1211},
	doi = {10.1002/widm.1211},
	shorttitle = {Enterprise data breach},
	abstract = {A data breach is the intentional or inadvertent exposure of confidential information to unauthorized parties. In the digital era, data has become one of the most critical components of an enterprise. Data leakage poses serious threats to organizations, including significant reputational damage and financial losses. As the volume of data is growing exponentially and data breaches are happening more frequently than ever before, detecting and preventing data loss has become one of the most pressing security concerns for enterprises. Despite a plethora of research efforts on safeguarding sensitive information from being leaked, it remains an active research problem. This review helps interested readers to learn about enterprise data leak threats, recent data leak incidents, various state-of-the-art prevention and detection techniques, new challenges, and promising solutions and exciting opportunities. {WIREs} Data Mining Knowl Discov 2017, 7:e1211. doi: 10.1002/widm.1211 This article is categorized under: Application Areas {\textgreater} Business and Industry Fundamental Concepts of Data and Knowledge {\textgreater} Key Design Issues in Data Mining Technologies {\textgreater} Prediction},
	pages = {e1211},
	number = {5},
	journaltitle = {{WIREs} Data Mining and Knowledge Discovery},
	author = {Cheng, Long and Liu, Fang and Yao, Danfeng},
	urldate = {2024-09-23},
	date = {2017},
	langid = {english},
}

@article{ayyagari_exploratory_2012,
	title = {An Exploratory Analysis of Data Breaches from 2005-2011: Trends and Insights},
	volume = {8},
	issn = {1553-6548},
	url = {https://doi.org/10.1080/15536548.2012.10845654},
	doi = {10.1080/15536548.2012.10845654},
	shorttitle = {An Exploratory Analysis of Data Breaches from 2005-2011},
	abstract = {Data breaches have become one of the biggest problems for organizations, costing an average of \$7.2 million per breach (Symantec, 2011). Previous research on data breaches has focused on: (i) reducing the possibility of data breach by addressing employee compliance behavior, and (ii) understanding the impact of data breaches on organizations. We extended this research by content analyzing 2633 unique data breaches that resulted in loss of more than 500 million individual records. Our results indicate that data breaches continue to be a major issue for organizations. The results imply that the nature of the data breaches is changing. Data breaches are typically associated with hacking - however, our results indicate that breaches due to hacking are decreasing, whereas breaches due to ‘human element’ are increasing. One disconcerting result from our analysis is that data breaches that can be directly attributed to implementation and enforcement of security policies account for a major share. Collectively, the results indicate that organizations need to implement effective training and stricter enforcement of security policies.},
	pages = {33--56},
	number = {2},
	journaltitle = {Journal of Information Privacy and Security},
	author = {Ayyagari, Ramakrishna},
	urldate = {2024-09-23},
	date = {2012-04-01},
	keywords = {Content Analysis, Data Breaches, Exploratory Analysis, Security Trends},
}

@inproceedings{villalobos_will_2024,
	title = {Will we run out of data? Limits of {LLM} scaling based on human-generated data},
	url = {https://proceedings.mlr.press/v235/villalobos24a.html},
	shorttitle = {Position},
	abstract = {We investigate the potential constraints on {LLM} scaling posed by the availability of public human-generated text data. We forecast the growing demand for training data based on current trends and estimate the total stock of public human text data. Our findings indicate that if current {LLM} development trends continue, models will be trained on datasets roughly equal in size to the available stock of public human text data between 2026 and 2032, or slightly earlier if models are overtrained. We explore how progress in language modeling can continue when human-generated text datasets cannot be scaled any further. We argue that synthetic data generation, transfer learning from data-rich domains, and data efficiency improvements might support further progress.},
	eventtitle = {International Conference on Machine Learning},
	pages = {49523--49544},
	booktitle = {Proceedings of the 41st International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Villalobos, Pablo and Ho, Anson and Sevilla, Jaime and Besiroglu, Tamay and Heim, Lennart and Hobbhahn, Marius},
	urldate = {2024-09-23},
	date = {2024-07-08},
	langid = {english},
	note = {{ISSN}: 2640-3498},
}

@online{meta_introducing_2024,
	title = {Introducing Meta Llama 3: The most capable openly available {LLM} to date},
	url = {https://ai.meta.com/blog/meta-llama-3/},
	shorttitle = {Introducing Meta Llama 3},
	abstract = {Today, we’re introducing Meta Llama 3, the next generation of our state-of-the-art open source large language model. In the coming months, we expect to share new capabilities, additional model sizes, and more.},
	titleaddon = {Meta {AI}},
	author = {Meta},
	urldate = {2024-09-23},
	date = {2024},
	langid = {english},
}

@online{bmdv_bmdv_2022,
	title = {{BMDV} - The Federal Ministry for Digital and Transport launches process for a Mobility Data Act},
	url = {https://bmdv.bund.de/SharedDocs/EN/PressRelease/2022/081-wissing-data-is-the-basis-of-progress.html},
	author = {{BMDV}},
	urldate = {2024-09-23},
	date = {2022},
}

@inproceedings{olivero_security_2019,
	title = {Security Assessment of Systems of Systems},
	url = {https://ieeexplore.ieee.org/abstract/document/8882841},
	doi = {10.1109/SESoS/WDES.2019.00017},
	abstract = {Engineering Systems of Systems is one of the new chal-lenges of the last few years. This depends on the increasing number of systems that must interact one with another to achieve a goal. One peculiarity of Systems of Systems is that they are made of systems able to live on their own with well-established functionalities and requirements, and that are not necessarily aware of the joint mission or prepared to collaborate. In this emergent scenario, securi-ty is one crucial aspect that must be considered from the very beginning. In fact, the security of a System of Sys-tems is not automatically granted even if the security of each constituent system is guaranteed. The aim of this paper is to address the problem of assessing security properties in Systems of Systems. We discuss the specific security aspects of such emergent systems, and propose the {TeSSoS} approach, which includes modelling and testing security properties in Systems of Systems and introduces the Red and Blue Requirements Specification concepts.},
	eventtitle = {2019 {IEEE}/{ACM} 7th International Workshop on Software Engineering for Systems-of-Systems ({SESoS}) and 13th Workshop on Distributed Software Development, Software Ecosystems and Systems-of-Systems ({WDES})},
	pages = {62--65},
	booktitle = {2019 {IEEE}/{ACM} 7th International Workshop on Software Engineering for Systems-of-Systems ({SESoS}) and 13th Workshop on Distributed Software Development, Software Ecosystems and Systems-of-Systems ({WDES})},
	author = {Olivero, Miguel Angel and Bertolino, Antonia and Dominguez-Mayo, Francisco José and Escalona, María José and Matteucci, Ilaria},
	urldate = {2024-09-23},
	date = {2019-05},
	keywords = {Computer architecture, Credit cards, Testing, Collaboration, Blue Requirements, Password, Red Requirements, Security Assessment, System of systems, System of Systems},
}

@online{statista_number_2004,
	title = {Number of internet users worldwide 2005-2023},
	url = {https://www.statista.com/statistics/273018/number-of-internet-users-worldwide/},
	abstract = {The number of internet users keeps increasing year by year and surpassed 5 billion internet users worldwide in 2022.},
	titleaddon = {Statista},
	author = {Statista},
	urldate = {2024-09-23},
	date = {2004},
	langid = {english},
}

@misc{upstream_2024_2024,
	title = {2024 Global Automotive Cybersecurity Report},
	url = {https://upstream.auto/reports/global-automotive-cybersecurity-report/},
	author = {{UpStream}},
	urldate = {2024-09-23},
	date = {2024},
}

@article{arat_attack_2023,
	title = {Attack Path Detection for {IIoT} Enabled Cyber Physical Systems: Revisited},
	volume = {128},
	issn = {0167-4048},
	url = {https://www.sciencedirect.com/science/article/pii/S0167404823000846},
	doi = {10.1016/j.cose.2023.103174},
	shorttitle = {Attack Path Detection for {IIoT} Enabled Cyber Physical Systems},
	abstract = {In this paper, we propose a generic vulnerability and risk assessment method for {IIoT}-enabled critical systems. We focus on reducing risk factors and vulnerable structures in order to provide security issues for the {IIoT} and enabled complex systems. In addition to the existing risk assessment and related methods, we represent the {IIoT}-enabled network topology as a directed graph, and we develop an attack tree-based approach using graph theory. We assume that each device is a potential critical node due to the existing vulnerabilities, which are defined in the National Vulnerability Database ({NVD}), and we establish directed relations between nodes, considering cyber and physical interactions. We improve existing attack path-identifying methods using the Depth First Search ({DFS}) algorithm to find all the paths from the source to the target nodes. In the generated topology, each node has the pre-assigned Common Vulnerability Scoring System ({CVSS}) scores acting as a weight. We also implement the Floyd-Warshall algorithm to identify path risk levels. Finally, we assess the identified vulnerable paths from varying source and target pairs via path and node-reducing procedures, considering risk thresholds. We perform our simulation on a custom Python simulator, considering the transportation and supply sectors. We compare our results with the previous ones. Simulation results show that our proposed methods and procedures outperform existing risk assessment and filtering methods in terms of running time and attack path identification and filtering.},
	pages = {103174},
	journaltitle = {Computers \& Security},
	shortjournal = {Computers \& Security},
	author = {Arat, Ferhat and Akleylek, Sedat},
	urldate = {2024-09-24},
	date = {2023-05-01},
	keywords = {Attack graph, Attack path, Cyber attacks, Industrial {IoT} security, Path filtering, Vulnerability and risk assessment},
}

@article{shaw_what_2002,
	title = {What makes good research in software engineering?},
	volume = {4},
	issn = {1433-2779},
	url = {https://doi.org/10.1007/s10009-002-0083-4},
	doi = {10.1007/s10009-002-0083-4},
	abstract = {Physics, biology, and medicine have well-refined public explanations of their research processes. Even in simplified form, these provide guidance about what counts as “good research” both inside and outside the field. Software engineering has not yet explicitly identified and explained either our research processes or the ways we recognize excellent work. Science and engineering research fields can be characterized in terms of the kinds of questions they find worth investigating, the research methods they adopt, and the criteria by which they evaluate their results. I will present such a characterization for software engineering, showing the diversity of research strategies and the way they shift as ideas mature. Understanding these strategies should help software engineers design research plans and report the results clearly; it should also help explain the character of software engineering research to computer science at large and to other scientists.},
	pages = {1--7},
	number = {1},
	journaltitle = {International Journal on Software Tools for Technology Transfer},
	shortjournal = {{STTT}},
	author = {Shaw, Mary},
	urldate = {2024-10-07},
	date = {2002-10-01},
	langid = {english},
	keywords = {Computer Science, Software Engineering, Design Research, Research Field, Research Method},
}

@online{koziolek_tracing_2022,
	title = {Tracing the Practical Impact of Software Architecture Research},
	url = {https://medium.com/@heiko.koziolek/tracing-the-practical-impact-of-software-architecture-research-a2b91136455},
	titleaddon = {Medium},
	author = {Koziolek, Heiko},
	urldate = {2024-10-07},
	date = {2022},
	langid = {english},
}

@misc{ronneberg_quantitative_2024,
	title = {Quantitative Information Flow Control by Construction for Component-Based Systems},
	url = {http://arxiv.org/abs/2401.07677},
	doi = {10.48550/arXiv.2401.07677},
	abstract = {Secure software architecture is increasingly important in a data-driven world. When security is neglected sensitive information might leak through unauthorized access. To mitigate this software architects needs tools and methods to quantify security risks in complex systems. This paper presents doctoral research in its early stages concerned with creating constructive methods for building secure component-based systems from a quantitative information flow specification. This research aim at developing a method that allows software architects to develop secure systems from a repository of secure components. Planned contributions are refinement rules for secure development of components from a specification and well-formedness rules for secure composition of said components.},
	number = {{arXiv}:2401.07677},
	publisher = {{arXiv}},
	author = {Rønneberg, Rasmus Carl},
	urldate = {2024-10-08},
	date = {2024-01-15},
	eprinttype = {arxiv},
	eprint = {2401.07677 [cs]},
	keywords = {Computer Science - Software Engineering},
}

@article{burton_resilience_2024,
	title = {Resilience and Antifragility of Autonomous Systems (Dagstuhl Seminar 24182)},
	volume = {14},
	issn = {2192-5283},
	url = {https://drops.dagstuhl.de/entities/document/10.4230/DagRep.14.4.142},
	doi = {10.4230/DagRep.14.4.142},
	pages = {142--163},
	number = {4},
	journaltitle = {Dagstuhl Reports},
	author = {Burton, Simon and Calinescu, Radu and Mirandola, Raffaela},
	editor = {Burton, Simon and Calinescu, Radu and Mirandola, Raffaela},
	date = {2024},
	note = {Place: Dagstuhl, Germany
Publisher: Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
}

@inproceedings{boltz_extensible_2024,
	location = {Cham},
	title = {An Extensible Framework for Architecture-Based Data Flow Analysis for Information Security},
	isbn = {978-3-031-66326-0},
	doi = {10.1007/978-3-031-66326-0_21},
	abstract = {The growing interconnection between software systems increases the need for security already at design time. Security-related properties like confidentiality are often analyzed based on data flow diagrams ({DFDs}). However, manually analyzing {DFDs} of large software systems is bothersome and error-prone, and adjusting an already deployed software is costly. Additionally, closed analysis ecosystems limit the reuse of modeled information and impede comprehensive statements about a system’s security. In this paper, we present an open and extensible framework for data flow analysis. The central element of our framework is our new implementation of a well-validated data-flow-based analysis approach. The framework is compatible with {DFDs} and can also extract data flows from the Palladio architectural description language. We showcase the extensibility with multiple model and analysis extensions. Our evaluation indicates that we can analyze similar scenarios while achieving higher scalability compared to previous implementations.},
	pages = {342--358},
	booktitle = {Software Architecture. {ECSA} 2023 Tracks, Workshops, and Doctoral Symposium},
	publisher = {Springer Nature Switzerland},
	author = {Boltz, Nicolas and Hahner, Sebastian and Gerking, Christopher and Heinrich, Robert},
	editor = {Tekinerdoğan, Bedir and Spalazzese, Romina and Sözer, Hasan and Bonfanti, Silvia and Weyns, Danny},
	date = {2024},
	langid = {english},
	keywords = {Security, Software Architecture, Data Flow Diagram},
}

@inproceedings{saglam_automated_2024,
	location = {New York, {NY}, {USA}},
	title = {Automated Detection of {AI}-Obfuscated Plagiarism in Modeling Assignments},
	isbn = {9798400704987},
	url = {https://dl.acm.org/doi/10.1145/3639474.3640084},
	doi = {10.1145/3639474.3640084},
	series = {{ICSE}-{SEET} '24},
	abstract = {Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like {ChatGPT} have made it easier than ever to obfuscate plagiarized solutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by {ChatGPT}. Our results show that we achieve a significantly higher detection rate for {AI}-generated attacks and a broader resilience than the state-of-the-art.},
	pages = {297--308},
	booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
	publisher = {Association for Computing Machinery},
	author = {Sağlam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
	urldate = {2024-10-14},
	date = {2024},
}

@inproceedings{saglam_obfuscation-resilient_2024,
	location = {New York, {NY}, {USA}},
	title = {Obfuscation-Resilient Software Plagiarism Detection with {JPlag}},
	isbn = {9798400705021},
	url = {https://dl.acm.org/doi/10.1145/3639478.3643074},
	doi = {10.1145/3639478.3643074},
	series = {{ICSE}-Companion '24},
	abstract = {The rise of automated obfuscation techniques challenges the widespread assumption that evading a software plagiarism detector requires more effort than completing programming and modeling assignments in computer science education. This threatens plagiarism detectors without comprehensive obfuscation resilience and, ultimately, academic integrity. This paper summarizes recent enhancements of {JPlag}, a widely-used software plagiarism detector, enabling it to achieve broad resilience against automated obfuscation. The findings demonstrate that {JPlag} significantly outperforms the state-of-the-art in terms of obfuscation resilience.},
	pages = {264--265},
	booktitle = {Proceedings of the 2024 {IEEE}/{ACM} 46th International Conference on Software Engineering: Companion Proceedings},
	publisher = {Association for Computing Machinery},
	author = {Sağlam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
	urldate = {2024-10-14},
	date = {2024},
}

@inproceedings{saglam_detecting_2024,
	location = {New York, {NY}, {USA}},
	title = {Detecting Automatic Software Plagiarism via Token Sequence Normalization},
	isbn = {9798400702174},
	url = {https://dl.acm.org/doi/10.1145/3597503.3639192},
	doi = {10.1145/3597503.3639192},
	series = {{ICSE} '24},
	abstract = {While software plagiarism detectors have been used for decades, the assumption that evading detection requires programming proficiency is challenged by the emergence of automated plagiarism generators. These generators enable effortless obfuscation attacks, exploiting vulnerabilities in existing detectors by inserting statements to disrupt the matching of related programs. Thus, we present a novel, language-independent defense mechanism that leverages program dependence graphs, rendering such attacks infeasible. We evaluate our approach with multiple real-world datasets and show that it defeats plagiarism generators by offering resilience against automated obfuscation while maintaining a low rate of false positives.},
	pages = {1--13},
	booktitle = {Proceedings of the {IEEE}/{ACM} 46th International Conference on Software Engineering},
	publisher = {Association for Computing Machinery},
	author = {Sağlam, Timur and Brödel, Moritz and Schmid, Larissa and Hahner, Sebastian},
	urldate = {2024-10-14},
	date = {2024-04-12},
}

@inproceedings{camara_uncertainty_2024,
	location = {New York, {NY}, {USA}},
	title = {Uncertainty Flow Diagrams: Towards a Systematic Representation of Uncertainty Propagation and Interaction in Adaptive Systems},
	isbn = {9798400705854},
	url = {https://dl.acm.org/doi/10.1145/3643915.3644084},
	doi = {10.1145/3643915.3644084},
	series = {{SEAMS} '24},
	shorttitle = {Uncertainty Flow Diagrams},
	abstract = {Sources of uncertainty in adaptive systems are rarely independent, and their interaction can affect the attainment of system goals in unpredictable ways. Despite ample work on "taming" uncertainty, the research community has devoted little attention to the systematic representation, analysis, and mitigation of uncertainty propagation and interaction ({UPI}) in adaptive systems. To address this oversight, we introduce Uncertainty Flow Diagrams, a notation that captures key {UPI} aspects. We demonstrate the use and benefits of our novel notation on Znn.com, an adaptive news site infrastructure.},
	pages = {37--43},
	booktitle = {Proceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
	publisher = {Association for Computing Machinery},
	author = {Camara, Javier and Hahner, Sebastian and Perez-Palacin, Diego and Vallecillo, Antonio and Acosta, Maribel and Bencomo, Nelly and Calinescu, Radu and Gerasimou, Simos},
	urldate = {2024-10-14},
	date = {2024-06-07},
}

@article{abbaspour_asadollah_enhancing_2024,
	title = {Enhancing Cybersecurity through Comprehensive Investigation of Data Flow-Based Attack Scenarios},
	volume = {4},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2624-800X},
	url = {https://www.mdpi.com/2624-800X/4/4/39},
	doi = {10.3390/jcp4040039},
	abstract = {Integration of the Internet of Things ({IoT}) in industrial settings necessitates robust cybersecurity measures to mitigate risks such as data leakage, vulnerability exploitation, and compromised information flows. Recent cyberattacks on critical industrial systems have highlighted the lack of threat analysis in software development processes. While existing threat modeling frameworks such as {STRIDE} enumerate potential security threats, they often lack detailed mapping of the sequences of threats that adversaries might exploit to apply cyberattacks. Our study proposes an enhanced approach to systematic threat modeling and data flow-based attack scenario analysis for integrating cybersecurity measures early in the development lifecycle. We enhance the {STRIDE} framework by extending it to include attack scenarios as sequences of threats exploited by adversaries. This extension allows us to illustrate various attack scenarios and demonstrate how these insights can aid system designers in strengthening their defenses. Our methodology prioritizes vulnerabilities based on their recurrence across various attack scenarios, offering actionable insights for enhancing system security. A case study in the automotive industry illustrates the practical application of our proposed methodology, demonstrating significant improvements in system security through proactive threat modeling and analysis of attack impacts. The results of our study provide actionable insights to improve system design and mitigate vulnerabilities.},
	pages = {823--852},
	number = {4},
	journaltitle = {Journal of Cybersecurity and Privacy},
	author = {Abbaspour Asadollah, Sara and Imtiaz, Shamoona and Dehlaghi-Ghadim, Alireza and Sjödin, Mikael and Sirjani, Marjan},
	urldate = {2024-10-21},
	date = {2024-12},
	langid = {english},
	note = {Number: 4
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {threat modeling, {STRIDE}, attack impact analysis, attack scenario, cyber–physical system ({CPS}), cyberattack, cybersecurity},
}

@inproceedings{kronjee_discovering_2018,
	location = {New York, {NY}, {USA}},
	title = {Discovering software vulnerabilities using data-flow analysis and machine learning},
	isbn = {978-1-4503-6448-5},
	url = {https://doi.org/10.1145/3230833.3230856},
	doi = {10.1145/3230833.3230856},
	series = {{ARES} '18},
	abstract = {We present a novel method for static analysis in which we combine data-flow analysis with machine learning to detect {SQL} injection ({SQLi}) and Cross-Site Scripting ({XSS}) vulnerabilities in {PHP} applications. We assembled a dataset from the National Vulnerability Database and the {SAMATE} project, containing vulnerable {PHP} code samples and their patched versions in which the vulnerability is solved. We extracted features from the code samples by applying data-flow analysis techniques, including reaching definitions analysis, taint analysis, and reaching constants analysis. We used these features in machine learning to train various probabilistic classifiers. To demonstrate the effectiveness of our approach, we built a tool called {WIRECAML}, and compared our tool to other tools for vulnerability detection in {PHP} code. Our tool performed best for detecting both {SQLi} and {XSS} vulnerabilities. We also tried our approach on a number of open-source software applications, and found a previously unknown vulnerability in a photo-sharing web application.},
	pages = {1--10},
	booktitle = {Proceedings of the 13th International Conference on Availability, Reliability and Security},
	publisher = {Association for Computing Machinery},
	author = {Kronjee, Jorrit and Hommersom, Arjen and Vranken, Harald},
	urldate = {2024-11-07},
	date = {2018-08-27},
}

@thesis{hahner_architecture-based_2024-1,
	location = {Karlsruhe, Germany},
	title = {Architecture-Based and Uncertainty-Aware Confidentiality Analysis},
	institution = {Karlsruhe Institute of Technology ({KIT})},
	type = {Dissertation},
	author = {Hahner, Sebastian},
	date = {2024},
}

@inproceedings{schmid_jplag_2025,
	title = {{JPlag}: Detecting Obfuscated Software Plagiarism using Token Normalization Graphs},
	booktitle = {Software Engineering 2025},
	publisher = {Gesellschaft für Informatik ({GI})},
	author = {Schmid, Larissa and Hahner, Sebastian and Sağlam, Timur},
	date = {2025},
	langid = {english},
	note = {accepted, to appear},
}

@inproceedings{saglam_mitigating_2025,
	title = {Mitigating Obfuscation Attacks on Software Plagiarism Detectors via Subsequence Merging},
	eventtitle = {{IEEE} Conference on Software Engineering Education and Training ({CSEE}\&T)},
	publisher = {{IEEE}},
	author = {Sağlam, Timur and Niehues, Nils and Hahner, Sebastian and Schmid, Larissa},
	date = {2025},
	note = {accepted, to appear},
}

@inproceedings{niehues_integrating_2024,
	title = {Integrating Security-Enriched Data Flow Diagrams Into Architecture-Based Confidentiality Analysis},
	url = {https://dl.gi.de/handle/20.500.12116/45546},
	eventtitle = {Softwaretechnik-Trends Band 44, Heft 4},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Niehues, Nils and Arp, Benjamin and Hüller, Tom and Schwickerath, Felix and Boltz, Nicolas and Hahner, Sebastian},
	urldate = {2025-01-16},
	date = {2024},
	langid = {english},
}

@inproceedings{huller_towards_2024,
	title = {Towards a Data Flow Diagram-Centric Confidentiality Analysis in Palladio},
	url = {https://dl.gi.de/handle/20.500.12116/45518},
	eventtitle = {Softwaretechnik-Trends Band 44, Heft 4},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Hüller, Tom and Schwickerath, Felix and Arp, Benjamin and Niehues, Nils and Boltz, Nicolas and Hahner, Sebastian},
	urldate = {2025-01-16},
	date = {2024},
	langid = {english},
}

@inproceedings{arp_analyzing_2024,
	title = {Analyzing Cyclic Data Flow Diagrams Regarding Information Security},
	url = {https://dl.gi.de/handle/20.500.12116/45545},
	eventtitle = {Softwaretechnik-Trends Band 44, Heft 4},
	publisher = {Gesellschaft für Informatik e.V.},
	author = {Arp, Benjamin and Niehues, Nils and Hüller, Tom and Schwickerath, Felix and Boltz, Nicolas and Hahner, Sebastian},
	urldate = {2025-01-16},
	date = {2024},
	langid = {english},
}

@inproceedings{niehues_architecture-based_2025,
	title = {An Architecture-Based Approach to Mitigate Confidentiality Violations Using Machine Learning},
	eventtitle = {2025 {IEEE} 22nd International Conference on Software Architecture ({ICSA})},
	booktitle = {2025 {IEEE} 22nd International Conference on Software Architecture ({ICSA})},
	publisher = {{IEEE}},
	author = {Niehues, Nils and Hahner, Sebastian and Heinrich, Robert},
	date = {2025},
	langid = {english},
	note = {accepted, to appear},
}

@inproceedings{schneider_how_2024,
	title = {How Dataflow Diagrams Impact Software Security Analysis: an Empirical Experiment},
	isbn = {9798350330663},
	doi = {10.1109/SANER60148.2024.00103},
	shorttitle = {How Dataflow Diagrams Impact Software Security Analysis},
	eventtitle = {2024 {IEEE} International Conference on Software Analysis, Evolution and Reengineering ({SANER})},
	pages = {952--963},
	publisher = {{IEEE} Computer Society},
	author = {Schneider, Simon and Ferreyra, Nicolás E. Díaz and Quéval, Pierre-Jean and Simhandl, Georg and Zdun, Uwe and Scandariato, Riccardo},
	urldate = {2025-01-30},
	date = {2024-03-01},
}

@inproceedings{tuma_automating_2020,
	location = {New York, {NY}, {USA}},
	title = {Automating the early detection of security design flaws},
	isbn = {978-1-4503-7019-6},
	url = {https://dl.acm.org/doi/10.1145/3365438.3410954},
	doi = {10.1145/3365438.3410954},
	series = {{MODELS} '20},
	pages = {332--342},
	booktitle = {Proceedings of the 23rd {ACM}/{IEEE} International Conference on Model Driven Engineering Languages and Systems},
	publisher = {Association for Computing Machinery},
	author = {Tuma, Katja and Sion, Laurens and Scandariato, Riccardo and Yskout, Koen},
	urldate = {2025-01-30},
	date = {2020},
}

@article{wohlin_case_2021,
	title = {Case Study Research in Software Engineering—It is a Case, and it is a Study, but is it a Case Study?},
	volume = {133},
	issn = {0950-5849},
	url = {https://www.sciencedirect.com/science/article/pii/S0950584921000033},
	doi = {10.1016/j.infsof.2021.106514},
	abstract = {Background:
Case studies are regularly published in the software engineering literature, and guidelines for conducting case studies are available. Based on a perception that the label “case study” is assigned to studies that are not case studies, an investigation has been conducted.
Objective:
The aim was to investigate whether or not the label “case study” is correctly used in software engineering research.
Method:
To address the objective, 100 recent articles found through Scopus when searching for case studies in software engineering have been investigated and classified.
Results:
Unfortunately, the perception of misuse of the label “case study” is correct. Close to 50\% of the articles investigated were judged as not being case studies according to the definition of a case study.
Conclusions:
We either need to ensure correct use of the label “case study”, or we need another label for its definition. Given that “case study” is a well-established label, it is probably impossible to change the label. Thus, we introduce an alternative definition of case study emphasising its real-life context, and urge researchers to carefully follow the definition of different research methods when presenting their research.},
	pages = {106514},
	journaltitle = {Information and Software Technology},
	shortjournal = {Information and Software Technology},
	author = {Wohlin, Claes},
	urldate = {2025-01-31},
	date = {2021-05-01},
	keywords = {Software engineering, Case study, Empirical, Misuse},
}
